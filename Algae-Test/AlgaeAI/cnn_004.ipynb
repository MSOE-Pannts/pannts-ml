{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_path, column_names):\n",
    "    data = pd.read_csv(file_path, header = 0, names = column_names)\n",
    "    return data\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset, axis = 0)\n",
    "    sigma = np.std(dataset, axis = 0)\n",
    "    return (dataset - mu) / sigma\n",
    "\n",
    "def convert_timestamp(dataset):\n",
    "    dataset['Timestamp'] = dataset['Timestamp'].apply(lambda x:\n",
    "                                                     datetime.strptime(x, '%m/%d/%y %H:%M').timestamp())\n",
    "    return dataset\n",
    "\n",
    "def convert_BGA_RFU(dataset, threshold):\n",
    "    dataset['BGA_Phycocyanin_RFU'] = dataset['BGA_Phycocyanin_RFU'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "    return dataset\n",
    "\n",
    "def plot_axis(ax, x, y, title):\n",
    "    ax.plot(x, y)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_visible(false)\n",
    "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "    ax.set_xlim([min(y), max(x)])\n",
    "    ax.grid(true)\n",
    "    \n",
    "def plot_activity(activity, data):\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows = 3, figsize = (15, 10), sharex = True)\n",
    "    plot_axis(ax0, data['timestamp'], data['x-axis'], 'x-axis')\n",
    "    plot_axis(ax1, data['timestamp'], data['y-axis'], 'y-axis')\n",
    "    plot_axis(ax2, data['timestamp'], data['z-axis'], 'z-axis')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    fig.suptitle(activity)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.show()\n",
    "    \n",
    "# We step 50% down based on window size\n",
    "def windows(data, size):\n",
    "    counter_output = 0\n",
    "    start = 0\n",
    "    while start < data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start += (size / 5)\n",
    "        counter_output += 1\n",
    "        if counter_output % 10 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format((start / data.count()) * 100))\n",
    "    \n",
    "# 32 chosen for 8 hours of 15 minute intervals\n",
    "# TODO: NEED TO PASS IN COLUMNS AND DETERMINE FROM THAT\n",
    "def segment_signal(dataset, window_size = 90, columns = 5):\n",
    "    segments = np.empty((0, window_size, columns))\n",
    "    labels = np.empty((0))\n",
    "    count = 0;\n",
    "    for (start, end) in windows(dataset[\"Timestamp\"], window_size):\n",
    "        temperature = dataset['Temperature'][start:end]\n",
    "        conductivity = dataset['Sp_Cond'][start:end]\n",
    "        turbidity = dataset['Turbidity'][start:end]\n",
    "        ph = dataset['pH'][start:end]\n",
    "        odo = dataset['ODO'][start:end]\n",
    "        if(len(dataset['Timestamp'][start:end]) == window_size):\n",
    "            segments = np.vstack([segments, np.dstack([temperature, conductivity, turbidity, ph, odo])])\n",
    "            labels = np.append(labels, stats.mode(dataset['BGA_Phycocyanin_RFU'][start:end])[0][0])\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Sp_Cond</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>ODO</th>\n",
       "      <th>BGA_Phycocyanin_RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.493960e+09</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493961e+09</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.493962e+09</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.493963e+09</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493964e+09</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  Temperature  Sp_Cond    pH  Turbidity   ODO  \\\n",
       "0  1.493960e+09        15.02     1848  8.36      16.84  9.04   \n",
       "1  1.493961e+09        14.99     1847  8.36      16.76  9.04   \n",
       "2  1.493962e+09        14.96     1847  8.36      16.82  9.04   \n",
       "3  1.493963e+09        14.95     1848  8.36      17.19  9.03   \n",
       "4  1.493964e+09        14.92     1848  8.36      16.85  9.02   \n",
       "\n",
       "   BGA_Phycocyanin_RFU  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Timestamp', 'Temperature', 'Sp_Cond', 'pH_mV', 'pH', 'Turbidity', 'Chlorophyll', 'Chlorophyll_RFU',\n",
    "        'ODOSat', 'ODO', 'BGA_Phycocyanin_RFU']\n",
    "\n",
    "cols_to_keep = []\n",
    "cols_to_keep.append('Timestamp')\n",
    "cols_to_keep.append('Temperature')\n",
    "cols_to_keep.append('Sp_Cond')\n",
    "# cols_to_keep.append('pH_mV')\n",
    "cols_to_keep.append('pH')\n",
    "cols_to_keep.append('Turbidity')\n",
    "# cols_to_keep.append('Chlorophyll')\n",
    "# cols_to_keep.append('Chlorophyll_RFU')\n",
    "# cols_to_keep.append('ODOSat')\n",
    "cols_to_keep.append('ODO')\n",
    "cols_to_keep.append('BGA_Phycocyanin_RFU')\n",
    "\n",
    "lake_dataset = read_data('./data/cleaned/utah_lake_vineyard.csv', cols) \n",
    "\n",
    "for col in cols:\n",
    "    if col not in cols_to_keep:\n",
    "        lake_dataset = lake_dataset.drop(col, axis=1)\n",
    "        \n",
    "lake_dataset = convert_timestamp(lake_dataset)\n",
    "lake_dataset = convert_BGA_RFU(lake_dataset, 1.0)\n",
    "lake_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 32\n",
    "columns = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 0.34% done\n",
      "Window Segmentation 0.68% done\n",
      "Window Segmentation 1.01% done\n",
      "Window Segmentation 1.35% done\n",
      "Window Segmentation 1.69% done\n",
      "Window Segmentation 2.03% done\n",
      "Window Segmentation 2.36% done\n",
      "Window Segmentation 2.70% done\n",
      "Window Segmentation 3.04% done\n",
      "Window Segmentation 3.38% done\n",
      "Window Segmentation 3.72% done\n",
      "Window Segmentation 4.05% done\n",
      "Window Segmentation 4.39% done\n",
      "Window Segmentation 4.73% done\n",
      "Window Segmentation 5.07% done\n",
      "Window Segmentation 5.40% done\n",
      "Window Segmentation 5.74% done\n",
      "Window Segmentation 6.08% done\n",
      "Window Segmentation 6.42% done\n",
      "Window Segmentation 6.76% done\n",
      "Window Segmentation 7.09% done\n",
      "Window Segmentation 7.43% done\n",
      "Window Segmentation 7.77% done\n",
      "Window Segmentation 8.11% done\n",
      "Window Segmentation 8.44% done\n",
      "Window Segmentation 8.78% done\n",
      "Window Segmentation 9.12% done\n",
      "Window Segmentation 9.46% done\n",
      "Window Segmentation 9.80% done\n",
      "Window Segmentation 10.13% done\n",
      "Window Segmentation 10.47% done\n",
      "Window Segmentation 10.81% done\n",
      "Window Segmentation 11.15% done\n",
      "Window Segmentation 11.48% done\n",
      "Window Segmentation 11.82% done\n",
      "Window Segmentation 12.16% done\n",
      "Window Segmentation 12.50% done\n",
      "Window Segmentation 12.84% done\n",
      "Window Segmentation 13.17% done\n",
      "Window Segmentation 13.51% done\n",
      "Window Segmentation 13.85% done\n",
      "Window Segmentation 14.19% done\n",
      "Window Segmentation 14.52% done\n",
      "Window Segmentation 14.86% done\n",
      "Window Segmentation 15.20% done\n",
      "Window Segmentation 15.54% done\n",
      "Window Segmentation 15.88% done\n",
      "Window Segmentation 16.21% done\n",
      "Window Segmentation 16.55% done\n",
      "Window Segmentation 16.89% done\n",
      "Window Segmentation 17.23% done\n",
      "Window Segmentation 17.56% done\n",
      "Window Segmentation 17.90% done\n",
      "Window Segmentation 18.24% done\n",
      "Window Segmentation 18.58% done\n",
      "Window Segmentation 18.92% done\n",
      "Window Segmentation 19.25% done\n",
      "Window Segmentation 19.59% done\n",
      "Window Segmentation 19.93% done\n",
      "Window Segmentation 20.27% done\n",
      "Window Segmentation 20.60% done\n",
      "Window Segmentation 20.94% done\n",
      "Window Segmentation 21.28% done\n",
      "Window Segmentation 21.62% done\n",
      "Window Segmentation 21.96% done\n",
      "Window Segmentation 22.29% done\n",
      "Window Segmentation 22.63% done\n",
      "Window Segmentation 22.97% done\n",
      "Window Segmentation 23.31% done\n",
      "Window Segmentation 23.64% done\n",
      "Window Segmentation 23.98% done\n",
      "Window Segmentation 24.32% done\n",
      "Window Segmentation 24.66% done\n",
      "Window Segmentation 25.00% done\n",
      "Window Segmentation 25.33% done\n",
      "Window Segmentation 25.67% done\n",
      "Window Segmentation 26.01% done\n",
      "Window Segmentation 26.35% done\n",
      "Window Segmentation 26.68% done\n",
      "Window Segmentation 27.02% done\n",
      "Window Segmentation 27.36% done\n",
      "Window Segmentation 27.70% done\n",
      "Window Segmentation 28.04% done\n",
      "Window Segmentation 28.37% done\n",
      "Window Segmentation 28.71% done\n",
      "Window Segmentation 29.05% done\n",
      "Window Segmentation 29.39% done\n",
      "Window Segmentation 29.73% done\n",
      "Window Segmentation 30.06% done\n",
      "Window Segmentation 30.40% done\n",
      "Window Segmentation 30.74% done\n",
      "Window Segmentation 31.08% done\n",
      "Window Segmentation 31.41% done\n",
      "Window Segmentation 31.75% done\n",
      "Window Segmentation 32.09% done\n",
      "Window Segmentation 32.43% done\n",
      "Window Segmentation 32.77% done\n",
      "Window Segmentation 33.10% done\n",
      "Window Segmentation 33.44% done\n",
      "Window Segmentation 33.78% done\n",
      "Window Segmentation 34.12% done\n",
      "Window Segmentation 34.45% done\n",
      "Window Segmentation 34.79% done\n",
      "Window Segmentation 35.13% done\n",
      "Window Segmentation 35.47% done\n",
      "Window Segmentation 35.81% done\n",
      "Window Segmentation 36.14% done\n",
      "Window Segmentation 36.48% done\n",
      "Window Segmentation 36.82% done\n",
      "Window Segmentation 37.16% done\n",
      "Window Segmentation 37.49% done\n",
      "Window Segmentation 37.83% done\n",
      "Window Segmentation 38.17% done\n",
      "Window Segmentation 38.51% done\n",
      "Window Segmentation 38.85% done\n",
      "Window Segmentation 39.18% done\n",
      "Window Segmentation 39.52% done\n",
      "Window Segmentation 39.86% done\n",
      "Window Segmentation 40.20% done\n",
      "Window Segmentation 40.53% done\n",
      "Window Segmentation 40.87% done\n",
      "Window Segmentation 41.21% done\n",
      "Window Segmentation 41.55% done\n",
      "Window Segmentation 41.89% done\n",
      "Window Segmentation 42.22% done\n",
      "Window Segmentation 42.56% done\n",
      "Window Segmentation 42.90% done\n",
      "Window Segmentation 43.24% done\n",
      "Window Segmentation 43.57% done\n",
      "Window Segmentation 43.91% done\n",
      "Window Segmentation 44.25% done\n",
      "Window Segmentation 44.59% done\n",
      "Window Segmentation 44.93% done\n",
      "Window Segmentation 45.26% done\n",
      "Window Segmentation 45.60% done\n",
      "Window Segmentation 45.94% done\n",
      "Window Segmentation 46.28% done\n",
      "Window Segmentation 46.61% done\n",
      "Window Segmentation 46.95% done\n",
      "Window Segmentation 47.29% done\n",
      "Window Segmentation 47.63% done\n",
      "Window Segmentation 47.97% done\n",
      "Window Segmentation 48.30% done\n",
      "Window Segmentation 48.64% done\n",
      "Window Segmentation 48.98% done\n",
      "Window Segmentation 49.32% done\n",
      "Window Segmentation 49.65% done\n",
      "Window Segmentation 49.99% done\n",
      "Window Segmentation 50.33% done\n",
      "Window Segmentation 50.67% done\n",
      "Window Segmentation 51.01% done\n",
      "Window Segmentation 51.34% done\n",
      "Window Segmentation 51.68% done\n",
      "Window Segmentation 52.02% done\n",
      "Window Segmentation 52.36% done\n",
      "Window Segmentation 52.69% done\n",
      "Window Segmentation 53.03% done\n",
      "Window Segmentation 53.37% done\n",
      "Window Segmentation 53.71% done\n",
      "Window Segmentation 54.05% done\n",
      "Window Segmentation 54.38% done\n",
      "Window Segmentation 54.72% done\n",
      "Window Segmentation 55.06% done\n",
      "Window Segmentation 55.40% done\n",
      "Window Segmentation 55.73% done\n",
      "Window Segmentation 56.07% done\n",
      "Window Segmentation 56.41% done\n",
      "Window Segmentation 56.75% done\n",
      "Window Segmentation 57.09% done\n",
      "Window Segmentation 57.42% done\n",
      "Window Segmentation 57.76% done\n",
      "Window Segmentation 58.10% done\n",
      "Window Segmentation 58.44% done\n",
      "Window Segmentation 58.77% done\n",
      "Window Segmentation 59.11% done\n",
      "Window Segmentation 59.45% done\n",
      "Window Segmentation 59.79% done\n",
      "Window Segmentation 60.13% done\n",
      "Window Segmentation 60.46% done\n",
      "Window Segmentation 60.80% done\n",
      "Window Segmentation 61.14% done\n",
      "Window Segmentation 61.48% done\n",
      "Window Segmentation 61.81% done\n",
      "Window Segmentation 62.15% done\n",
      "Window Segmentation 62.49% done\n",
      "Window Segmentation 62.83% done\n",
      "Window Segmentation 63.17% done\n",
      "Window Segmentation 63.50% done\n",
      "Window Segmentation 63.84% done\n",
      "Window Segmentation 64.18% done\n",
      "Window Segmentation 64.52% done\n",
      "Window Segmentation 64.85% done\n",
      "Window Segmentation 65.19% done\n",
      "Window Segmentation 65.53% done\n",
      "Window Segmentation 65.87% done\n",
      "Window Segmentation 66.21% done\n",
      "Window Segmentation 66.54% done\n",
      "Window Segmentation 66.88% done\n",
      "Window Segmentation 67.22% done\n",
      "Window Segmentation 67.56% done\n",
      "Window Segmentation 67.89% done\n",
      "Window Segmentation 68.23% done\n",
      "Window Segmentation 68.57% done\n",
      "Window Segmentation 68.91% done\n",
      "Window Segmentation 69.25% done\n",
      "Window Segmentation 69.58% done\n",
      "Window Segmentation 69.92% done\n",
      "Window Segmentation 70.26% done\n",
      "Window Segmentation 70.60% done\n",
      "Window Segmentation 70.93% done\n",
      "Window Segmentation 71.27% done\n",
      "Window Segmentation 71.61% done\n",
      "Window Segmentation 71.95% done\n",
      "Window Segmentation 72.29% done\n",
      "Window Segmentation 72.62% done\n",
      "Window Segmentation 72.96% done\n",
      "Window Segmentation 73.30% done\n",
      "Window Segmentation 73.64% done\n",
      "Window Segmentation 73.97% done\n",
      "Window Segmentation 74.31% done\n",
      "Window Segmentation 74.65% done\n",
      "Window Segmentation 74.99% done\n",
      "Window Segmentation 75.33% done\n",
      "Window Segmentation 75.66% done\n",
      "Window Segmentation 76.00% done\n",
      "Window Segmentation 76.34% done\n",
      "Window Segmentation 76.68% done\n",
      "Window Segmentation 77.01% done\n",
      "Window Segmentation 77.35% done\n",
      "Window Segmentation 77.69% done\n",
      "Window Segmentation 78.03% done\n",
      "Window Segmentation 78.37% done\n",
      "Window Segmentation 78.70% done\n",
      "Window Segmentation 79.04% done\n",
      "Window Segmentation 79.38% done\n",
      "Window Segmentation 79.72% done\n",
      "Window Segmentation 80.05% done\n",
      "Window Segmentation 80.39% done\n",
      "Window Segmentation 80.73% done\n",
      "Window Segmentation 81.07% done\n",
      "Window Segmentation 81.41% done\n",
      "Window Segmentation 81.74% done\n",
      "Window Segmentation 82.08% done\n",
      "Window Segmentation 82.42% done\n",
      "Window Segmentation 82.76% done\n",
      "Window Segmentation 83.09% done\n",
      "Window Segmentation 83.43% done\n",
      "Window Segmentation 83.77% done\n",
      "Window Segmentation 84.11% done\n",
      "Window Segmentation 84.45% done\n",
      "Window Segmentation 84.78% done\n",
      "Window Segmentation 85.12% done\n",
      "Window Segmentation 85.46% done\n",
      "Window Segmentation 85.80% done\n",
      "Window Segmentation 86.14% done\n",
      "Window Segmentation 86.47% done\n",
      "Window Segmentation 86.81% done\n",
      "Window Segmentation 87.15% done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 87.49% done\n",
      "Window Segmentation 87.82% done\n",
      "Window Segmentation 88.16% done\n",
      "Window Segmentation 88.50% done\n",
      "Window Segmentation 88.84% done\n",
      "Window Segmentation 89.18% done\n",
      "Window Segmentation 89.51% done\n",
      "Window Segmentation 89.85% done\n",
      "Window Segmentation 90.19% done\n",
      "Window Segmentation 90.53% done\n",
      "Window Segmentation 90.86% done\n",
      "Window Segmentation 91.20% done\n",
      "Window Segmentation 91.54% done\n",
      "Window Segmentation 91.88% done\n",
      "Window Segmentation 92.22% done\n",
      "Window Segmentation 92.55% done\n",
      "Window Segmentation 92.89% done\n",
      "Window Segmentation 93.23% done\n",
      "Window Segmentation 93.57% done\n",
      "Window Segmentation 93.90% done\n",
      "Window Segmentation 94.24% done\n",
      "Window Segmentation 94.58% done\n",
      "Window Segmentation 94.92% done\n",
      "Window Segmentation 95.26% done\n",
      "Window Segmentation 95.59% done\n",
      "Window Segmentation 95.93% done\n",
      "Window Segmentation 96.27% done\n",
      "Window Segmentation 96.61% done\n",
      "Window Segmentation 96.94% done\n",
      "Window Segmentation 97.28% done\n",
      "Window Segmentation 97.62% done\n",
      "Window Segmentation 97.96% done\n",
      "Window Segmentation 98.30% done\n",
      "Window Segmentation 98.63% done\n",
      "Window Segmentation 98.97% done\n",
      "Window Segmentation 99.31% done\n",
      "Window Segmentation 99.65% done\n",
      "Window Segmentation 99.98% done\n"
     ]
    }
   ],
   "source": [
    "segments, labels = segment_signal(lake_dataset, window_size, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.asarray(pd.get_dummies(labels), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2955, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ..., \n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18947, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2955, 32, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Args: \n",
    "reshaped_segments = segments.reshape(len(segments), 1, window_size, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2955, 1, 32, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split = np.random.rand(len(reshaped_segments)) < 0.70\n",
    "train_x = reshaped_segments[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = reshaped_segments[~train_test_split]\n",
    "test_y = labels[~train_test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_height = 1\n",
    "input_width = window_size\n",
    "num_labels = 2\n",
    "num_channels = columns\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 5\n",
    "\n",
    "total_batchs = train_x.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=[None,input_height,input_width,columns])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,num_labels])\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    print (shape)\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 2, 1],\n",
    "                          strides=[1, 1, 2, 1], padding='VALID')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 5, 32]\n"
     ]
    }
   ],
   "source": [
    "convo_1 = convolutional_layer(X,shape=[1,4,5,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 32, 64]\n"
     ]
    }
   ],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[1,4,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,1*8*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512, 128]\n"
     ]
    }
   ],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 10]\n"
     ]
    }
   ],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_y,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension size must be evenly divisible by 10 but is 1664 for 'gradients/Reshape_1_grad/Reshape' (op: 'Reshape') with input shapes: [832,2], [2] and with input tensors computed as partial shapes: input[1] = [?,10].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1704\u001b[0m       raise ValueError(\"No attr named '\" + name + \"' in \" +\n\u001b[1;32m-> 1705\u001b[1;33m                        str(self._node_def))\n\u001b[0m\u001b[0;32m   1706\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_node_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No attr named '_XlaCompile' in name: \"Reshape_1\"\nop: \"Reshape\"\ninput: \"add_3\"\ninput: \"concat\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"Tshape\"\n  value {\n    type: DT_INT32\n  }\n}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension size must be evenly divisible by 10 but is 1664 for 'gradients/Reshape_1_grad/Reshape' (op: 'Reshape') with input shapes: [832,2], [2] and with input tensors computed as partial shapes: input[1] = [?,10].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-6af0689ba780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[0;32m    387\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[0;32m    540\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[1;32m--> 542\u001b[1;33m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    543\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    346\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaScope\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    540\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[1;32m--> 542\u001b[1;33m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    543\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reshape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_ReshapeGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   2617\u001b[0m   \"\"\"\n\u001b[0;32m   2618\u001b[0m   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\n\u001b[1;32m-> 2619\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m   2620\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2631\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2632\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension size must be evenly divisible by 10 but is 1664 for 'gradients/Reshape_1_grad/Reshape' (op: 'Reshape') with input shapes: [832,2], [2] and with input tensors computed as partial shapes: input[1] = [?,10]."
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,1,32,5]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,1,32,5], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-44-26494cb36a7f>\", line 1, in <module>\n    x = tf.placeholder(tf.float32,shape=[None,input_height,input_width,columns])\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,1,32,5]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,1,32,5], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,1,32,5]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,1,32,5], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-3bedb67b8920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#             print(batch_y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m#             cost_history = np.append(cost_history,c)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#         print (\"Epoch: \",epoch,\" Training Loss: \",np.mean(cost_history),\" Training Accuracy: \",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,1,32,5]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,1,32,5], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-44-26494cb36a7f>\", line 1, in <module>\n    x = tf.placeholder(tf.float32,shape=[None,input_height,input_width,columns])\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\MattS\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,1,32,5]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,1,32,5], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        cost_history = np.empty(shape=[1],dtype=float)\n",
    "        for b in range(total_batchs):    \n",
    "            offset = (b * batch_size) % (train_y.shape[0] - batch_size)\n",
    "            batch_x = train_x[offset:(offset + batch_size), :, :, :]\n",
    "            batch_y = train_y[offset:(offset + batch_size), :]\n",
    "#             print(batch_x.shape)\n",
    "#             print(batch_y.shape)\n",
    "\n",
    "            _, c = session.run(train,feed_dict={X: batch_x, Y : batch_y})\n",
    "            cost_history = np.append(cost_history,c)\n",
    "#         print (\"Epoch: \",epoch,\" Training Loss: \",np.mean(cost_history),\" Training Accuracy: \",\n",
    "#               session.run(accuracy, feed_dict={X: train_x, Y: train_y}))\n",
    "    \n",
    "#     print (\"Testing Accuracy:\", session.run(accuracy, feed_dict={X: test_x, Y: test_y}))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for i in range(5000):\n",
    "#         batch = ch.next_batch(100)\n",
    "#         sess.run(train, feed_dict={x: batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "        \n",
    "#         # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "#         if i%100 == 0:\n",
    "            \n",
    "#             print('Currently on step {}'.format(i))\n",
    "#             print('Accuracy is:')\n",
    "#             # Test the Train Model\n",
    "#             matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "#             acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "#             print(sess.run(acc,feed_dict={x:ch.test_images,y_true:ch.test_labels,hold_prob:1.0}))\n",
    "#             print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
