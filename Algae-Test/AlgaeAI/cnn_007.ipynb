{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccomackjp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path, column_names):\n",
    "    \"\"\"Reads the data from the specified file and retrieves the column names\n",
    "    \n",
    "    Args:\n",
    "        file_path: The path of the file as a String\n",
    "        column_names: Array of Strings representing the names of the colunms\n",
    "        \n",
    "    Returns:\n",
    "        A DataFrame of the read in data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path, header = 0, names = column_names)\n",
    "    return data\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    \"\"\"Normalizes the data in the DataFrame using the mean and sigma values\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame to normalize\n",
    "        \n",
    "    Returns:\n",
    "        The normalized data\n",
    "    \"\"\"\n",
    "    mu = np.mean(dataset, axis = 0)\n",
    "    sigma = np.std(dataset, axis = 0)\n",
    "    return (dataset - mu) / sigma\n",
    "\n",
    "def basic_feature_normalize(dataset, cols_to_norm):\n",
    "    \"\"\"A Basic Normalization of the dataset\n",
    "    \n",
    "    Takes the dataset and normalizes it from 0 (min value) to 1 (max value)\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame to normalize\n",
    "        cols_to_norm: An Array of strings of the columns that need normalization\n",
    "        \n",
    "    Returns:\n",
    "        The normalized dataset with the specified columns normalized between 0 and 1\n",
    "    \"\"\"\n",
    "    dataset[cols_to_norm] = dataset[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "    return dataset\n",
    "\n",
    "def make_rgbs(dataset, cols_to_rgb):\n",
    "    \"\"\"Takes a dataset and converts specific columns into rgb values\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame to convert to rgb values\n",
    "        cols_to_rgb: An Arrya of strings of the columns that need to be converted\n",
    "        \n",
    "    Returns:\n",
    "        The dataset with the specified columns converted to rgb values\n",
    "    \"\"\"\n",
    "    dataset[cols_to_rgb] = dataset[cols_to_rgb].apply(lambda x: int(x * 255))\n",
    "    return dataset\n",
    "\n",
    "def convert_timestamp(dataset):\n",
    "    \"\"\"Converts the timestamp to a unix timestamp\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame with the timestamp column to convert to unix\n",
    "        \n",
    "    Returns:\n",
    "        The dataset with the converted timestamp\n",
    "    \"\"\"\n",
    "    dataset['Timestamp'] = dataset['Timestamp'].apply(lambda x:\n",
    "                                                     datetime.strptime(x, '%m/%d/%y %H:%M').timestamp())\n",
    "    return dataset\n",
    "\n",
    "def convert_BGA_RFU(dataset, threshold):\n",
    "    \"\"\"Converts the BGA_Phycocyanin_RFU column to a true or false value (represented by 1 or 0)\n",
    "       based on the threshold value\n",
    "       \n",
    "    Args:\n",
    "        dataset: The DataFrame with the BGA_Phycocyanin_RFU value to be adjusted\n",
    "        threshold: The minimum value for an algae bloom to be true\n",
    "        \n",
    "    Returns:\n",
    "        The dataset with the converted BGA_RFU value\"\"\"\n",
    "    dataset['BGA_Phycocyanin_RFU'] = dataset['BGA_Phycocyanin_RFU'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We step 50% down based on window size\n",
    "def windows(data, size):\n",
    "    counter_output = 0\n",
    "    start = 0\n",
    "    while start < data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start += (size / 12)\n",
    "        counter_output += 1\n",
    "        if counter_output % 10 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format((start / data.count()) * 100))\n",
    "    \n",
    "# 32 chosen for 8 hours of 15 minute intervals\n",
    "# TODO: NEED TO PASS IN COLUMNS AND DETERMINE FROM THAT\n",
    "def segment_signal(dataset, window_size = 90, columns = 5):\n",
    "    segments = np.empty((0, window_size, columns))\n",
    "    labels = np.empty((0))\n",
    "    count = 0;\n",
    "    for (start, end) in windows(dataset[\"Timestamp\"], window_size):\n",
    "        temperature = dataset['Temperature'][start:end]\n",
    "        conductivity = dataset['Sp_Cond'][start:end]\n",
    "        turbidity = dataset['Turbidity'][start:end]\n",
    "#         ph = dataset['pH'][start:end]\n",
    "        odo = dataset['ODO'][start:end]\n",
    "        if(len(dataset['Timestamp'][start:end]) == window_size):\n",
    "            segments = np.vstack([segments, np.dstack([temperature, conductivity, turbidity, odo])])\n",
    "            labels = np.append(labels, stats.mode(dataset['BGA_Phycocyanin_RFU'][start:end])[0][0])\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Lake_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Sp_Cond</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>ODO</th>\n",
       "      <th>BGA_Phycocyanin_RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.493960e+09</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>16.84</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493961e+09</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>16.76</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.493962e+09</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>16.82</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.493963e+09</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>17.19</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493964e+09</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>16.85</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  Temperature  Sp_Cond  Turbidity   ODO  BGA_Phycocyanin_RFU\n",
       "0  1.493960e+09        15.02     1848      16.84  9.04                  0.4\n",
       "1  1.493961e+09        14.99     1847      16.76  9.04                  0.4\n",
       "2  1.493962e+09        14.96     1847      16.82  9.04                  0.4\n",
       "3  1.493963e+09        14.95     1848      17.19  9.03                  0.4\n",
       "4  1.493964e+09        14.92     1848      16.85  9.02                  0.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Timestamp', 'Temperature', 'Sp_Cond', 'pH_mV', 'pH', 'Turbidity', 'Chlorophyll', 'Chlorophyll_RFU',\n",
    "        'ODOSat', 'ODO', 'BGA_Phycocyanin_RFU']\n",
    "\n",
    "cols_to_keep = []\n",
    "cols_to_keep.append('Timestamp')\n",
    "cols_to_keep.append('Temperature')\n",
    "cols_to_keep.append('Sp_Cond')\n",
    "# cols_to_keep.append('pH_mV')\n",
    "# cols_to_keep.append('pH')\n",
    "cols_to_keep.append('Turbidity')\n",
    "# cols_to_keep.append('Chlorophyll')\n",
    "# cols_to_keep.append('Chlorophyll_RFU')\n",
    "# cols_to_keep.append('ODOSat')\n",
    "cols_to_keep.append('ODO')\n",
    "cols_to_keep.append('BGA_Phycocyanin_RFU')\n",
    "\n",
    "lake_dataset = read_data('./data/cleaned/utah_lake_vineyard.csv', cols) \n",
    "\n",
    "for col in cols:\n",
    "    if col not in cols_to_keep:\n",
    "        lake_dataset = lake_dataset.drop(col, axis=1)\n",
    "        \n",
    "lake_dataset = convert_timestamp(lake_dataset)\n",
    "lake_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_dataset = convert_BGA_RFU(lake_dataset, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lake_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Sp_Cond</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>ODO</th>\n",
       "      <th>BGA_Phycocyanin_RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.493960e+09</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>16.84</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493961e+09</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>16.76</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.493962e+09</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>16.82</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.493963e+09</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>17.19</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493964e+09</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>16.85</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  Temperature  Sp_Cond  Turbidity   ODO  BGA_Phycocyanin_RFU\n",
       "0  1.493960e+09        15.02     1848      16.84  9.04                    0\n",
       "1  1.493961e+09        14.99     1847      16.76  9.04                    0\n",
       "2  1.493962e+09        14.96     1847      16.82  9.04                    0\n",
       "3  1.493963e+09        14.95     1848      17.19  9.03                    0\n",
       "4  1.493964e+09        14.92     1848      16.85  9.02                    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Sp_Cond</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>ODO</th>\n",
       "      <th>BGA_Phycocyanin_RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.493960e+09</td>\n",
       "      <td>0.409329</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493961e+09</td>\n",
       "      <td>0.408021</td>\n",
       "      <td>0.853309</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.493962e+09</td>\n",
       "      <td>0.406713</td>\n",
       "      <td>0.853309</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.493963e+09</td>\n",
       "      <td>0.406277</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>0.350909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493964e+09</td>\n",
       "      <td>0.404969</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.025454</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  Temperature   Sp_Cond  Turbidity       ODO  \\\n",
       "0  1.493960e+09     0.409329  0.853771   0.025439  0.351818   \n",
       "1  1.493961e+09     0.408021  0.853309   0.025313  0.351818   \n",
       "2  1.493962e+09     0.406713  0.853309   0.025407  0.351818   \n",
       "3  1.493963e+09     0.406277  0.853771   0.025989  0.350909   \n",
       "4  1.493964e+09     0.404969  0.853771   0.025454  0.350000   \n",
       "\n",
       "   BGA_Phycocyanin_RFU  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset = basic_feature_normalize(lake_dataset, ['Temperature', 'Sp_Cond', 'Turbidity', 'ODO'])\n",
    "normalized_lake_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset['Temperature'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset['Temperature'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset['BGA_Phycocyanin_RFU'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18947, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(normalized_lake_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the segments and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 0.16% done\n",
      "Window Segmentation 0.32% done\n",
      "Window Segmentation 0.48% done\n",
      "Window Segmentation 0.63% done\n",
      "Window Segmentation 0.79% done\n",
      "Window Segmentation 0.95% done\n",
      "Window Segmentation 1.11% done\n",
      "Window Segmentation 1.27% done\n",
      "Window Segmentation 1.43% done\n",
      "Window Segmentation 1.58% done\n",
      "Window Segmentation 1.74% done\n",
      "Window Segmentation 1.90% done\n",
      "Window Segmentation 2.06% done\n",
      "Window Segmentation 2.22% done\n",
      "Window Segmentation 2.38% done\n",
      "Window Segmentation 2.53% done\n",
      "Window Segmentation 2.69% done\n",
      "Window Segmentation 2.85% done\n",
      "Window Segmentation 3.01% done\n",
      "Window Segmentation 3.17% done\n",
      "Window Segmentation 3.33% done\n",
      "Window Segmentation 3.48% done\n",
      "Window Segmentation 3.64% done\n",
      "Window Segmentation 3.80% done\n",
      "Window Segmentation 3.96% done\n",
      "Window Segmentation 4.12% done\n",
      "Window Segmentation 4.28% done\n",
      "Window Segmentation 4.43% done\n",
      "Window Segmentation 4.59% done\n",
      "Window Segmentation 4.75% done\n",
      "Window Segmentation 4.91% done\n",
      "Window Segmentation 5.07% done\n",
      "Window Segmentation 5.23% done\n",
      "Window Segmentation 5.38% done\n",
      "Window Segmentation 5.54% done\n",
      "Window Segmentation 5.70% done\n",
      "Window Segmentation 5.86% done\n",
      "Window Segmentation 6.02% done\n",
      "Window Segmentation 6.18% done\n",
      "Window Segmentation 6.33% done\n",
      "Window Segmentation 6.49% done\n",
      "Window Segmentation 6.65% done\n",
      "Window Segmentation 6.81% done\n",
      "Window Segmentation 6.97% done\n",
      "Window Segmentation 7.13% done\n",
      "Window Segmentation 7.28% done\n",
      "Window Segmentation 7.44% done\n",
      "Window Segmentation 7.60% done\n",
      "Window Segmentation 7.76% done\n",
      "Window Segmentation 7.92% done\n",
      "Window Segmentation 8.08% done\n",
      "Window Segmentation 8.23% done\n",
      "Window Segmentation 8.39% done\n",
      "Window Segmentation 8.55% done\n",
      "Window Segmentation 8.71% done\n",
      "Window Segmentation 8.87% done\n",
      "Window Segmentation 9.03% done\n",
      "Window Segmentation 9.18% done\n",
      "Window Segmentation 9.34% done\n",
      "Window Segmentation 9.50% done\n",
      "Window Segmentation 9.66% done\n",
      "Window Segmentation 9.82% done\n",
      "Window Segmentation 9.98% done\n",
      "Window Segmentation 10.13% done\n",
      "Window Segmentation 10.29% done\n",
      "Window Segmentation 10.45% done\n",
      "Window Segmentation 10.61% done\n",
      "Window Segmentation 10.77% done\n",
      "Window Segmentation 10.93% done\n",
      "Window Segmentation 11.08% done\n",
      "Window Segmentation 11.24% done\n",
      "Window Segmentation 11.40% done\n",
      "Window Segmentation 11.56% done\n",
      "Window Segmentation 11.72% done\n",
      "Window Segmentation 11.88% done\n",
      "Window Segmentation 12.03% done\n",
      "Window Segmentation 12.19% done\n",
      "Window Segmentation 12.35% done\n",
      "Window Segmentation 12.51% done\n",
      "Window Segmentation 12.67% done\n",
      "Window Segmentation 12.83% done\n",
      "Window Segmentation 12.98% done\n",
      "Window Segmentation 13.14% done\n",
      "Window Segmentation 13.30% done\n",
      "Window Segmentation 13.46% done\n",
      "Window Segmentation 13.62% done\n",
      "Window Segmentation 13.78% done\n",
      "Window Segmentation 13.93% done\n",
      "Window Segmentation 14.09% done\n",
      "Window Segmentation 14.25% done\n",
      "Window Segmentation 14.41% done\n",
      "Window Segmentation 14.57% done\n",
      "Window Segmentation 14.73% done\n",
      "Window Segmentation 14.88% done\n",
      "Window Segmentation 15.04% done\n",
      "Window Segmentation 15.20% done\n",
      "Window Segmentation 15.36% done\n",
      "Window Segmentation 15.52% done\n",
      "Window Segmentation 15.68% done\n",
      "Window Segmentation 15.83% done\n",
      "Window Segmentation 15.99% done\n",
      "Window Segmentation 16.15% done\n",
      "Window Segmentation 16.31% done\n",
      "Window Segmentation 16.47% done\n",
      "Window Segmentation 16.63% done\n",
      "Window Segmentation 16.78% done\n",
      "Window Segmentation 16.94% done\n",
      "Window Segmentation 17.10% done\n",
      "Window Segmentation 17.26% done\n",
      "Window Segmentation 17.42% done\n",
      "Window Segmentation 17.58% done\n",
      "Window Segmentation 17.73% done\n",
      "Window Segmentation 17.89% done\n",
      "Window Segmentation 18.05% done\n",
      "Window Segmentation 18.21% done\n",
      "Window Segmentation 18.37% done\n",
      "Window Segmentation 18.53% done\n",
      "Window Segmentation 18.68% done\n",
      "Window Segmentation 18.84% done\n",
      "Window Segmentation 19.00% done\n",
      "Window Segmentation 19.16% done\n",
      "Window Segmentation 19.32% done\n",
      "Window Segmentation 19.48% done\n",
      "Window Segmentation 19.63% done\n",
      "Window Segmentation 19.79% done\n",
      "Window Segmentation 19.95% done\n",
      "Window Segmentation 20.11% done\n",
      "Window Segmentation 20.27% done\n",
      "Window Segmentation 20.43% done\n",
      "Window Segmentation 20.58% done\n",
      "Window Segmentation 20.74% done\n",
      "Window Segmentation 20.90% done\n",
      "Window Segmentation 21.06% done\n",
      "Window Segmentation 21.22% done\n",
      "Window Segmentation 21.38% done\n",
      "Window Segmentation 21.53% done\n",
      "Window Segmentation 21.69% done\n",
      "Window Segmentation 21.85% done\n",
      "Window Segmentation 22.01% done\n",
      "Window Segmentation 22.17% done\n",
      "Window Segmentation 22.33% done\n",
      "Window Segmentation 22.48% done\n",
      "Window Segmentation 22.64% done\n",
      "Window Segmentation 22.80% done\n",
      "Window Segmentation 22.96% done\n",
      "Window Segmentation 23.12% done\n",
      "Window Segmentation 23.28% done\n",
      "Window Segmentation 23.43% done\n",
      "Window Segmentation 23.59% done\n",
      "Window Segmentation 23.75% done\n",
      "Window Segmentation 23.91% done\n",
      "Window Segmentation 24.07% done\n",
      "Window Segmentation 24.23% done\n",
      "Window Segmentation 24.38% done\n",
      "Window Segmentation 24.54% done\n",
      "Window Segmentation 24.70% done\n",
      "Window Segmentation 24.86% done\n",
      "Window Segmentation 25.02% done\n",
      "Window Segmentation 25.18% done\n",
      "Window Segmentation 25.33% done\n",
      "Window Segmentation 25.49% done\n",
      "Window Segmentation 25.65% done\n",
      "Window Segmentation 25.81% done\n",
      "Window Segmentation 25.97% done\n",
      "Window Segmentation 26.13% done\n",
      "Window Segmentation 26.28% done\n",
      "Window Segmentation 26.44% done\n",
      "Window Segmentation 26.60% done\n",
      "Window Segmentation 26.76% done\n",
      "Window Segmentation 26.92% done\n",
      "Window Segmentation 27.08% done\n",
      "Window Segmentation 27.23% done\n",
      "Window Segmentation 27.39% done\n",
      "Window Segmentation 27.55% done\n",
      "Window Segmentation 27.71% done\n",
      "Window Segmentation 27.87% done\n",
      "Window Segmentation 28.03% done\n",
      "Window Segmentation 28.18% done\n",
      "Window Segmentation 28.34% done\n",
      "Window Segmentation 28.50% done\n",
      "Window Segmentation 28.66% done\n",
      "Window Segmentation 28.82% done\n",
      "Window Segmentation 28.98% done\n",
      "Window Segmentation 29.13% done\n",
      "Window Segmentation 29.29% done\n",
      "Window Segmentation 29.45% done\n",
      "Window Segmentation 29.61% done\n",
      "Window Segmentation 29.77% done\n",
      "Window Segmentation 29.93% done\n",
      "Window Segmentation 30.08% done\n",
      "Window Segmentation 30.24% done\n",
      "Window Segmentation 30.40% done\n",
      "Window Segmentation 30.56% done\n",
      "Window Segmentation 30.72% done\n",
      "Window Segmentation 30.88% done\n",
      "Window Segmentation 31.03% done\n",
      "Window Segmentation 31.19% done\n",
      "Window Segmentation 31.35% done\n",
      "Window Segmentation 31.51% done\n",
      "Window Segmentation 31.67% done\n",
      "Window Segmentation 31.83% done\n",
      "Window Segmentation 31.98% done\n",
      "Window Segmentation 32.14% done\n",
      "Window Segmentation 32.30% done\n",
      "Window Segmentation 32.46% done\n",
      "Window Segmentation 32.62% done\n",
      "Window Segmentation 32.78% done\n",
      "Window Segmentation 32.93% done\n",
      "Window Segmentation 33.09% done\n",
      "Window Segmentation 33.25% done\n",
      "Window Segmentation 33.41% done\n",
      "Window Segmentation 33.57% done\n",
      "Window Segmentation 33.73% done\n",
      "Window Segmentation 33.88% done\n",
      "Window Segmentation 34.04% done\n",
      "Window Segmentation 34.20% done\n",
      "Window Segmentation 34.36% done\n",
      "Window Segmentation 34.52% done\n",
      "Window Segmentation 34.68% done\n",
      "Window Segmentation 34.83% done\n",
      "Window Segmentation 34.99% done\n",
      "Window Segmentation 35.15% done\n",
      "Window Segmentation 35.31% done\n",
      "Window Segmentation 35.47% done\n",
      "Window Segmentation 35.63% done\n",
      "Window Segmentation 35.78% done\n",
      "Window Segmentation 35.94% done\n",
      "Window Segmentation 36.10% done\n",
      "Window Segmentation 36.26% done\n",
      "Window Segmentation 36.42% done\n",
      "Window Segmentation 36.58% done\n",
      "Window Segmentation 36.73% done\n",
      "Window Segmentation 36.89% done\n",
      "Window Segmentation 37.05% done\n",
      "Window Segmentation 37.21% done\n",
      "Window Segmentation 37.37% done\n",
      "Window Segmentation 37.53% done\n",
      "Window Segmentation 37.68% done\n",
      "Window Segmentation 37.84% done\n",
      "Window Segmentation 38.00% done\n",
      "Window Segmentation 38.16% done\n",
      "Window Segmentation 38.32% done\n",
      "Window Segmentation 38.48% done\n",
      "Window Segmentation 38.63% done\n",
      "Window Segmentation 38.79% done\n",
      "Window Segmentation 38.95% done\n",
      "Window Segmentation 39.11% done\n",
      "Window Segmentation 39.27% done\n",
      "Window Segmentation 39.43% done\n",
      "Window Segmentation 39.58% done\n",
      "Window Segmentation 39.74% done\n",
      "Window Segmentation 39.90% done\n",
      "Window Segmentation 40.06% done\n",
      "Window Segmentation 40.22% done\n",
      "Window Segmentation 40.38% done\n",
      "Window Segmentation 40.53% done\n",
      "Window Segmentation 40.69% done\n",
      "Window Segmentation 40.85% done\n",
      "Window Segmentation 41.01% done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 41.17% done\n",
      "Window Segmentation 41.33% done\n",
      "Window Segmentation 41.48% done\n",
      "Window Segmentation 41.64% done\n",
      "Window Segmentation 41.80% done\n",
      "Window Segmentation 41.96% done\n",
      "Window Segmentation 42.12% done\n",
      "Window Segmentation 42.28% done\n",
      "Window Segmentation 42.43% done\n",
      "Window Segmentation 42.59% done\n",
      "Window Segmentation 42.75% done\n",
      "Window Segmentation 42.91% done\n",
      "Window Segmentation 43.07% done\n",
      "Window Segmentation 43.23% done\n",
      "Window Segmentation 43.38% done\n",
      "Window Segmentation 43.54% done\n",
      "Window Segmentation 43.70% done\n",
      "Window Segmentation 43.86% done\n",
      "Window Segmentation 44.02% done\n",
      "Window Segmentation 44.18% done\n",
      "Window Segmentation 44.33% done\n",
      "Window Segmentation 44.49% done\n",
      "Window Segmentation 44.65% done\n",
      "Window Segmentation 44.81% done\n",
      "Window Segmentation 44.97% done\n",
      "Window Segmentation 45.13% done\n",
      "Window Segmentation 45.28% done\n",
      "Window Segmentation 45.44% done\n",
      "Window Segmentation 45.60% done\n",
      "Window Segmentation 45.76% done\n",
      "Window Segmentation 45.92% done\n",
      "Window Segmentation 46.08% done\n",
      "Window Segmentation 46.23% done\n",
      "Window Segmentation 46.39% done\n",
      "Window Segmentation 46.55% done\n",
      "Window Segmentation 46.71% done\n",
      "Window Segmentation 46.87% done\n",
      "Window Segmentation 47.03% done\n",
      "Window Segmentation 47.18% done\n",
      "Window Segmentation 47.34% done\n",
      "Window Segmentation 47.50% done\n",
      "Window Segmentation 47.66% done\n",
      "Window Segmentation 47.82% done\n",
      "Window Segmentation 47.98% done\n",
      "Window Segmentation 48.13% done\n",
      "Window Segmentation 48.29% done\n",
      "Window Segmentation 48.45% done\n",
      "Window Segmentation 48.61% done\n",
      "Window Segmentation 48.77% done\n",
      "Window Segmentation 48.93% done\n",
      "Window Segmentation 49.08% done\n",
      "Window Segmentation 49.24% done\n",
      "Window Segmentation 49.40% done\n",
      "Window Segmentation 49.56% done\n",
      "Window Segmentation 49.72% done\n",
      "Window Segmentation 49.88% done\n",
      "Window Segmentation 50.03% done\n",
      "Window Segmentation 50.19% done\n",
      "Window Segmentation 50.35% done\n",
      "Window Segmentation 50.51% done\n",
      "Window Segmentation 50.67% done\n",
      "Window Segmentation 50.83% done\n",
      "Window Segmentation 50.98% done\n",
      "Window Segmentation 51.14% done\n",
      "Window Segmentation 51.30% done\n",
      "Window Segmentation 51.46% done\n",
      "Window Segmentation 51.62% done\n",
      "Window Segmentation 51.78% done\n",
      "Window Segmentation 51.93% done\n",
      "Window Segmentation 52.09% done\n",
      "Window Segmentation 52.25% done\n",
      "Window Segmentation 52.41% done\n",
      "Window Segmentation 52.57% done\n",
      "Window Segmentation 52.73% done\n",
      "Window Segmentation 52.88% done\n",
      "Window Segmentation 53.04% done\n",
      "Window Segmentation 53.20% done\n",
      "Window Segmentation 53.36% done\n",
      "Window Segmentation 53.52% done\n",
      "Window Segmentation 53.68% done\n",
      "Window Segmentation 53.83% done\n",
      "Window Segmentation 53.99% done\n",
      "Window Segmentation 54.15% done\n",
      "Window Segmentation 54.31% done\n",
      "Window Segmentation 54.47% done\n",
      "Window Segmentation 54.63% done\n",
      "Window Segmentation 54.78% done\n",
      "Window Segmentation 54.94% done\n",
      "Window Segmentation 55.10% done\n",
      "Window Segmentation 55.26% done\n",
      "Window Segmentation 55.42% done\n",
      "Window Segmentation 55.58% done\n",
      "Window Segmentation 55.73% done\n",
      "Window Segmentation 55.89% done\n",
      "Window Segmentation 56.05% done\n",
      "Window Segmentation 56.21% done\n",
      "Window Segmentation 56.37% done\n",
      "Window Segmentation 56.53% done\n",
      "Window Segmentation 56.68% done\n",
      "Window Segmentation 56.84% done\n",
      "Window Segmentation 57.00% done\n",
      "Window Segmentation 57.16% done\n",
      "Window Segmentation 57.32% done\n",
      "Window Segmentation 57.48% done\n",
      "Window Segmentation 57.63% done\n",
      "Window Segmentation 57.79% done\n",
      "Window Segmentation 57.95% done\n",
      "Window Segmentation 58.11% done\n",
      "Window Segmentation 58.27% done\n",
      "Window Segmentation 58.43% done\n",
      "Window Segmentation 58.58% done\n",
      "Window Segmentation 58.74% done\n",
      "Window Segmentation 58.90% done\n",
      "Window Segmentation 59.06% done\n",
      "Window Segmentation 59.22% done\n",
      "Window Segmentation 59.38% done\n",
      "Window Segmentation 59.53% done\n",
      "Window Segmentation 59.69% done\n",
      "Window Segmentation 59.85% done\n",
      "Window Segmentation 60.01% done\n",
      "Window Segmentation 60.17% done\n",
      "Window Segmentation 60.33% done\n",
      "Window Segmentation 60.48% done\n",
      "Window Segmentation 60.64% done\n",
      "Window Segmentation 60.80% done\n",
      "Window Segmentation 60.96% done\n",
      "Window Segmentation 61.12% done\n",
      "Window Segmentation 61.28% done\n",
      "Window Segmentation 61.43% done\n",
      "Window Segmentation 61.59% done\n",
      "Window Segmentation 61.75% done\n",
      "Window Segmentation 61.91% done\n",
      "Window Segmentation 62.07% done\n",
      "Window Segmentation 62.23% done\n",
      "Window Segmentation 62.38% done\n",
      "Window Segmentation 62.54% done\n",
      "Window Segmentation 62.70% done\n",
      "Window Segmentation 62.86% done\n",
      "Window Segmentation 63.02% done\n",
      "Window Segmentation 63.18% done\n",
      "Window Segmentation 63.33% done\n",
      "Window Segmentation 63.49% done\n",
      "Window Segmentation 63.65% done\n",
      "Window Segmentation 63.81% done\n",
      "Window Segmentation 63.97% done\n",
      "Window Segmentation 64.13% done\n",
      "Window Segmentation 64.28% done\n",
      "Window Segmentation 64.44% done\n",
      "Window Segmentation 64.60% done\n",
      "Window Segmentation 64.76% done\n",
      "Window Segmentation 64.92% done\n",
      "Window Segmentation 65.08% done\n",
      "Window Segmentation 65.23% done\n",
      "Window Segmentation 65.39% done\n",
      "Window Segmentation 65.55% done\n",
      "Window Segmentation 65.71% done\n",
      "Window Segmentation 65.87% done\n",
      "Window Segmentation 66.03% done\n",
      "Window Segmentation 66.18% done\n",
      "Window Segmentation 66.34% done\n",
      "Window Segmentation 66.50% done\n",
      "Window Segmentation 66.66% done\n",
      "Window Segmentation 66.82% done\n",
      "Window Segmentation 66.98% done\n",
      "Window Segmentation 67.13% done\n",
      "Window Segmentation 67.29% done\n",
      "Window Segmentation 67.45% done\n",
      "Window Segmentation 67.61% done\n",
      "Window Segmentation 67.77% done\n",
      "Window Segmentation 67.93% done\n",
      "Window Segmentation 68.08% done\n",
      "Window Segmentation 68.24% done\n",
      "Window Segmentation 68.40% done\n",
      "Window Segmentation 68.56% done\n",
      "Window Segmentation 68.72% done\n",
      "Window Segmentation 68.88% done\n",
      "Window Segmentation 69.03% done\n",
      "Window Segmentation 69.19% done\n",
      "Window Segmentation 69.35% done\n",
      "Window Segmentation 69.51% done\n",
      "Window Segmentation 69.67% done\n",
      "Window Segmentation 69.83% done\n",
      "Window Segmentation 69.98% done\n",
      "Window Segmentation 70.14% done\n",
      "Window Segmentation 70.30% done\n",
      "Window Segmentation 70.46% done\n",
      "Window Segmentation 70.62% done\n",
      "Window Segmentation 70.78% done\n",
      "Window Segmentation 70.93% done\n",
      "Window Segmentation 71.09% done\n",
      "Window Segmentation 71.25% done\n",
      "Window Segmentation 71.41% done\n",
      "Window Segmentation 71.57% done\n",
      "Window Segmentation 71.73% done\n",
      "Window Segmentation 71.88% done\n",
      "Window Segmentation 72.04% done\n",
      "Window Segmentation 72.20% done\n",
      "Window Segmentation 72.36% done\n",
      "Window Segmentation 72.52% done\n",
      "Window Segmentation 72.68% done\n",
      "Window Segmentation 72.83% done\n",
      "Window Segmentation 72.99% done\n",
      "Window Segmentation 73.15% done\n",
      "Window Segmentation 73.31% done\n",
      "Window Segmentation 73.47% done\n",
      "Window Segmentation 73.63% done\n",
      "Window Segmentation 73.78% done\n",
      "Window Segmentation 73.94% done\n",
      "Window Segmentation 74.10% done\n",
      "Window Segmentation 74.26% done\n",
      "Window Segmentation 74.42% done\n",
      "Window Segmentation 74.58% done\n",
      "Window Segmentation 74.73% done\n",
      "Window Segmentation 74.89% done\n",
      "Window Segmentation 75.05% done\n",
      "Window Segmentation 75.21% done\n",
      "Window Segmentation 75.37% done\n",
      "Window Segmentation 75.53% done\n",
      "Window Segmentation 75.68% done\n",
      "Window Segmentation 75.84% done\n",
      "Window Segmentation 76.00% done\n",
      "Window Segmentation 76.16% done\n",
      "Window Segmentation 76.32% done\n",
      "Window Segmentation 76.48% done\n",
      "Window Segmentation 76.63% done\n",
      "Window Segmentation 76.79% done\n",
      "Window Segmentation 76.95% done\n",
      "Window Segmentation 77.11% done\n",
      "Window Segmentation 77.27% done\n",
      "Window Segmentation 77.43% done\n",
      "Window Segmentation 77.58% done\n",
      "Window Segmentation 77.74% done\n",
      "Window Segmentation 77.90% done\n",
      "Window Segmentation 78.06% done\n",
      "Window Segmentation 78.22% done\n",
      "Window Segmentation 78.38% done\n",
      "Window Segmentation 78.53% done\n",
      "Window Segmentation 78.69% done\n",
      "Window Segmentation 78.85% done\n",
      "Window Segmentation 79.01% done\n",
      "Window Segmentation 79.17% done\n",
      "Window Segmentation 79.33% done\n",
      "Window Segmentation 79.48% done\n",
      "Window Segmentation 79.64% done\n",
      "Window Segmentation 79.80% done\n",
      "Window Segmentation 79.96% done\n",
      "Window Segmentation 80.12% done\n",
      "Window Segmentation 80.28% done\n",
      "Window Segmentation 80.43% done\n",
      "Window Segmentation 80.59% done\n",
      "Window Segmentation 80.75% done\n",
      "Window Segmentation 80.91% done\n",
      "Window Segmentation 81.07% done\n",
      "Window Segmentation 81.23% done\n",
      "Window Segmentation 81.38% done\n",
      "Window Segmentation 81.54% done\n",
      "Window Segmentation 81.70% done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 81.86% done\n",
      "Window Segmentation 82.02% done\n",
      "Window Segmentation 82.18% done\n",
      "Window Segmentation 82.33% done\n",
      "Window Segmentation 82.49% done\n",
      "Window Segmentation 82.65% done\n",
      "Window Segmentation 82.81% done\n",
      "Window Segmentation 82.97% done\n",
      "Window Segmentation 83.13% done\n",
      "Window Segmentation 83.28% done\n",
      "Window Segmentation 83.44% done\n",
      "Window Segmentation 83.60% done\n",
      "Window Segmentation 83.76% done\n",
      "Window Segmentation 83.92% done\n",
      "Window Segmentation 84.08% done\n",
      "Window Segmentation 84.23% done\n",
      "Window Segmentation 84.39% done\n",
      "Window Segmentation 84.55% done\n",
      "Window Segmentation 84.71% done\n",
      "Window Segmentation 84.87% done\n",
      "Window Segmentation 85.03% done\n",
      "Window Segmentation 85.18% done\n",
      "Window Segmentation 85.34% done\n",
      "Window Segmentation 85.50% done\n",
      "Window Segmentation 85.66% done\n",
      "Window Segmentation 85.82% done\n",
      "Window Segmentation 85.98% done\n",
      "Window Segmentation 86.14% done\n",
      "Window Segmentation 86.29% done\n",
      "Window Segmentation 86.45% done\n",
      "Window Segmentation 86.61% done\n",
      "Window Segmentation 86.77% done\n",
      "Window Segmentation 86.93% done\n",
      "Window Segmentation 87.09% done\n",
      "Window Segmentation 87.24% done\n",
      "Window Segmentation 87.40% done\n",
      "Window Segmentation 87.56% done\n",
      "Window Segmentation 87.72% done\n",
      "Window Segmentation 87.88% done\n",
      "Window Segmentation 88.04% done\n",
      "Window Segmentation 88.19% done\n",
      "Window Segmentation 88.35% done\n",
      "Window Segmentation 88.51% done\n",
      "Window Segmentation 88.67% done\n",
      "Window Segmentation 88.83% done\n",
      "Window Segmentation 88.99% done\n",
      "Window Segmentation 89.14% done\n",
      "Window Segmentation 89.30% done\n",
      "Window Segmentation 89.46% done\n",
      "Window Segmentation 89.62% done\n",
      "Window Segmentation 89.78% done\n",
      "Window Segmentation 89.94% done\n",
      "Window Segmentation 90.09% done\n",
      "Window Segmentation 90.25% done\n",
      "Window Segmentation 90.41% done\n",
      "Window Segmentation 90.57% done\n",
      "Window Segmentation 90.73% done\n",
      "Window Segmentation 90.89% done\n",
      "Window Segmentation 91.04% done\n",
      "Window Segmentation 91.20% done\n",
      "Window Segmentation 91.36% done\n",
      "Window Segmentation 91.52% done\n",
      "Window Segmentation 91.68% done\n",
      "Window Segmentation 91.84% done\n",
      "Window Segmentation 91.99% done\n",
      "Window Segmentation 92.15% done\n",
      "Window Segmentation 92.31% done\n",
      "Window Segmentation 92.47% done\n",
      "Window Segmentation 92.63% done\n",
      "Window Segmentation 92.79% done\n",
      "Window Segmentation 92.94% done\n",
      "Window Segmentation 93.10% done\n",
      "Window Segmentation 93.26% done\n",
      "Window Segmentation 93.42% done\n",
      "Window Segmentation 93.58% done\n",
      "Window Segmentation 93.74% done\n",
      "Window Segmentation 93.89% done\n",
      "Window Segmentation 94.05% done\n",
      "Window Segmentation 94.21% done\n",
      "Window Segmentation 94.37% done\n",
      "Window Segmentation 94.53% done\n",
      "Window Segmentation 94.69% done\n",
      "Window Segmentation 94.84% done\n",
      "Window Segmentation 95.00% done\n",
      "Window Segmentation 95.16% done\n",
      "Window Segmentation 95.32% done\n",
      "Window Segmentation 95.48% done\n",
      "Window Segmentation 95.64% done\n",
      "Window Segmentation 95.79% done\n",
      "Window Segmentation 95.95% done\n",
      "Window Segmentation 96.11% done\n",
      "Window Segmentation 96.27% done\n",
      "Window Segmentation 96.43% done\n",
      "Window Segmentation 96.59% done\n",
      "Window Segmentation 96.74% done\n",
      "Window Segmentation 96.90% done\n",
      "Window Segmentation 97.06% done\n",
      "Window Segmentation 97.22% done\n",
      "Window Segmentation 97.38% done\n",
      "Window Segmentation 97.54% done\n",
      "Window Segmentation 97.69% done\n",
      "Window Segmentation 97.85% done\n",
      "Window Segmentation 98.01% done\n",
      "Window Segmentation 98.17% done\n",
      "Window Segmentation 98.33% done\n",
      "Window Segmentation 98.49% done\n",
      "Window Segmentation 98.64% done\n",
      "Window Segmentation 98.80% done\n",
      "Window Segmentation 98.96% done\n",
      "Window Segmentation 99.12% done\n",
      "Window Segmentation 99.28% done\n",
      "Window Segmentation 99.44% done\n",
      "Window Segmentation 99.59% done\n",
      "Window Segmentation 99.75% done\n",
      "Window Segmentation 99.91% done\n"
     ]
    }
   ],
   "source": [
    "segments, labels = segment_signal(normalized_lake_dataset, 36, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 36, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 1, 36, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_segments = segments.reshape(len(segments), 1, 36, 4)\n",
    "reshaped_segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef2af5f2b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reshaped_segments[1000][0] * 255, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_segments_as_image = segments.reshape(len(segments), 6, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 36, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 6, 6, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_segments_as_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = labels.reshape(len(labels), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = np.zeros((len(labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "while(iter < len(labels)):\n",
    "    if labels[iter] > 0.0:\n",
    "        print(iter)\n",
    "    new_labels[iter][int(labels[iter])] = 1\n",
    "    iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels[1500:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break apart the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CNNHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.iterator = 0\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(reshaped_segments_as_image, labels, test_size=0.3, random_state=101)\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.X_train[self.iterator:self.iterator + batch_size]\n",
    "        y = self.y_train[self.iterator:self.iterator + batch_size]\n",
    "        self.iterator = (self.iterator + batch_size) % len(self.X_train)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 6, 6, 4])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[2,2,4,6])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[2,2,6,12])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 4*12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(64)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_one_dropout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,2)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-43-e0c07892321c>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "cnn_helper = CNNHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 6, 6, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_helper.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5749782 , 0.91763073, 0.47173134, 0.18909091],\n",
       "        [0.5793374 , 0.91716798, 0.49248475, 0.18545455],\n",
       "        [0.58238884, 0.89958353, 0.49102258, 0.18272727],\n",
       "        [0.581517  , 0.89958353, 0.528363  , 0.18363636],\n",
       "        [0.58064516, 0.89819528, 0.53306396, 0.18363636],\n",
       "        [0.58064516, 0.90189727, 0.52944783, 0.18636364]],\n",
       "\n",
       "       [[0.58108108, 0.90652476, 0.55636438, 0.18636364],\n",
       "        [0.57890148, 0.9106895 , 0.5577165 , 0.18909091],\n",
       "        [0.57802964, 0.91207774, 0.5577165 , 0.19      ],\n",
       "        [0.57585004, 0.91577973, 0.58389409, 0.19181818],\n",
       "        [0.57628596, 0.91716798, 0.56215018, 0.19454545],\n",
       "        [0.5771578 , 0.91439149, 0.56329791, 0.19363636]],\n",
       "\n",
       "       [[0.57672188, 0.91439149, 0.61592038, 0.19454545],\n",
       "        [0.57672188, 0.91115224, 0.61860889, 0.19545455],\n",
       "        [0.57672188, 0.909764  , 0.63134394, 0.19636364],\n",
       "        [0.5771578 , 0.90606201, 0.6047104 , 0.19636364],\n",
       "        [0.57802964, 0.88847756, 0.55083014, 0.19636364],\n",
       "        [0.5793374 , 0.86904211, 0.5260361 , 0.19636364]],\n",
       "\n",
       "       [[0.58195292, 0.85978714, 0.46975033, 0.19727273],\n",
       "        [0.5836966 , 0.8546969 , 0.49000063, 0.19727273],\n",
       "        [0.5858762 , 0.84683017, 0.48393183, 0.19636364],\n",
       "        [0.58631212, 0.84544193, 0.50682347, 0.19636364],\n",
       "        [0.58544028, 0.84775567, 0.45251871, 0.19727273],\n",
       "        [0.58282476, 0.8546969 , 0.43127791, 0.19818182]],\n",
       "\n",
       "       [[0.5793374 , 0.86024988, 0.45174832, 0.19727273],\n",
       "        [0.57672188, 0.86348913, 0.48070876, 0.19818182],\n",
       "        [0.57279861, 0.87413235, 0.50367901, 0.19909091],\n",
       "        [0.56974717, 0.88153633, 0.4966826 , 0.20090909],\n",
       "        [0.56713165, 0.88477557, 0.51743601, 0.20272727],\n",
       "        [0.56495205, 0.88431282, 0.49440287, 0.20363636]],\n",
       "\n",
       "       [[0.56277245, 0.88246182, 0.46630715, 0.20363636],\n",
       "        [0.56102877, 0.87690884, 0.48404188, 0.20454545],\n",
       "        [0.55928509, 0.87089311, 0.46251808, 0.20454545],\n",
       "        [0.55754141, 0.86580287, 0.41997359, 0.20454545],\n",
       "        [0.55797733, 0.86580287, 0.43209547, 0.20363636],\n",
       "        [0.55666957, 0.86302638, 0.3964845 , 0.20272727]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_helper.X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_helper.X_test = np.zeros((1892, 6, 6, 3))\n",
    "# cnn_helper.X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.6125793\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.61627907\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.7917548\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cost_history = []\n",
    "    acc_history = []\n",
    "\n",
    "    for i in range(4000):\n",
    "        batch = cnn_helper.next_batch(100)\n",
    "        _, c = sess.run([train, cross_entropy], feed_dict={x: batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "        cost_history.append(c)\n",
    "        \n",
    "        matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "        acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "        acc_history.append(sess.run(acc,feed_dict={x:cnn_helper.X_test,y_true:cnn_helper.y_test,hold_prob:1.0}))\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:cnn_helper.X_test,y_true:cnn_helper.y_test,hold_prob:1.0}))\n",
    "#             print(tf.argmax(y_pred,1).eval(sess))\n",
    "            print(y_true.eval(session=sess, feed_dict={y_true:cnn_helper.y_test}))\n",
    "#             print(y_pred.eval(session=sess, feed_dict={y_pred:y_pred}))\n",
    "#             print(\"Recall:\", recall_score(y_true.eval(), y_pred.eval()))\n",
    "#             print(\"Precision:\", precision_score(y, predict))\n",
    "#             print(confusion_matrix(y_true=y_true.eval(), y_pred=y_pred.eval()))\n",
    "            print('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_history)\n",
    "plt.plot(acc_history)\n",
    "plt.figure(figsize=(40,20))\n",
    "plt.show()\n",
    "# acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
