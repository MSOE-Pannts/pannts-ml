{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_path, column_names):\n",
    "    \"\"\"Reads the data from the specified file and retrieves the column names\n",
    "    \n",
    "    Args:\n",
    "        file_path: The path of the file as a String\n",
    "        column_names: Array of Strings representing the names of the colunms\n",
    "        \n",
    "    Returns:\n",
    "        A DataFrame of the read in data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path, header = 0, names = column_names)\n",
    "    return data\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    \"\"\"Normalizes the data in the DataFrame using the mean and sigma values\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame to normalize\n",
    "        \n",
    "    Returns:\n",
    "        The normalized data\n",
    "    \"\"\"\n",
    "    mu = np.mean(dataset, axis = 0)\n",
    "    sigma = np.std(dataset, axis = 0)\n",
    "    return (dataset - mu) / sigma\n",
    "\n",
    "def basic_feature_normalize(dataset, cols_to_norm):\n",
    "    \"\"\"A Basic Normalization of the dataset\n",
    "    \n",
    "    Takes the dataset and normalizes it from 0 (min value) to 1 (max value)\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame to normalize\n",
    "        cols_to_norm: An Array of strings of the columns that need normalization\n",
    "        \n",
    "    Returns:\n",
    "        The normalized dataset with the specified columns normalized between 0 and 1\n",
    "    \"\"\"\n",
    "    dataset[cols_to_norm] = dataset[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "    return dataset\n",
    "\n",
    "def make_rgbs(dataset, cols_to_rgb):\n",
    "    \"\"\"Takes a dataset and converts specific columns into rgb values\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame to convert to rgb values\n",
    "        cols_to_rgb: An Arrya of strings of the columns that need to be converted\n",
    "        \n",
    "    Returns:\n",
    "        The dataset with the specified columns converted to rgb values\n",
    "    \"\"\"\n",
    "    dataset[cols_to_rgb] = dataset[cols_to_rgb].apply(lambda x: int(x * 255))\n",
    "    return dataset\n",
    "\n",
    "def convert_timestamp(dataset):\n",
    "    \"\"\"Converts the timestamp to a unix timestamp\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame with the timestamp column to convert to unix\n",
    "        \n",
    "    Returns:\n",
    "        The dataset with the converted timestamp\n",
    "    \"\"\"\n",
    "    dataset['Timestamp'] = dataset['Timestamp'].apply(lambda x:\n",
    "                                                     datetime.strptime(x, '%m/%d/%y %H:%M').timestamp())\n",
    "    return dataset\n",
    "\n",
    "def convert_BGA_RFU(dataset, threshold):\n",
    "    \"\"\"Converts the BGA_Phycocyanin_RFU column to a true or false value (represented by 1 or 0)\n",
    "       based on the threshold value\n",
    "       \n",
    "    Args:\n",
    "        dataset: The DataFrame with the BGA_Phycocyanin_RFU value to be adjusted\n",
    "        threshold: The minimum value for an algae bloom to be true\n",
    "        \n",
    "    Returns:\n",
    "        The dataset with the converted BGA_RFU value\"\"\"\n",
    "    dataset['BGA_Phycocyanin_RFU'] = dataset['BGA_Phycocyanin_RFU'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We step 50% down based on window size\n",
    "def windows(data, size):\n",
    "    counter_output = 0\n",
    "    start = 0\n",
    "    while start < data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start += (size / 12)\n",
    "        counter_output += 1\n",
    "        if counter_output % 10 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format((start / data.count()) * 100))\n",
    "    \n",
    "# 32 chosen for 8 hours of 15 minute intervals\n",
    "# TODO: NEED TO PASS IN COLUMNS AND DETERMINE FROM THAT\n",
    "def segment_signal(dataset, window_size = 90, columns = 5):\n",
    "    segments = np.empty((0, window_size, columns))\n",
    "    labels = np.empty((0))\n",
    "    count = 0;\n",
    "    for (start, end) in windows(dataset[\"Timestamp\"], window_size):\n",
    "        temperature = dataset['Temperature'][start:end]\n",
    "        conductivity = dataset['Sp_Cond'][start:end]\n",
    "        turbidity = dataset['Turbidity'][start:end]\n",
    "        ph = dataset['pH'][start:end]\n",
    "        odo = dataset['ODO'][start:end]\n",
    "        if(len(dataset['Timestamp'][start:end]) == window_size):\n",
    "            segments = np.vstack([segments, np.dstack([temperature, conductivity, turbidity, ph, odo])])\n",
    "            labels = np.append(labels, stats.mode(dataset['BGA_Phycocyanin_RFU'][start:end])[0][0])\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Lake_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Sp_Cond</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>ODO</th>\n",
       "      <th>BGA_Phycocyanin_RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.493960e+09</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493961e+09</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.493962e+09</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.493963e+09</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493964e+09</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  Temperature  Sp_Cond    pH  Turbidity   ODO  \\\n",
       "0  1.493960e+09        15.02     1848  8.36      16.84  9.04   \n",
       "1  1.493961e+09        14.99     1847  8.36      16.76  9.04   \n",
       "2  1.493962e+09        14.96     1847  8.36      16.82  9.04   \n",
       "3  1.493963e+09        14.95     1848  8.36      17.19  9.03   \n",
       "4  1.493964e+09        14.92     1848  8.36      16.85  9.02   \n",
       "\n",
       "   BGA_Phycocyanin_RFU  \n",
       "0                  0.4  \n",
       "1                  0.4  \n",
       "2                  0.4  \n",
       "3                  0.4  \n",
       "4                  0.4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Timestamp', 'Temperature', 'Sp_Cond', 'pH_mV', 'pH', 'Turbidity', 'Chlorophyll', 'Chlorophyll_RFU',\n",
    "        'ODOSat', 'ODO', 'BGA_Phycocyanin_RFU']\n",
    "\n",
    "cols_to_keep = []\n",
    "cols_to_keep.append('Timestamp')\n",
    "cols_to_keep.append('Temperature')\n",
    "cols_to_keep.append('Sp_Cond')\n",
    "# cols_to_keep.append('pH_mV')\n",
    "cols_to_keep.append('pH')\n",
    "cols_to_keep.append('Turbidity')\n",
    "# cols_to_keep.append('Chlorophyll')\n",
    "# cols_to_keep.append('Chlorophyll_RFU')\n",
    "# cols_to_keep.append('ODOSat')\n",
    "cols_to_keep.append('ODO')\n",
    "cols_to_keep.append('BGA_Phycocyanin_RFU')\n",
    "\n",
    "lake_dataset = read_data('./data/cleaned/utah_lake_vineyard.csv', cols) \n",
    "\n",
    "for col in cols:\n",
    "    if col not in cols_to_keep:\n",
    "        lake_dataset = lake_dataset.drop(col, axis=1)\n",
    "        \n",
    "lake_dataset = convert_timestamp(lake_dataset)\n",
    "lake_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lake_dataset = convert_BGA_RFU(lake_dataset, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Sp_Cond</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>ODO</th>\n",
       "      <th>BGA_Phycocyanin_RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.493960e+09</td>\n",
       "      <td>0.409329</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493961e+09</td>\n",
       "      <td>0.408021</td>\n",
       "      <td>0.853309</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.493962e+09</td>\n",
       "      <td>0.406713</td>\n",
       "      <td>0.853309</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0.351818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.493963e+09</td>\n",
       "      <td>0.406277</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>0.350909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493964e+09</td>\n",
       "      <td>0.404969</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.025454</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  Temperature   Sp_Cond        pH  Turbidity       ODO  \\\n",
       "0  1.493960e+09     0.409329  0.853771  0.330769   0.025439  0.351818   \n",
       "1  1.493961e+09     0.408021  0.853309  0.330769   0.025313  0.351818   \n",
       "2  1.493962e+09     0.406713  0.853309  0.330769   0.025407  0.351818   \n",
       "3  1.493963e+09     0.406277  0.853771  0.330769   0.025989  0.350909   \n",
       "4  1.493964e+09     0.404969  0.853771  0.330769   0.025454  0.350000   \n",
       "\n",
       "   BGA_Phycocyanin_RFU  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset = basic_feature_normalize(lake_dataset, ['Temperature', 'Sp_Cond', 'Turbidity', 'pH', 'ODO'])\n",
    "normalized_lake_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset['Temperature'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset['Temperature'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset['BGA_Phycocyanin_RFU'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18947, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_lake_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the segments and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 0.16% done\n",
      "Window Segmentation 0.32% done\n",
      "Window Segmentation 0.48% done\n",
      "Window Segmentation 0.63% done\n",
      "Window Segmentation 0.79% done\n",
      "Window Segmentation 0.95% done\n",
      "Window Segmentation 1.11% done\n",
      "Window Segmentation 1.27% done\n",
      "Window Segmentation 1.43% done\n",
      "Window Segmentation 1.58% done\n",
      "Window Segmentation 1.74% done\n",
      "Window Segmentation 1.90% done\n",
      "Window Segmentation 2.06% done\n",
      "Window Segmentation 2.22% done\n",
      "Window Segmentation 2.38% done\n",
      "Window Segmentation 2.53% done\n",
      "Window Segmentation 2.69% done\n",
      "Window Segmentation 2.85% done\n",
      "Window Segmentation 3.01% done\n",
      "Window Segmentation 3.17% done\n",
      "Window Segmentation 3.33% done\n",
      "Window Segmentation 3.48% done\n",
      "Window Segmentation 3.64% done\n",
      "Window Segmentation 3.80% done\n",
      "Window Segmentation 3.96% done\n",
      "Window Segmentation 4.12% done\n",
      "Window Segmentation 4.28% done\n",
      "Window Segmentation 4.43% done\n",
      "Window Segmentation 4.59% done\n",
      "Window Segmentation 4.75% done\n",
      "Window Segmentation 4.91% done\n",
      "Window Segmentation 5.07% done\n",
      "Window Segmentation 5.23% done\n",
      "Window Segmentation 5.38% done\n",
      "Window Segmentation 5.54% done\n",
      "Window Segmentation 5.70% done\n",
      "Window Segmentation 5.86% done\n",
      "Window Segmentation 6.02% done\n",
      "Window Segmentation 6.18% done\n",
      "Window Segmentation 6.33% done\n",
      "Window Segmentation 6.49% done\n",
      "Window Segmentation 6.65% done\n",
      "Window Segmentation 6.81% done\n",
      "Window Segmentation 6.97% done\n",
      "Window Segmentation 7.13% done\n",
      "Window Segmentation 7.28% done\n",
      "Window Segmentation 7.44% done\n",
      "Window Segmentation 7.60% done\n",
      "Window Segmentation 7.76% done\n",
      "Window Segmentation 7.92% done\n",
      "Window Segmentation 8.08% done\n",
      "Window Segmentation 8.23% done\n",
      "Window Segmentation 8.39% done\n",
      "Window Segmentation 8.55% done\n",
      "Window Segmentation 8.71% done\n",
      "Window Segmentation 8.87% done\n",
      "Window Segmentation 9.03% done\n",
      "Window Segmentation 9.18% done\n",
      "Window Segmentation 9.34% done\n",
      "Window Segmentation 9.50% done\n",
      "Window Segmentation 9.66% done\n",
      "Window Segmentation 9.82% done\n",
      "Window Segmentation 9.98% done\n",
      "Window Segmentation 10.13% done\n",
      "Window Segmentation 10.29% done\n",
      "Window Segmentation 10.45% done\n",
      "Window Segmentation 10.61% done\n",
      "Window Segmentation 10.77% done\n",
      "Window Segmentation 10.93% done\n",
      "Window Segmentation 11.08% done\n",
      "Window Segmentation 11.24% done\n",
      "Window Segmentation 11.40% done\n",
      "Window Segmentation 11.56% done\n",
      "Window Segmentation 11.72% done\n",
      "Window Segmentation 11.88% done\n",
      "Window Segmentation 12.03% done\n",
      "Window Segmentation 12.19% done\n",
      "Window Segmentation 12.35% done\n",
      "Window Segmentation 12.51% done\n",
      "Window Segmentation 12.67% done\n",
      "Window Segmentation 12.83% done\n",
      "Window Segmentation 12.98% done\n",
      "Window Segmentation 13.14% done\n",
      "Window Segmentation 13.30% done\n",
      "Window Segmentation 13.46% done\n",
      "Window Segmentation 13.62% done\n",
      "Window Segmentation 13.78% done\n",
      "Window Segmentation 13.93% done\n",
      "Window Segmentation 14.09% done\n",
      "Window Segmentation 14.25% done\n",
      "Window Segmentation 14.41% done\n",
      "Window Segmentation 14.57% done\n",
      "Window Segmentation 14.73% done\n",
      "Window Segmentation 14.88% done\n",
      "Window Segmentation 15.04% done\n",
      "Window Segmentation 15.20% done\n",
      "Window Segmentation 15.36% done\n",
      "Window Segmentation 15.52% done\n",
      "Window Segmentation 15.68% done\n",
      "Window Segmentation 15.83% done\n",
      "Window Segmentation 15.99% done\n",
      "Window Segmentation 16.15% done\n",
      "Window Segmentation 16.31% done\n",
      "Window Segmentation 16.47% done\n",
      "Window Segmentation 16.63% done\n",
      "Window Segmentation 16.78% done\n",
      "Window Segmentation 16.94% done\n",
      "Window Segmentation 17.10% done\n",
      "Window Segmentation 17.26% done\n",
      "Window Segmentation 17.42% done\n",
      "Window Segmentation 17.58% done\n",
      "Window Segmentation 17.73% done\n",
      "Window Segmentation 17.89% done\n",
      "Window Segmentation 18.05% done\n",
      "Window Segmentation 18.21% done\n",
      "Window Segmentation 18.37% done\n",
      "Window Segmentation 18.53% done\n",
      "Window Segmentation 18.68% done\n",
      "Window Segmentation 18.84% done\n",
      "Window Segmentation 19.00% done\n",
      "Window Segmentation 19.16% done\n",
      "Window Segmentation 19.32% done\n",
      "Window Segmentation 19.48% done\n",
      "Window Segmentation 19.63% done\n",
      "Window Segmentation 19.79% done\n",
      "Window Segmentation 19.95% done\n",
      "Window Segmentation 20.11% done\n",
      "Window Segmentation 20.27% done\n",
      "Window Segmentation 20.43% done\n",
      "Window Segmentation 20.58% done\n",
      "Window Segmentation 20.74% done\n",
      "Window Segmentation 20.90% done\n",
      "Window Segmentation 21.06% done\n",
      "Window Segmentation 21.22% done\n",
      "Window Segmentation 21.38% done\n",
      "Window Segmentation 21.53% done\n",
      "Window Segmentation 21.69% done\n",
      "Window Segmentation 21.85% done\n",
      "Window Segmentation 22.01% done\n",
      "Window Segmentation 22.17% done\n",
      "Window Segmentation 22.33% done\n",
      "Window Segmentation 22.48% done\n",
      "Window Segmentation 22.64% done\n",
      "Window Segmentation 22.80% done\n",
      "Window Segmentation 22.96% done\n",
      "Window Segmentation 23.12% done\n",
      "Window Segmentation 23.28% done\n",
      "Window Segmentation 23.43% done\n",
      "Window Segmentation 23.59% done\n",
      "Window Segmentation 23.75% done\n",
      "Window Segmentation 23.91% done\n",
      "Window Segmentation 24.07% done\n",
      "Window Segmentation 24.23% done\n",
      "Window Segmentation 24.38% done\n",
      "Window Segmentation 24.54% done\n",
      "Window Segmentation 24.70% done\n",
      "Window Segmentation 24.86% done\n",
      "Window Segmentation 25.02% done\n",
      "Window Segmentation 25.18% done\n",
      "Window Segmentation 25.33% done\n",
      "Window Segmentation 25.49% done\n",
      "Window Segmentation 25.65% done\n",
      "Window Segmentation 25.81% done\n",
      "Window Segmentation 25.97% done\n",
      "Window Segmentation 26.13% done\n",
      "Window Segmentation 26.28% done\n",
      "Window Segmentation 26.44% done\n",
      "Window Segmentation 26.60% done\n",
      "Window Segmentation 26.76% done\n",
      "Window Segmentation 26.92% done\n",
      "Window Segmentation 27.08% done\n",
      "Window Segmentation 27.23% done\n",
      "Window Segmentation 27.39% done\n",
      "Window Segmentation 27.55% done\n",
      "Window Segmentation 27.71% done\n",
      "Window Segmentation 27.87% done\n",
      "Window Segmentation 28.03% done\n",
      "Window Segmentation 28.18% done\n",
      "Window Segmentation 28.34% done\n",
      "Window Segmentation 28.50% done\n",
      "Window Segmentation 28.66% done\n",
      "Window Segmentation 28.82% done\n",
      "Window Segmentation 28.98% done\n",
      "Window Segmentation 29.13% done\n",
      "Window Segmentation 29.29% done\n",
      "Window Segmentation 29.45% done\n",
      "Window Segmentation 29.61% done\n",
      "Window Segmentation 29.77% done\n",
      "Window Segmentation 29.93% done\n",
      "Window Segmentation 30.08% done\n",
      "Window Segmentation 30.24% done\n",
      "Window Segmentation 30.40% done\n",
      "Window Segmentation 30.56% done\n",
      "Window Segmentation 30.72% done\n",
      "Window Segmentation 30.88% done\n",
      "Window Segmentation 31.03% done\n",
      "Window Segmentation 31.19% done\n",
      "Window Segmentation 31.35% done\n",
      "Window Segmentation 31.51% done\n",
      "Window Segmentation 31.67% done\n",
      "Window Segmentation 31.83% done\n",
      "Window Segmentation 31.98% done\n",
      "Window Segmentation 32.14% done\n",
      "Window Segmentation 32.30% done\n",
      "Window Segmentation 32.46% done\n",
      "Window Segmentation 32.62% done\n",
      "Window Segmentation 32.78% done\n",
      "Window Segmentation 32.93% done\n",
      "Window Segmentation 33.09% done\n",
      "Window Segmentation 33.25% done\n",
      "Window Segmentation 33.41% done\n",
      "Window Segmentation 33.57% done\n",
      "Window Segmentation 33.73% done\n",
      "Window Segmentation 33.88% done\n",
      "Window Segmentation 34.04% done\n",
      "Window Segmentation 34.20% done\n",
      "Window Segmentation 34.36% done\n",
      "Window Segmentation 34.52% done\n",
      "Window Segmentation 34.68% done\n",
      "Window Segmentation 34.83% done\n",
      "Window Segmentation 34.99% done\n",
      "Window Segmentation 35.15% done\n",
      "Window Segmentation 35.31% done\n",
      "Window Segmentation 35.47% done\n",
      "Window Segmentation 35.63% done\n",
      "Window Segmentation 35.78% done\n",
      "Window Segmentation 35.94% done\n",
      "Window Segmentation 36.10% done\n",
      "Window Segmentation 36.26% done\n",
      "Window Segmentation 36.42% done\n",
      "Window Segmentation 36.58% done\n",
      "Window Segmentation 36.73% done\n",
      "Window Segmentation 36.89% done\n",
      "Window Segmentation 37.05% done\n",
      "Window Segmentation 37.21% done\n",
      "Window Segmentation 37.37% done\n",
      "Window Segmentation 37.53% done\n",
      "Window Segmentation 37.68% done\n",
      "Window Segmentation 37.84% done\n",
      "Window Segmentation 38.00% done\n",
      "Window Segmentation 38.16% done\n",
      "Window Segmentation 38.32% done\n",
      "Window Segmentation 38.48% done\n",
      "Window Segmentation 38.63% done\n",
      "Window Segmentation 38.79% done\n",
      "Window Segmentation 38.95% done\n",
      "Window Segmentation 39.11% done\n",
      "Window Segmentation 39.27% done\n",
      "Window Segmentation 39.43% done\n",
      "Window Segmentation 39.58% done\n",
      "Window Segmentation 39.74% done\n",
      "Window Segmentation 39.90% done\n",
      "Window Segmentation 40.06% done\n",
      "Window Segmentation 40.22% done\n",
      "Window Segmentation 40.38% done\n",
      "Window Segmentation 40.53% done\n",
      "Window Segmentation 40.69% done\n",
      "Window Segmentation 40.85% done\n",
      "Window Segmentation 41.01% done\n",
      "Window Segmentation 41.17% done\n",
      "Window Segmentation 41.33% done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 41.48% done\n",
      "Window Segmentation 41.64% done\n",
      "Window Segmentation 41.80% done\n",
      "Window Segmentation 41.96% done\n",
      "Window Segmentation 42.12% done\n",
      "Window Segmentation 42.28% done\n",
      "Window Segmentation 42.43% done\n",
      "Window Segmentation 42.59% done\n",
      "Window Segmentation 42.75% done\n",
      "Window Segmentation 42.91% done\n",
      "Window Segmentation 43.07% done\n",
      "Window Segmentation 43.23% done\n",
      "Window Segmentation 43.38% done\n",
      "Window Segmentation 43.54% done\n",
      "Window Segmentation 43.70% done\n",
      "Window Segmentation 43.86% done\n",
      "Window Segmentation 44.02% done\n",
      "Window Segmentation 44.18% done\n",
      "Window Segmentation 44.33% done\n",
      "Window Segmentation 44.49% done\n",
      "Window Segmentation 44.65% done\n",
      "Window Segmentation 44.81% done\n",
      "Window Segmentation 44.97% done\n",
      "Window Segmentation 45.13% done\n",
      "Window Segmentation 45.28% done\n",
      "Window Segmentation 45.44% done\n",
      "Window Segmentation 45.60% done\n",
      "Window Segmentation 45.76% done\n",
      "Window Segmentation 45.92% done\n",
      "Window Segmentation 46.08% done\n",
      "Window Segmentation 46.23% done\n",
      "Window Segmentation 46.39% done\n",
      "Window Segmentation 46.55% done\n",
      "Window Segmentation 46.71% done\n",
      "Window Segmentation 46.87% done\n",
      "Window Segmentation 47.03% done\n",
      "Window Segmentation 47.18% done\n",
      "Window Segmentation 47.34% done\n",
      "Window Segmentation 47.50% done\n",
      "Window Segmentation 47.66% done\n",
      "Window Segmentation 47.82% done\n",
      "Window Segmentation 47.98% done\n",
      "Window Segmentation 48.13% done\n",
      "Window Segmentation 48.29% done\n",
      "Window Segmentation 48.45% done\n",
      "Window Segmentation 48.61% done\n",
      "Window Segmentation 48.77% done\n",
      "Window Segmentation 48.93% done\n",
      "Window Segmentation 49.08% done\n",
      "Window Segmentation 49.24% done\n",
      "Window Segmentation 49.40% done\n",
      "Window Segmentation 49.56% done\n",
      "Window Segmentation 49.72% done\n",
      "Window Segmentation 49.88% done\n",
      "Window Segmentation 50.03% done\n",
      "Window Segmentation 50.19% done\n",
      "Window Segmentation 50.35% done\n",
      "Window Segmentation 50.51% done\n",
      "Window Segmentation 50.67% done\n",
      "Window Segmentation 50.83% done\n",
      "Window Segmentation 50.98% done\n",
      "Window Segmentation 51.14% done\n",
      "Window Segmentation 51.30% done\n",
      "Window Segmentation 51.46% done\n",
      "Window Segmentation 51.62% done\n",
      "Window Segmentation 51.78% done\n",
      "Window Segmentation 51.93% done\n",
      "Window Segmentation 52.09% done\n",
      "Window Segmentation 52.25% done\n",
      "Window Segmentation 52.41% done\n",
      "Window Segmentation 52.57% done\n",
      "Window Segmentation 52.73% done\n",
      "Window Segmentation 52.88% done\n",
      "Window Segmentation 53.04% done\n",
      "Window Segmentation 53.20% done\n",
      "Window Segmentation 53.36% done\n",
      "Window Segmentation 53.52% done\n",
      "Window Segmentation 53.68% done\n",
      "Window Segmentation 53.83% done\n",
      "Window Segmentation 53.99% done\n",
      "Window Segmentation 54.15% done\n",
      "Window Segmentation 54.31% done\n",
      "Window Segmentation 54.47% done\n",
      "Window Segmentation 54.63% done\n",
      "Window Segmentation 54.78% done\n",
      "Window Segmentation 54.94% done\n",
      "Window Segmentation 55.10% done\n",
      "Window Segmentation 55.26% done\n",
      "Window Segmentation 55.42% done\n",
      "Window Segmentation 55.58% done\n",
      "Window Segmentation 55.73% done\n",
      "Window Segmentation 55.89% done\n",
      "Window Segmentation 56.05% done\n",
      "Window Segmentation 56.21% done\n",
      "Window Segmentation 56.37% done\n",
      "Window Segmentation 56.53% done\n",
      "Window Segmentation 56.68% done\n",
      "Window Segmentation 56.84% done\n",
      "Window Segmentation 57.00% done\n",
      "Window Segmentation 57.16% done\n",
      "Window Segmentation 57.32% done\n",
      "Window Segmentation 57.48% done\n",
      "Window Segmentation 57.63% done\n",
      "Window Segmentation 57.79% done\n",
      "Window Segmentation 57.95% done\n",
      "Window Segmentation 58.11% done\n",
      "Window Segmentation 58.27% done\n",
      "Window Segmentation 58.43% done\n",
      "Window Segmentation 58.58% done\n",
      "Window Segmentation 58.74% done\n",
      "Window Segmentation 58.90% done\n",
      "Window Segmentation 59.06% done\n",
      "Window Segmentation 59.22% done\n",
      "Window Segmentation 59.38% done\n",
      "Window Segmentation 59.53% done\n",
      "Window Segmentation 59.69% done\n",
      "Window Segmentation 59.85% done\n",
      "Window Segmentation 60.01% done\n",
      "Window Segmentation 60.17% done\n",
      "Window Segmentation 60.33% done\n",
      "Window Segmentation 60.48% done\n",
      "Window Segmentation 60.64% done\n",
      "Window Segmentation 60.80% done\n",
      "Window Segmentation 60.96% done\n",
      "Window Segmentation 61.12% done\n",
      "Window Segmentation 61.28% done\n",
      "Window Segmentation 61.43% done\n",
      "Window Segmentation 61.59% done\n",
      "Window Segmentation 61.75% done\n",
      "Window Segmentation 61.91% done\n",
      "Window Segmentation 62.07% done\n",
      "Window Segmentation 62.23% done\n",
      "Window Segmentation 62.38% done\n",
      "Window Segmentation 62.54% done\n",
      "Window Segmentation 62.70% done\n",
      "Window Segmentation 62.86% done\n",
      "Window Segmentation 63.02% done\n",
      "Window Segmentation 63.18% done\n",
      "Window Segmentation 63.33% done\n",
      "Window Segmentation 63.49% done\n",
      "Window Segmentation 63.65% done\n",
      "Window Segmentation 63.81% done\n",
      "Window Segmentation 63.97% done\n",
      "Window Segmentation 64.13% done\n",
      "Window Segmentation 64.28% done\n",
      "Window Segmentation 64.44% done\n",
      "Window Segmentation 64.60% done\n",
      "Window Segmentation 64.76% done\n",
      "Window Segmentation 64.92% done\n",
      "Window Segmentation 65.08% done\n",
      "Window Segmentation 65.23% done\n",
      "Window Segmentation 65.39% done\n",
      "Window Segmentation 65.55% done\n",
      "Window Segmentation 65.71% done\n",
      "Window Segmentation 65.87% done\n",
      "Window Segmentation 66.03% done\n",
      "Window Segmentation 66.18% done\n",
      "Window Segmentation 66.34% done\n",
      "Window Segmentation 66.50% done\n",
      "Window Segmentation 66.66% done\n",
      "Window Segmentation 66.82% done\n",
      "Window Segmentation 66.98% done\n",
      "Window Segmentation 67.13% done\n",
      "Window Segmentation 67.29% done\n",
      "Window Segmentation 67.45% done\n",
      "Window Segmentation 67.61% done\n",
      "Window Segmentation 67.77% done\n",
      "Window Segmentation 67.93% done\n",
      "Window Segmentation 68.08% done\n",
      "Window Segmentation 68.24% done\n",
      "Window Segmentation 68.40% done\n",
      "Window Segmentation 68.56% done\n",
      "Window Segmentation 68.72% done\n",
      "Window Segmentation 68.88% done\n",
      "Window Segmentation 69.03% done\n",
      "Window Segmentation 69.19% done\n",
      "Window Segmentation 69.35% done\n",
      "Window Segmentation 69.51% done\n",
      "Window Segmentation 69.67% done\n",
      "Window Segmentation 69.83% done\n",
      "Window Segmentation 69.98% done\n",
      "Window Segmentation 70.14% done\n",
      "Window Segmentation 70.30% done\n",
      "Window Segmentation 70.46% done\n",
      "Window Segmentation 70.62% done\n",
      "Window Segmentation 70.78% done\n",
      "Window Segmentation 70.93% done\n",
      "Window Segmentation 71.09% done\n",
      "Window Segmentation 71.25% done\n",
      "Window Segmentation 71.41% done\n",
      "Window Segmentation 71.57% done\n",
      "Window Segmentation 71.73% done\n",
      "Window Segmentation 71.88% done\n",
      "Window Segmentation 72.04% done\n",
      "Window Segmentation 72.20% done\n",
      "Window Segmentation 72.36% done\n",
      "Window Segmentation 72.52% done\n",
      "Window Segmentation 72.68% done\n",
      "Window Segmentation 72.83% done\n",
      "Window Segmentation 72.99% done\n",
      "Window Segmentation 73.15% done\n",
      "Window Segmentation 73.31% done\n",
      "Window Segmentation 73.47% done\n",
      "Window Segmentation 73.63% done\n",
      "Window Segmentation 73.78% done\n",
      "Window Segmentation 73.94% done\n",
      "Window Segmentation 74.10% done\n",
      "Window Segmentation 74.26% done\n",
      "Window Segmentation 74.42% done\n",
      "Window Segmentation 74.58% done\n",
      "Window Segmentation 74.73% done\n",
      "Window Segmentation 74.89% done\n",
      "Window Segmentation 75.05% done\n",
      "Window Segmentation 75.21% done\n",
      "Window Segmentation 75.37% done\n",
      "Window Segmentation 75.53% done\n",
      "Window Segmentation 75.68% done\n",
      "Window Segmentation 75.84% done\n",
      "Window Segmentation 76.00% done\n",
      "Window Segmentation 76.16% done\n",
      "Window Segmentation 76.32% done\n",
      "Window Segmentation 76.48% done\n",
      "Window Segmentation 76.63% done\n",
      "Window Segmentation 76.79% done\n",
      "Window Segmentation 76.95% done\n",
      "Window Segmentation 77.11% done\n",
      "Window Segmentation 77.27% done\n",
      "Window Segmentation 77.43% done\n",
      "Window Segmentation 77.58% done\n",
      "Window Segmentation 77.74% done\n",
      "Window Segmentation 77.90% done\n",
      "Window Segmentation 78.06% done\n",
      "Window Segmentation 78.22% done\n",
      "Window Segmentation 78.38% done\n",
      "Window Segmentation 78.53% done\n",
      "Window Segmentation 78.69% done\n",
      "Window Segmentation 78.85% done\n",
      "Window Segmentation 79.01% done\n",
      "Window Segmentation 79.17% done\n",
      "Window Segmentation 79.33% done\n",
      "Window Segmentation 79.48% done\n",
      "Window Segmentation 79.64% done\n",
      "Window Segmentation 79.80% done\n",
      "Window Segmentation 79.96% done\n",
      "Window Segmentation 80.12% done\n",
      "Window Segmentation 80.28% done\n",
      "Window Segmentation 80.43% done\n",
      "Window Segmentation 80.59% done\n",
      "Window Segmentation 80.75% done\n",
      "Window Segmentation 80.91% done\n",
      "Window Segmentation 81.07% done\n",
      "Window Segmentation 81.23% done\n",
      "Window Segmentation 81.38% done\n",
      "Window Segmentation 81.54% done\n",
      "Window Segmentation 81.70% done\n",
      "Window Segmentation 81.86% done\n",
      "Window Segmentation 82.02% done\n",
      "Window Segmentation 82.18% done\n",
      "Window Segmentation 82.33% done\n",
      "Window Segmentation 82.49% done\n",
      "Window Segmentation 82.65% done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Segmentation 82.81% done\n",
      "Window Segmentation 82.97% done\n",
      "Window Segmentation 83.13% done\n",
      "Window Segmentation 83.28% done\n",
      "Window Segmentation 83.44% done\n",
      "Window Segmentation 83.60% done\n",
      "Window Segmentation 83.76% done\n",
      "Window Segmentation 83.92% done\n",
      "Window Segmentation 84.08% done\n",
      "Window Segmentation 84.23% done\n",
      "Window Segmentation 84.39% done\n",
      "Window Segmentation 84.55% done\n",
      "Window Segmentation 84.71% done\n",
      "Window Segmentation 84.87% done\n",
      "Window Segmentation 85.03% done\n",
      "Window Segmentation 85.18% done\n",
      "Window Segmentation 85.34% done\n",
      "Window Segmentation 85.50% done\n",
      "Window Segmentation 85.66% done\n",
      "Window Segmentation 85.82% done\n",
      "Window Segmentation 85.98% done\n",
      "Window Segmentation 86.14% done\n",
      "Window Segmentation 86.29% done\n",
      "Window Segmentation 86.45% done\n",
      "Window Segmentation 86.61% done\n",
      "Window Segmentation 86.77% done\n",
      "Window Segmentation 86.93% done\n",
      "Window Segmentation 87.09% done\n",
      "Window Segmentation 87.24% done\n",
      "Window Segmentation 87.40% done\n",
      "Window Segmentation 87.56% done\n",
      "Window Segmentation 87.72% done\n",
      "Window Segmentation 87.88% done\n",
      "Window Segmentation 88.04% done\n",
      "Window Segmentation 88.19% done\n",
      "Window Segmentation 88.35% done\n",
      "Window Segmentation 88.51% done\n",
      "Window Segmentation 88.67% done\n",
      "Window Segmentation 88.83% done\n",
      "Window Segmentation 88.99% done\n",
      "Window Segmentation 89.14% done\n",
      "Window Segmentation 89.30% done\n",
      "Window Segmentation 89.46% done\n",
      "Window Segmentation 89.62% done\n",
      "Window Segmentation 89.78% done\n",
      "Window Segmentation 89.94% done\n",
      "Window Segmentation 90.09% done\n",
      "Window Segmentation 90.25% done\n",
      "Window Segmentation 90.41% done\n",
      "Window Segmentation 90.57% done\n",
      "Window Segmentation 90.73% done\n",
      "Window Segmentation 90.89% done\n",
      "Window Segmentation 91.04% done\n",
      "Window Segmentation 91.20% done\n",
      "Window Segmentation 91.36% done\n",
      "Window Segmentation 91.52% done\n",
      "Window Segmentation 91.68% done\n",
      "Window Segmentation 91.84% done\n",
      "Window Segmentation 91.99% done\n",
      "Window Segmentation 92.15% done\n",
      "Window Segmentation 92.31% done\n",
      "Window Segmentation 92.47% done\n",
      "Window Segmentation 92.63% done\n",
      "Window Segmentation 92.79% done\n",
      "Window Segmentation 92.94% done\n",
      "Window Segmentation 93.10% done\n",
      "Window Segmentation 93.26% done\n",
      "Window Segmentation 93.42% done\n",
      "Window Segmentation 93.58% done\n",
      "Window Segmentation 93.74% done\n",
      "Window Segmentation 93.89% done\n",
      "Window Segmentation 94.05% done\n",
      "Window Segmentation 94.21% done\n",
      "Window Segmentation 94.37% done\n",
      "Window Segmentation 94.53% done\n",
      "Window Segmentation 94.69% done\n",
      "Window Segmentation 94.84% done\n",
      "Window Segmentation 95.00% done\n",
      "Window Segmentation 95.16% done\n",
      "Window Segmentation 95.32% done\n",
      "Window Segmentation 95.48% done\n",
      "Window Segmentation 95.64% done\n",
      "Window Segmentation 95.79% done\n",
      "Window Segmentation 95.95% done\n",
      "Window Segmentation 96.11% done\n",
      "Window Segmentation 96.27% done\n",
      "Window Segmentation 96.43% done\n",
      "Window Segmentation 96.59% done\n",
      "Window Segmentation 96.74% done\n",
      "Window Segmentation 96.90% done\n",
      "Window Segmentation 97.06% done\n",
      "Window Segmentation 97.22% done\n",
      "Window Segmentation 97.38% done\n",
      "Window Segmentation 97.54% done\n",
      "Window Segmentation 97.69% done\n",
      "Window Segmentation 97.85% done\n",
      "Window Segmentation 98.01% done\n",
      "Window Segmentation 98.17% done\n",
      "Window Segmentation 98.33% done\n",
      "Window Segmentation 98.49% done\n",
      "Window Segmentation 98.64% done\n",
      "Window Segmentation 98.80% done\n",
      "Window Segmentation 98.96% done\n",
      "Window Segmentation 99.12% done\n",
      "Window Segmentation 99.28% done\n",
      "Window Segmentation 99.44% done\n",
      "Window Segmentation 99.59% done\n",
      "Window Segmentation 99.75% done\n",
      "Window Segmentation 99.91% done\n"
     ]
    }
   ],
   "source": [
    "segments, labels = segment_signal(normalized_lake_dataset, 36, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 36, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 1, 36, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_segments = segments.reshape(len(segments), 1, 36, 5)\n",
    "reshaped_segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24542091b00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEMAAAD8CAYAAAAsVhnTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVWMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24541f50470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reshaped_segments[1000][0] * 255, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped_segments_as_image = segments.reshape(len(segments), 6, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 36, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 6, 6, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_segments_as_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels = labels.reshape(len(labels), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels = np.zeros((len(labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "while(iter < len(labels)):\n",
    "    if labels[iter] > 0.0:\n",
    "        print(iter)\n",
    "    new_labels[iter][int(labels[iter])] = 1\n",
    "    iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels[1500:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break apart the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CNNHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.iterator = 0\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(reshaped_segments_as_image, labels, test_size=0.3, random_state=101)\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.X_train[self.iterator:self.iterator + batch_size]\n",
    "        y = self.y_train[self.iterator:self.iterator + batch_size]\n",
    "        self.iterator = (self.iterator + batch_size) % len(self.X_train)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 6, 6, 5])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[2,2,5,6])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[2,2,6,12])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 4*12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(64)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_one_dropout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,2)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "cnn_helper = CNNHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1892, 6, 6, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_helper.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.5749782 ,  0.91763073,  0.47173134,  0.42307692,  0.18909091],\n",
       "        [ 0.5793374 ,  0.91716798,  0.49248475,  0.42307692,  0.18545455],\n",
       "        [ 0.58238884,  0.89958353,  0.49102258,  0.41538462,  0.18272727],\n",
       "        [ 0.581517  ,  0.89958353,  0.528363  ,  0.41538462,  0.18363636],\n",
       "        [ 0.58064516,  0.89819528,  0.53306396,  0.41538462,  0.18363636],\n",
       "        [ 0.58064516,  0.90189727,  0.52944783,  0.41538462,  0.18636364]],\n",
       "\n",
       "       [[ 0.58108108,  0.90652476,  0.55636438,  0.41538462,  0.18636364],\n",
       "        [ 0.57890148,  0.9106895 ,  0.5577165 ,  0.41538462,  0.18909091],\n",
       "        [ 0.57802964,  0.91207774,  0.5577165 ,  0.41538462,  0.19      ],\n",
       "        [ 0.57585004,  0.91577973,  0.58389409,  0.41538462,  0.19181818],\n",
       "        [ 0.57628596,  0.91716798,  0.56215018,  0.41538462,  0.19454545],\n",
       "        [ 0.5771578 ,  0.91439149,  0.56329791,  0.41538462,  0.19363636]],\n",
       "\n",
       "       [[ 0.57672188,  0.91439149,  0.61592038,  0.41538462,  0.19454545],\n",
       "        [ 0.57672188,  0.91115224,  0.61860889,  0.41538462,  0.19545455],\n",
       "        [ 0.57672188,  0.909764  ,  0.63134394,  0.41538462,  0.19636364],\n",
       "        [ 0.5771578 ,  0.90606201,  0.6047104 ,  0.41538462,  0.19636364],\n",
       "        [ 0.57802964,  0.88847756,  0.55083014,  0.41538462,  0.19636364],\n",
       "        [ 0.5793374 ,  0.86904211,  0.5260361 ,  0.40769231,  0.19636364]],\n",
       "\n",
       "       [[ 0.58195292,  0.85978714,  0.46975033,  0.40769231,  0.19727273],\n",
       "        [ 0.5836966 ,  0.8546969 ,  0.49000063,  0.41538462,  0.19727273],\n",
       "        [ 0.5858762 ,  0.84683017,  0.48393183,  0.41538462,  0.19636364],\n",
       "        [ 0.58631212,  0.84544193,  0.50682347,  0.41538462,  0.19636364],\n",
       "        [ 0.58544028,  0.84775567,  0.45251871,  0.40769231,  0.19727273],\n",
       "        [ 0.58282476,  0.8546969 ,  0.43127791,  0.41538462,  0.19818182]],\n",
       "\n",
       "       [[ 0.5793374 ,  0.86024988,  0.45174832,  0.40769231,  0.19727273],\n",
       "        [ 0.57672188,  0.86348913,  0.48070876,  0.40769231,  0.19818182],\n",
       "        [ 0.57279861,  0.87413235,  0.50367901,  0.41538462,  0.19909091],\n",
       "        [ 0.56974717,  0.88153633,  0.4966826 ,  0.41538462,  0.20090909],\n",
       "        [ 0.56713165,  0.88477557,  0.51743601,  0.41538462,  0.20272727],\n",
       "        [ 0.56495205,  0.88431282,  0.49440287,  0.41538462,  0.20363636]],\n",
       "\n",
       "       [[ 0.56277245,  0.88246182,  0.46630715,  0.41538462,  0.20363636],\n",
       "        [ 0.56102877,  0.87690884,  0.48404188,  0.41538462,  0.20454545],\n",
       "        [ 0.55928509,  0.87089311,  0.46251808,  0.41538462,  0.20454545],\n",
       "        [ 0.55754141,  0.86580287,  0.41997359,  0.41538462,  0.20454545],\n",
       "        [ 0.55797733,  0.86580287,  0.43209547,  0.41538462,  0.20363636],\n",
       "        [ 0.55666957,  0.86302638,  0.3964845 ,  0.41538462,  0.20272727]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_helper.X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnn_helper.X_test = np.zeros((1892, 6, 6, 3))\n",
    "# cnn_helper.X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.612579\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.650106\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.838266\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.846723\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.849366\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.857294\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.861522\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.876321\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.876321\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.865222\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.886892\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.880021\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.873679\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.890063\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.874207\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.89112\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is:\n",
      "0.897463\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is:\n",
      "0.895877\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is:\n",
      "0.894292\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is:\n",
      "0.885835\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is:\n",
      "0.897463\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is:\n",
      "0.897992\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is:\n",
      "0.897992\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is:\n",
      "0.89852\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is:\n",
      "0.89482\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is:\n",
      "0.901691\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is:\n",
      "0.893235\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is:\n",
      "0.868393\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is:\n",
      "0.896934\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is:\n",
      "0.892178\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is:\n",
      "0.900106\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "Accuracy is:\n",
      "0.896406\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "Accuracy is:\n",
      "0.895877\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "Accuracy is:\n",
      "0.903805\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "Accuracy is:\n",
      "0.902748\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "Accuracy is:\n",
      "0.899577\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "Accuracy is:\n",
      "0.89852\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "Accuracy is:\n",
      "0.903277\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "Accuracy is:\n",
      "0.900634\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "Accuracy is:\n",
      "0.90222\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cost_history = []\n",
    "    acc_history = []\n",
    "\n",
    "    for i in range(4000):\n",
    "        batch = cnn_helper.next_batch(100)\n",
    "        _, c = sess.run([train, cross_entropy], feed_dict={x: batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "        cost_history.append(c)\n",
    "        \n",
    "        matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "        acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "        acc_history.append(acc)\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:cnn_helper.X_test,y_true:cnn_helper.y_test,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2456d009fd0>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2456cf73e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_history)\n",
    "# plt.plot(acc_history)\n",
    "# plt.figure(figsize=(20,10))\n",
    "# acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
