{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "from scripts.functions import create_model\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variables to be used in Keras and the CNN\n",
    "\n",
    "# number of items to use for training\n",
    "BATCH_SIZE = 400 \n",
    "\n",
    "# Number of identifying classes \n",
    "#   WE have two, Bloom and no bloom 1/0\n",
    "NUM_CLASSES = 2 \n",
    "\n",
    "# number of times to repeat process\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>Chlorophyll (ug/L)</th>\n",
       "      <th>Chlorophyll RFU</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.02             1848   -100.1  8.36   \n",
       "1          5/5/2017      0:15   14.99             1847   -100.1  8.36   \n",
       "2          5/5/2017      0:30   14.96             1847   -100.1  8.36   \n",
       "3          5/5/2017      0:45   14.95             1848   -100.1  8.36   \n",
       "4          5/5/2017      1:00   14.92             1848   -100.0  8.36   \n",
       "\n",
       "   Turbidity (NTU)  Chlorophyll (ug/L)  Chlorophyll RFU  ODOSat%  ODO (mg/L)  \\\n",
       "0            16.84                 4.4              1.3     90.2        9.04   \n",
       "1            16.76                 4.2              1.2     90.2        9.04   \n",
       "2            16.82                 4.3              1.3     90.1        9.04   \n",
       "3            17.19                 4.5              1.3     90.0        9.03   \n",
       "4            16.85                 4.5              1.3     89.8        9.02   \n",
       "\n",
       "   BGA-Phycocyanin RFU  \n",
       "0                  0.4  \n",
       "1                  0.4  \n",
       "2                  0.4  \n",
       "3                  0.4  \n",
       "4                  0.4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../../data/cleaned/site1_vineyard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.02             1848   -100.1  8.36   \n",
       "1          5/5/2017      0:15   14.99             1847   -100.1  8.36   \n",
       "2          5/5/2017      0:30   14.96             1847   -100.1  8.36   \n",
       "3          5/5/2017      0:45   14.95             1848   -100.1  8.36   \n",
       "4          5/5/2017      1:00   14.92             1848   -100.0  8.36   \n",
       "\n",
       "   Turbidity (NTU)  ODOSat%  ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)  \n",
       "0            16.84     90.2        9.04                  0.4    1.713796  \n",
       "1            16.76     90.2        9.04                  0.4    1.713796  \n",
       "2            16.82     90.1        9.04                  0.4    1.713796  \n",
       "3            17.19     90.0        9.03                  0.4    1.713796  \n",
       "4            16.85     89.8        9.02                  0.4    1.713796  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "target\n",
    "dataset = df.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "dataset['BGA (ug/L)'] = target\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.02             1848   -100.1  8.36   \n",
       "1          5/5/2017      0:15   14.99             1847   -100.1  8.36   \n",
       "2          5/5/2017      0:30   14.96             1847   -100.1  8.36   \n",
       "3          5/5/2017      0:45   14.95             1848   -100.1  8.36   \n",
       "4          5/5/2017      1:00   14.92             1848   -100.0  8.36   \n",
       "\n",
       "   Turbidity (NTU)  ODOSat%  ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)  \\\n",
       "0            16.84     90.2        9.04                  0.4    1.713796   \n",
       "1            16.76     90.2        9.04                  0.4    1.713796   \n",
       "2            16.82     90.1        9.04                  0.4    1.713796   \n",
       "3            17.19     90.0        9.03                  0.4    1.713796   \n",
       "4            16.85     89.8        9.02                  0.4    1.713796   \n",
       "\n",
       "            Timestamp  \n",
       "0 2017-05-05 00:00:00  \n",
       "1 2017-05-05 00:15:00  \n",
       "2 2017-05-05 00:30:00  \n",
       "3 2017-05-05 00:45:00  \n",
       "4 2017-05-05 01:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = dataset['Date (mm.dd.yyyy)'] + ' '+ dataset['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "dataset['Timestamp'] = timestamp\n",
    "dataset.head()\n",
    "#converts the date object to a numerical representation of that object\n",
    "#dataset['date (mm.dd.yyyy)'] = (dataset['date (mm.dd.yyyy)'] - dataset['date (mm.dd.yyyy)'].min()) / np.timedelta64(1,'D')\n",
    "#dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.92</td>\n",
       "      <td>1850</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.43</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.90</td>\n",
       "      <td>1851</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.35</td>\n",
       "      <td>89.7</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.88</td>\n",
       "      <td>1852</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.40</td>\n",
       "      <td>89.6</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.84</td>\n",
       "      <td>1850</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>89.4</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1851</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.50</td>\n",
       "      <td>89.4</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 02:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temp C  Sp Cond (uS/cm)  pH (mV)    pH  Turbidity (NTU)  ODOSat%  \\\n",
       "0   15.02             1848   -100.1  8.36            16.84     90.2   \n",
       "1   14.99             1847   -100.1  8.36            16.76     90.2   \n",
       "2   14.96             1847   -100.1  8.36            16.82     90.1   \n",
       "3   14.95             1848   -100.1  8.36            17.19     90.0   \n",
       "4   14.92             1848   -100.0  8.36            16.85     89.8   \n",
       "5   14.92             1850   -100.1  8.36            16.43     89.8   \n",
       "6   14.90             1851   -100.1  8.36            16.35     89.7   \n",
       "7   14.88             1852   -100.0  8.36            16.40     89.6   \n",
       "8   14.84             1850    -99.9  8.36            16.82     89.4   \n",
       "9   14.83             1851   -100.0  8.36            16.50     89.4   \n",
       "\n",
       "   ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)           Timestamp  \n",
       "0        9.04                  0.4    1.713796 2017-05-05 00:00:00  \n",
       "1        9.04                  0.4    1.713796 2017-05-05 00:15:00  \n",
       "2        9.04                  0.4    1.713796 2017-05-05 00:30:00  \n",
       "3        9.03                  0.4    1.713796 2017-05-05 00:45:00  \n",
       "4        9.02                  0.4    1.713796 2017-05-05 01:00:00  \n",
       "5        9.02                  0.4    1.713796 2017-05-05 01:15:00  \n",
       "6        9.01                  0.4    1.713796 2017-05-05 01:30:00  \n",
       "7        9.00                  0.4    1.713796 2017-05-05 01:45:00  \n",
       "8        8.99                  0.4    1.713796 2017-05-05 02:00:00  \n",
       "9        8.99                  0.4    1.713796 2017-05-05 02:15:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dont need data and time now that we have Timestamp. Lets remove them\n",
    "\n",
    "dataset = dataset.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temp C                        float64\n",
       "Sp Cond (uS/cm)                 int64\n",
       "pH (mV)                       float64\n",
       "pH                            float64\n",
       "Turbidity (NTU)               float64\n",
       "ODOSat%                       float64\n",
       "ODO (mg/L)                    float64\n",
       "BGA-Phycocyanin RFU           float64\n",
       "BGA (ug/L)                    float64\n",
       "Timestamp              datetime64[ns]\n",
       "Bloom                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = dataset['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "dataset['Bloom'] = target\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>Bloom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.560516</td>\n",
       "      <td>0.893366</td>\n",
       "      <td>0.477889</td>\n",
       "      <td>0.541089</td>\n",
       "      <td>0.090355</td>\n",
       "      <td>0.165126</td>\n",
       "      <td>0.273546</td>\n",
       "      <td>0.005120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.267413</td>\n",
       "      <td>0.070246</td>\n",
       "      <td>0.116241</td>\n",
       "      <td>0.113254</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>0.093899</td>\n",
       "      <td>0.116220</td>\n",
       "      <td>0.071369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.308195</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.117086</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.640366</td>\n",
       "      <td>0.895882</td>\n",
       "      <td>0.492228</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.065216</td>\n",
       "      <td>0.138870</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.784656</td>\n",
       "      <td>0.956502</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>0.177672</td>\n",
       "      <td>0.370909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Temp C  Sp Cond (uS/cm)       pH (mV)            pH  \\\n",
       "count  18947.000000     18947.000000  18947.000000  18947.000000   \n",
       "mean       0.560516         0.893366      0.477889      0.541089   \n",
       "std        0.267413         0.070246      0.116241      0.113254   \n",
       "min        0.000000         0.000000      0.000000      0.000000   \n",
       "25%        0.308195         0.853771      0.426166      0.461538   \n",
       "50%        0.640366         0.895882      0.492228      0.553846   \n",
       "75%        0.784656         0.956502      0.538860      0.592308   \n",
       "max        1.000000         1.000000      1.000000      1.000000   \n",
       "\n",
       "       Turbidity (NTU)       ODOSat%    ODO (mg/L)         Bloom  \n",
       "count     18947.000000  18947.000000  18947.000000  18947.000000  \n",
       "mean          0.090355      0.165126      0.273546      0.005120  \n",
       "std           0.085879      0.093899      0.116220      0.071369  \n",
       "min           0.000000      0.000000      0.000000      0.000000  \n",
       "25%           0.045893      0.117086      0.190000      0.000000  \n",
       "50%           0.065216      0.138870      0.264545      0.000000  \n",
       "75%           0.102407      0.177672      0.370909      0.000000  \n",
       "max           1.000000      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try to normalize this now....\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "dataset_columns = ['Temp C','Sp Cond (uS/cm)', 'pH (mV)','pH', 'Turbidity (NTU)', 'ODOSat%','ODO (mg/L)', 'Bloom']\n",
    "scaler = MinMaxScaler()\n",
    "ds_scaled = scaler.fit_transform(dataset[dataset_columns])\n",
    "dataset = pd.DataFrame(ds_scaled,columns=dataset_columns)\n",
    "dataset.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to take a moving window of the data of 10 time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "determines the window size for the daata set\n",
    "@param dataset - The dataset to get windows for\n",
    "@param window_size - the size of the window  \n",
    "@param shift - the amout to shift the window\n",
    "'''\n",
    "def windows(dataset, window_size, shift):\n",
    "    start = 0\n",
    "    while start+window_size < dataset.shape[0]: \n",
    "        yield (int(start), int(start+window_size))\n",
    "        # shift the window five blocks of time\n",
    "        start += shift\n",
    "        if start % 300 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format(((start+window_size) / dataset.shape[0]) * 100 ))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Segments the dataset based on the parameters that are passed in.\n",
    "@param dataset - the dataset to segment into window\n",
    "@param columns - the array of columns from the dataset to be looked at\n",
    "@param window_size - the size of the window you would like to be looked at. Defualt is 10\n",
    "\n",
    "'''\n",
    "def segment_dataset(dataset, columns, target, window_size=10):    \n",
    "    print('WINDOW SIZE',window_size)\n",
    "    print('NUMBER OF COULUMNS',len(columns))\n",
    "    segments = np.empty((0, window_size, len(columns)))\n",
    "    labels = np.empty((0))\n",
    "    count = 0\n",
    "    for (start, end) in windows(dataset, window_size, 1):\n",
    "        count+=1\n",
    "        values = dataset[columns][start:end]\n",
    "        if(values.shape[0] == window_size):\n",
    "            segments = np.vstack([segments, np.stack([values])])\n",
    "            # Takes the larger of the two variables if there are more than one. \n",
    "            # This makes it more likly to predict a bloom. Can be changed to iloc[0] to\n",
    "            # be less likly to predict a bloom (more 0s in the label array)\n",
    "            \n",
    "            labels = np.append(labels, dataset[target][start:end].mode().iloc[-1])\n",
    "        else:\n",
    "            print(\"No more Windows available... Exiting\")\n",
    "            break\n",
    "    return (segments, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.63% done\n",
      "Window Segmentation 3.21% done\n",
      "Window Segmentation 4.80% done\n",
      "Window Segmentation 6.38% done\n",
      "Window Segmentation 7.96% done\n",
      "Window Segmentation 9.55% done\n",
      "Window Segmentation 11.13% done\n",
      "Window Segmentation 12.71% done\n",
      "Window Segmentation 14.30% done\n",
      "Window Segmentation 15.88% done\n",
      "Window Segmentation 17.46% done\n",
      "Window Segmentation 19.05% done\n",
      "Window Segmentation 20.63% done\n",
      "Window Segmentation 22.21% done\n",
      "Window Segmentation 23.80% done\n",
      "Window Segmentation 25.38% done\n",
      "Window Segmentation 26.96% done\n",
      "Window Segmentation 28.55% done\n",
      "Window Segmentation 30.13% done\n",
      "Window Segmentation 31.71% done\n",
      "Window Segmentation 33.30% done\n",
      "Window Segmentation 34.88% done\n",
      "Window Segmentation 36.46% done\n",
      "Window Segmentation 38.05% done\n",
      "Window Segmentation 39.63% done\n",
      "Window Segmentation 41.21% done\n",
      "Window Segmentation 42.80% done\n",
      "Window Segmentation 44.38% done\n",
      "Window Segmentation 45.97% done\n",
      "Window Segmentation 47.55% done\n",
      "Window Segmentation 49.13% done\n",
      "Window Segmentation 50.72% done\n",
      "Window Segmentation 52.30% done\n",
      "Window Segmentation 53.88% done\n",
      "Window Segmentation 55.47% done\n",
      "Window Segmentation 57.05% done\n",
      "Window Segmentation 58.63% done\n",
      "Window Segmentation 60.22% done\n",
      "Window Segmentation 61.80% done\n",
      "Window Segmentation 63.38% done\n",
      "Window Segmentation 64.97% done\n",
      "Window Segmentation 66.55% done\n",
      "Window Segmentation 68.13% done\n",
      "Window Segmentation 69.72% done\n",
      "Window Segmentation 71.30% done\n",
      "Window Segmentation 72.88% done\n",
      "Window Segmentation 74.47% done\n",
      "Window Segmentation 76.05% done\n",
      "Window Segmentation 77.63% done\n",
      "Window Segmentation 79.22% done\n",
      "Window Segmentation 80.80% done\n",
      "Window Segmentation 82.38% done\n",
      "Window Segmentation 83.97% done\n",
      "Window Segmentation 85.55% done\n",
      "Window Segmentation 87.13% done\n",
      "Window Segmentation 88.72% done\n",
      "Window Segmentation 90.30% done\n",
      "Window Segmentation 91.88% done\n",
      "Window Segmentation 93.47% done\n",
      "Window Segmentation 95.05% done\n",
      "Window Segmentation 96.63% done\n",
      "Window Segmentation 98.22% done\n",
      "Window Segmentation 99.80% done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "feature_columns = dataset_columns[:-1]\n",
    "(segments, labels) = segment_dataset(dataset, feature_columns, 'Bloom', 9)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938, 9, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaping the data to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938, 9, 7, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = segments.reshape(len(segments),9,7,1)\n",
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS0AAAAkCAYAAADcm2ySAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABMNJREFUeJztnE1oXFUUx3/HNlEMNTQVaxUKCiLdKPiBiAYFEUtE2oULXYiLaikudCUGBDcqUhWXLlxIiAsV3NiFtLY1tZsWjPiRKMTaClKoxmhFotg29bi4N+k4TpPJm/cx983/B0Pu+8j73XOYHO57796YuyOEEKlwSdUdEEKI1aCiJYRIChUtIURSqGgJIZJCRUsIkRQqWkKIpOioaJnZVjObMbPvzWw0r051k7PuviqcdfdV4eyFGJe8Wedpmdka4G/gOHAGuAG4zd2/za971Trr7qvCWXdfFc5eiLGRFUdaZva2mc2a2XTDviHgCLAG+Am4F3gR2JZHp8p21t1XhbNbYgTuI3zP+4BZ4LUifb2Q06KdK9HO7eEYsLVp3yjwHfAncDhunwSuzalfZTvr7qvCWbbvYs6ngAXgDuAgcGvBvl7IadHOZVmxaLn7YeC3pt3bgE9jezvwDKHa/u9e08x2mtmkmU329fW1dS/aibNsXxancrq8L2fn7cA54GPgUeDugn2ZcmpmvxTpa+VcydepM4uvHbI+iN8ITAOfu/tNhHvbEaC/xbnDwBZgy8LCQicdb9dZti8vp3JajPMKYNLdbwHuj9vdltMFYF3BvmZnSt+b/9DJ28PPgM1mdh2hwhrwR/NJ7v6Yuw+4+wAtqn/ezrJ9OTuV0/yd5xt8v8d93ZbTr2I/C/O1cKb2vVkia9H6GdgMPAscAAYIbxAO5tSvbnDW3VeFs4oYZ4GXgX3AMUJxUE7Tcy6xNuPv7QF2AQ8AlxMq7FvuvjevjnWBs+6+KpxVxHgIeIlQvAaBI8ppks4LuPuyH+Bd4BThYeZJYAewgVBVj8WfQytdJ17raJvn5eIs29euUzlVjE3X2Qm8o5y298k8uVQIIapAaw+FEGmR15CtaSj4PHCWMKScIwwj9wPr4/EnCK9JzxAmqP0DfBk/exLynSU8iNzf6Gzhe47wADjFGEvx9UKMymk+vlyLVexUX+zwPcAbsf0QYdbs7njOODAd248A5xL1DcT2WDw2Cuxu4XsfmE80xsJ9vRCjcpqfL3NClun4k8BcbM8AE8BeYBMwE/dPAR/E9lriPI/UfHF7HpiI7U2xD82+OTorWrXOaS/EqJzm5yvimdaNhD9SCDNnZ4Br3P0UcFXcvx4YNrOvgffivi/M7KiZbU/IByHxGwAanM2+eeCyuKQhtRjL8FXhrLuvCmcpvqzztJYwswPA1Q27NgLrzKxxxXfzK8p5YMTdT5jZLuBBwmr8QeATM5ty9+Pd4GvhXPRNE+7f2/GNADe7+zdmdn23xdgFOa1djMppMTGGK2YcenY4RNwH3Bnb/YSHcYvTL8aAh1Pwxe1Wt4cX9aUWYxm+XohROc3PV8Tt4TgwaGbDwEeEVfVvAo8DH8ZzDsVtCA/sTru7m9mVwF3Aav6RWGU+MxsALgV+jMcWnY2+Vwhr3voBUouxJF8vxKic5uVbTeVeRcV9gQuvPX8lvPY8Dbwej4/H44uvPU8QFo1OATsS800QZgX/BfwADAGvEkZg5wlLHJ6OrlRjLNzXCzEqp/n4NCNeCJEUmhEvhEgKFS0hRFKoaAkhkkJFSwiRFCpaQoikUNESQiSFipYQIilUtIQQSfEvi9PXTjwosD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x2880 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what the heck does this look like now?\n",
    "X = 5\n",
    "y = 40\n",
    "plt.figure(figsize=(X,y))\n",
    "columns = 10\n",
    "for x in range(0, 10):\n",
    "    plt.subplot(len(segments) / columns + 1, columns, x + 1)\n",
    "    plt.imshow(segments[x][0]*255,cmap='gray')\n",
    "#plt.imshow(segments[0][0] * 255, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.reshape(labels.shape[0],1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking apart training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(segments, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (17044, 9, 7, 1)\n",
      "x_test shape: (1894, 9, 7, 1)\n",
      "y_train shape: (17044, 1)\n",
      "y_test shape: (1894, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"x_test shape:\",x_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mod = ks.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_mod = ks.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "input_shape = (9,7,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Activation, MaxPooling2D\n",
    "\n",
    "# Gets the precision of the different metrics\n",
    "def create_class_predictions(pred):\n",
    "    retval = np.array([])\n",
    "    for row in pred:\n",
    "        max_value = (-1,-1)\n",
    "        for index, value in enumerate(row):\n",
    "            if value > max_value[1]:\n",
    "                max_value = (index, value)\n",
    "        retval = np.append(retval, max_value[0])\n",
    "    return retval\n",
    "\n",
    "\n",
    "def create_layers(num_layers):\n",
    "    layers = [Flatten(), Dropout(0.2), Dense(NUM_CLASSES, activation='softmax', input_dim=2)]\n",
    "    for i in range(0, num_layers):\n",
    "        layers.insert(0, Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Come on, let's create the model already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...And Here we go....\n",
      "Started at 2019-01-15 17:30:55\n",
      "Epoch 1/200\n",
      "17044/17044 [==============================] - 1s 57us/step - loss: 0.2440 - acc: 0.9928\n",
      "Epoch 2/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0295 - acc: 0.9960\n",
      "Epoch 3/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0281 - acc: 0.9960\n",
      "Epoch 4/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0273 - acc: 0.9960\n",
      "Epoch 5/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0258 - acc: 0.9960\n",
      "Epoch 6/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0245 - acc: 0.9960\n",
      "Epoch 7/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0222 - acc: 0.9960\n",
      "Epoch 8/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0202 - acc: 0.9960\n",
      "Epoch 9/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0184 - acc: 0.9960\n",
      "Epoch 10/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0176 - acc: 0.9960\n",
      "Epoch 11/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0173 - acc: 0.9960\n",
      "Epoch 12/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0171 - acc: 0.9960\n",
      "Epoch 13/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0167 - acc: 0.9960\n",
      "Epoch 14/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0162 - acc: 0.9958\n",
      "Epoch 15/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0159 - acc: 0.9959\n",
      "Epoch 16/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0160 - acc: 0.9958\n",
      "Epoch 17/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0152 - acc: 0.9960\n",
      "Epoch 18/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0159 - acc: 0.9961\n",
      "Epoch 19/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0150 - acc: 0.9962\n",
      "Epoch 20/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0145 - acc: 0.9961\n",
      "Epoch 21/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0148 - acc: 0.9961\n",
      "Epoch 22/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0143 - acc: 0.9961\n",
      "Epoch 23/200\n",
      "17044/17044 [==============================] - 0s 23us/step - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 24/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0140 - acc: 0.9963\n",
      "Epoch 25/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0139 - acc: 0.9961\n",
      "Epoch 26/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0135 - acc: 0.9961\n",
      "Epoch 27/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0134 - acc: 0.9963\n",
      "Epoch 28/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0136 - acc: 0.9962\n",
      "Epoch 29/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 30/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0133 - acc: 0.9961\n",
      "Epoch 31/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0129 - acc: 0.9962\n",
      "Epoch 32/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0126 - acc: 0.9965\n",
      "Epoch 33/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0126 - acc: 0.9962\n",
      "Epoch 34/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0126 - acc: 0.9964\n",
      "Epoch 35/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0126 - acc: 0.9963\n",
      "Epoch 36/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0127 - acc: 0.9961\n",
      "Epoch 37/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 38/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 39/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0121 - acc: 0.9964\n",
      "Epoch 40/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 41/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 42/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0126 - acc: 0.9962\n",
      "Epoch 43/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0116 - acc: 0.9962\n",
      "Epoch 44/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 45/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0113 - acc: 0.9964\n",
      "Epoch 46/200\n",
      "17044/17044 [==============================] - 0s 23us/step - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 47/200\n",
      "17044/17044 [==============================] - 0s 23us/step - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 48/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0117 - acc: 0.9962\n",
      "Epoch 49/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0117 - acc: 0.9963\n",
      "Epoch 50/200\n",
      "17044/17044 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.996 - 0s 21us/step - loss: 0.0112 - acc: 0.9964\n",
      "Epoch 51/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0114 - acc: 0.9965\n",
      "Epoch 52/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0110 - acc: 0.9964\n",
      "Epoch 53/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 54/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0105 - acc: 0.9965\n",
      "Epoch 55/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0107 - acc: 0.9964\n",
      "Epoch 56/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0104 - acc: 0.9967\n",
      "Epoch 57/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0107 - acc: 0.9966\n",
      "Epoch 58/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0105 - acc: 0.9964\n",
      "Epoch 59/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0101 - acc: 0.9967\n",
      "Epoch 60/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 61/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 62/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0100 - acc: 0.9965\n",
      "Epoch 63/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0100 - acc: 0.9968\n",
      "Epoch 64/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0097 - acc: 0.9971\n",
      "Epoch 65/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 66/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 67/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0096 - acc: 0.9968\n",
      "Epoch 68/200\n",
      "17044/17044 [==============================] - 0s 23us/step - loss: 0.0094 - acc: 0.9971\n",
      "Epoch 69/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 70/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0095 - acc: 0.9967\n",
      "Epoch 71/200\n",
      "17044/17044 [==============================] - 0s 23us/step - loss: 0.0090 - acc: 0.9971\n",
      "Epoch 72/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 73/200\n",
      "17044/17044 [==============================] - 0s 23us/step - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 74/200\n",
      "17044/17044 [==============================] - 1s 34us/step - loss: 0.0088 - acc: 0.9970\n",
      "Epoch 75/200\n",
      "17044/17044 [==============================] - 0s 27us/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 76/200\n",
      "17044/17044 [==============================] - 0s 25us/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 77/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0088 - acc: 0.9971\n",
      "Epoch 78/200\n",
      "17044/17044 [==============================] - 0s 23us/step - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 79/200\n",
      "17044/17044 [==============================] - 0s 24us/step - loss: 0.0085 - acc: 0.9975: 0s - loss: 0.0075 - acc: \n",
      "Epoch 80/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 81/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 82/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0082 - acc: 0.9972\n",
      "Epoch 83/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0081 - acc: 0.9972\n",
      "Epoch 84/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 85/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0077 - acc: 0.9974\n",
      "Epoch 86/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0075 - acc: 0.9974\n",
      "Epoch 87/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 88/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0077 - acc: 0.9974\n",
      "Epoch 89/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 90/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0071 - acc: 0.9975\n",
      "Epoch 91/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 92/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0068 - acc: 0.9976\n",
      "Epoch 93/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0068 - acc: 0.9977\n",
      "Epoch 94/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 95/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0066 - acc: 0.9978\n",
      "Epoch 96/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0065 - acc: 0.9975\n",
      "Epoch 97/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 98/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0069 - acc: 0.9976\n",
      "Epoch 99/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0064 - acc: 0.9977\n",
      "Epoch 100/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0068 - acc: 0.9979\n",
      "Epoch 101/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0069 - acc: 0.9975\n",
      "Epoch 102/200\n",
      "17044/17044 [==============================] - 0s 24us/step - loss: 0.0066 - acc: 0.9978\n",
      "Epoch 103/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 104/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 105/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0062 - acc: 0.9980\n",
      "Epoch 106/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 107/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0059 - acc: 0.9981\n",
      "Epoch 108/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0057 - acc: 0.9977\n",
      "Epoch 109/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0062 - acc: 0.9979\n",
      "Epoch 110/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0056 - acc: 0.9979\n",
      "Epoch 111/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0059 - acc: 0.9981\n",
      "Epoch 112/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0058 - acc: 0.9980\n",
      "Epoch 113/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 114/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0055 - acc: 0.9979\n",
      "Epoch 115/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0054 - acc: 0.9982\n",
      "Epoch 116/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0062 - acc: 0.9977\n",
      "Epoch 117/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0056 - acc: 0.9979\n",
      "Epoch 118/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 119/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 120/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0051 - acc: 0.9982\n",
      "Epoch 121/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0053 - acc: 0.9981\n",
      "Epoch 122/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 123/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0051 - acc: 0.9984\n",
      "Epoch 124/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0055 - acc: 0.9982\n",
      "Epoch 125/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0047 - acc: 0.9988\n",
      "Epoch 126/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0047 - acc: 0.9982\n",
      "Epoch 127/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0045 - acc: 0.9985\n",
      "Epoch 128/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0048 - acc: 0.9984\n",
      "Epoch 129/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0046 - acc: 0.9984\n",
      "Epoch 130/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0045 - acc: 0.9985\n",
      "Epoch 131/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 132/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0048 - acc: 0.9982\n",
      "Epoch 133/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 134/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0045 - acc: 0.9984\n",
      "Epoch 135/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0048 - acc: 0.9983\n",
      "Epoch 136/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0053 - acc: 0.9982\n",
      "Epoch 137/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 138/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0045 - acc: 0.9984\n",
      "Epoch 139/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0045 - acc: 0.9982\n",
      "Epoch 140/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 141/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 142/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0042 - acc: 0.9984\n",
      "Epoch 143/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 144/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0043 - acc: 0.9984\n",
      "Epoch 145/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0046 - acc: 0.9984\n",
      "Epoch 146/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0046 - acc: 0.9983\n",
      "Epoch 147/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 148/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 149/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0042 - acc: 0.9985\n",
      "Epoch 150/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0042 - acc: 0.9985\n",
      "Epoch 151/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0040 - acc: 0.9985\n",
      "Epoch 152/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0044 - acc: 0.9982\n",
      "Epoch 153/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0038 - acc: 0.9987\n",
      "Epoch 154/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 155/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0040 - acc: 0.9985\n",
      "Epoch 156/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0037 - acc: 0.9985\n",
      "Epoch 157/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0038 - acc: 0.9987\n",
      "Epoch 158/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0050 - acc: 0.9981\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0038 - acc: 0.9985\n",
      "Epoch 160/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0035 - acc: 0.9988\n",
      "Epoch 161/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 162/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 163/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0040 - acc: 0.9981\n",
      "Epoch 164/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0035 - acc: 0.9989\n",
      "Epoch 165/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 166/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 167/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0035 - acc: 0.9989\n",
      "Epoch 168/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 169/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0031 - acc: 0.9989\n",
      "Epoch 170/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0035 - acc: 0.9989\n",
      "Epoch 171/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0031 - acc: 0.9989\n",
      "Epoch 172/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0031 - acc: 0.9989\n",
      "Epoch 173/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0032 - acc: 0.9989\n",
      "Epoch 174/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0038 - acc: 0.9986\n",
      "Epoch 175/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0033 - acc: 0.9989\n",
      "Epoch 176/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0036 - acc: 0.9986\n",
      "Epoch 177/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 178/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0035 - acc: 0.9987\n",
      "Epoch 179/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0033 - acc: 0.9988\n",
      "Epoch 180/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0032 - acc: 0.9989\n",
      "Epoch 181/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0033 - acc: 0.9987\n",
      "Epoch 182/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0032 - acc: 0.9986\n",
      "Epoch 183/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0033 - acc: 0.9987\n",
      "Epoch 184/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 185/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0029 - acc: 0.9990\n",
      "Epoch 186/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 187/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0033 - acc: 0.9989\n",
      "Epoch 188/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 189/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 190/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0031 - acc: 0.9989\n",
      "Epoch 191/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 192/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0033 - acc: 0.9987\n",
      "Epoch 193/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 194/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0028 - acc: 0.9990\n",
      "Epoch 195/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0030 - acc: 0.9989\n",
      "Epoch 196/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 197/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0030 - acc: 0.9989\n",
      "Epoch 198/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 199/200\n",
      "17044/17044 [==============================] - 0s 21us/step - loss: 0.0032 - acc: 0.9987\n",
      "Epoch 200/200\n",
      "17044/17044 [==============================] - 0s 22us/step - loss: 0.0028 - acc: 0.9991\n",
      "17044/17044 [==============================] - 1s 67us/step\n",
      "Layers:2, Recall:0.8333333333333334\n",
      "Current Time:  2019-01-15 17:30:55\n",
      "Finished at 2019-01-15 17:32:12\n",
      "[(2, 0.8333333333333334)]\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "\n",
    "print(\"...And Here we go....\")\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Started at\",st)\n",
    "max_layers = 2\n",
    "for i in range(2, max_layers+1):\n",
    "    layers = create_layers(i)\n",
    "    model = create_model(44, 7, input_shape, NUM_CLASSES, 0.0001, layers=layers)\n",
    "    model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=200,verbose=1)\n",
    "    # What is our score?\n",
    "    score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "    predictions = model.predict(x_test)\n",
    "    predict = create_class_predictions(predictions)\n",
    "    recall = recall_score(y_test.reshape(-1,), predict)\n",
    "    value = (i, recall)\n",
    "    values.append(value)\n",
    "    print(\"Layers:{}, Recall:{}\".format(i, recall))\n",
    "    print(\"Current Time: \", st)\n",
    "\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Finished at\",st)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...And Here we go....\n",
      "Started at 2019-01-12 13:23:40\n",
      "Epoch 1/200\n",
      "17044/17044 [==============================] - 2s 89us/step - loss: 0.5404 - acc: 0.9951\n",
      "Epoch 2/200\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.4416 - acc: 0.9960\n",
      "Epoch 3/200\n",
      "17044/17044 [==============================] - 1s 54us/step - loss: 0.3485 - acc: 0.9960\n",
      "Epoch 4/200\n",
      "17044/17044 [==============================] - 1s 55us/step - loss: 0.2658 - acc: 0.9960\n",
      "Epoch 5/200\n",
      "17044/17044 [==============================] - 1s 55us/step - loss: 0.1954 - acc: 0.9960\n",
      "Epoch 6/200\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.1422 - acc: 0.9960\n",
      "Epoch 7/200\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.1046 - acc: 0.9960\n",
      "Epoch 8/200\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0776 - acc: 0.9960\n",
      "Epoch 9/200\n",
      "17044/17044 [==============================] - 1s 52us/step - loss: 0.0603 - acc: 0.9960\n",
      "Epoch 10/200\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0496 - acc: 0.9960\n",
      "Epoch 11/200\n",
      "17044/17044 [==============================] - 1s 55us/step - loss: 0.0427 - acc: 0.9960\n",
      "Epoch 12/200\n",
      "16000/17044 [===========================>..] - ETA: 0s - loss: 0.0366 - acc: 0.9963"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-63f47743867c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Started at\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# What is our score?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Checking for minimum values that give the best recall.\n",
    "values = []\n",
    "neurons = 20\n",
    "print(\"...And Here we go....\")\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Started at\",st)\n",
    "model = create_model(neurons, 7, input_shape, NUM_CLASSES, 0.00001)\n",
    "history = model.fit(x=x_train, y=y_train_mod, batch_size=100, epochs=200, verbose=1)\n",
    "# What is our score?\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "recall = recall_score(y_test.reshape(-1,), predict)\n",
    "value = (neurons, recall)\n",
    "values.append(value)\n",
    "print(\"Layers:{}, Recall:{}\".format(neurons, recall))\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Finished at\",st)\n",
    "print(history.history.keys())\n",
    "sns.lineplot(data=pd.DataFrame({'loss': history.history['loss']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...And Here we go....\n",
      "Started at 2019-01-15 17:50:12\n",
      "17044/17044 [==============================] - 1s 68us/step\n",
      "Layer <keras.layers.pooling.MaxPooling2D object at 0x0000026C242AA438> done and produced a recall score of 0.16666666666666666\n",
      "17044/17044 [==============================] - 1s 77us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA4E0> done and produced a recall score of 0.6666666666666666\n",
      "17044/17044 [==============================] - 1s 81us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA668> done and produced a recall score of 0.16666666666666666\n",
      "17044/17044 [==============================] - 1s 84us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA7F0> done and produced a recall score of 0.6666666666666666\n",
      "17044/17044 [==============================] - 2s 91us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA978> done and produced a recall score of 0.6666666666666666\n",
      "Iteration 0 done!\n",
      "17044/17044 [==============================] - 1s 84us/step\n",
      "Layer <keras.layers.pooling.MaxPooling2D object at 0x0000026C242AA438> done and produced a recall score of 0.3333333333333333\n",
      "17044/17044 [==============================] - 2s 89us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA4E0> done and produced a recall score of 0.8333333333333334\n",
      "17044/17044 [==============================] - 2s 93us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA668> done and produced a recall score of 0.3333333333333333\n",
      "17044/17044 [==============================] - 2s 97us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA7F0> done and produced a recall score of 0.5\n",
      "17044/17044 [==============================] - 2s 96us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA978> done and produced a recall score of 0.5\n",
      "Iteration 1 done!\n",
      "17044/17044 [==============================] - 2s 98us/step\n",
      "Layer <keras.layers.pooling.MaxPooling2D object at 0x0000026C242AA438> done and produced a recall score of 0.5\n",
      "17044/17044 [==============================] - 2s 106us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA4E0> done and produced a recall score of 0.5\n",
      "17044/17044 [==============================] - 2s 110us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA668> done and produced a recall score of 0.16666666666666666\n",
      "17044/17044 [==============================] - 2s 112us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA7F0> done and produced a recall score of 1.0\n",
      "17044/17044 [==============================] - 2s 111us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA978> done and produced a recall score of 0.16666666666666666\n",
      "Iteration 2 done!\n",
      "17044/17044 [==============================] - 2s 116us/step\n",
      "Layer <keras.layers.pooling.MaxPooling2D object at 0x0000026C242AA438> done and produced a recall score of 0.8333333333333334\n",
      "17044/17044 [==============================] - 2s 125us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA4E0> done and produced a recall score of 0.3333333333333333\n",
      "17044/17044 [==============================] - 2s 128us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA668> done and produced a recall score of 1.0\n",
      "17044/17044 [==============================] - 2s 131us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA7F0> done and produced a recall score of 1.0\n",
      "17044/17044 [==============================] - 2s 131us/step\n",
      "Layer <keras.layers.convolutional.Conv2D object at 0x0000026C242AA978> done and produced a recall score of 1.0\n",
      "Iteration 3 done!\n",
      "17044/17044 [==============================] - 2s 135us/step\n",
      "Layer <keras.layers.pooling.MaxPooling2D object at 0x0000026C242AA438> done and produced a recall score of 0.8333333333333334\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_14: expected axis -1 of input shape to have value 44 but got shape (None, 9, 7, 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-62628c5b5566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model_with_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchoices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;31m# with the input_spec set at build time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;31m# Handle mask propagation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    350\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' of input shape to have '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                                 \u001b[1;34m'value '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                                 ' but got shape ' + str(x_shape))\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;31m# Check shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_14: expected axis -1 of input shape to have value 44 but got shape (None, 9, 7, 26)"
     ]
    }
   ],
   "source": [
    "# Lets try iterating over multiple layers and types of layers\n",
    "import datetime\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Activation, MaxPooling2D\n",
    "\n",
    "layers = []\n",
    "layer_to_keep = (None,0)\n",
    "choices = [\n",
    "            MaxPooling2D(pool_size=(3,3)), \n",
    "            Conv2D(44, 4, activation='relu', padding='same'),\n",
    "            Conv2D(26, 7, activation='relu', padding='same'),\n",
    "            Conv2D(44, 7, activation='relu', padding='same'),\n",
    "            Conv2D(26, 4, activation='relu', padding='same'),\n",
    "           ]\n",
    "\n",
    "def create_model_with_layer(model, layers=[]):\n",
    "    if layers:\n",
    "        for layer in layers:\n",
    "            model.add(layer)\n",
    "    return model\n",
    "\n",
    "print(\"...And Here we go....\")\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Started at\",st)\n",
    "\n",
    "for i in range(8):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "    model = create_model_with_layer(model, layers)\n",
    "    for layer in choices:\n",
    "        model.add(layer)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.2)) \n",
    "        model.add(Dense(44))\n",
    "        model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "        model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "                optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "                metrics=['accuracy'])\n",
    "        model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=0)\n",
    "        # What is our score?\n",
    "        score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "        predictions = model.predict(x_test)\n",
    "        predict = create_class_predictions(predictions)\n",
    "        recall = recall_score(y_test.reshape(-1,), predict)\n",
    "        if recall > layer_to_keep[1]:\n",
    "            layer_to_keep = (layer, recall)\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "        model = create_model_with_layer(model, layers)\n",
    "        \n",
    "        print(\"Layer {} done and produced a recall score of {}\".format(layer, recall))\n",
    "    layers.append(layer_to_keep[0])\n",
    "    layer_to_keep = (None,0)\n",
    "    if i == 7:\n",
    "        model.summary()\n",
    "    print(\"Iteration {} done!\".format(i))\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"Finished at\",st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17044/17044 [==============================] - 3s 174us/step - loss: 0.2284 - acc: 0.9685\n",
      "Epoch 2/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0299 - acc: 0.9960: 0s - loss: 0.0462 -\n",
      "Epoch 3/100\n",
      "17044/17044 [==============================] - 1s 47us/step - loss: 0.0253 - acc: 0.9960\n",
      "Epoch 4/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0218 - acc: 0.9960\n",
      "Epoch 5/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0179 - acc: 0.9960\n",
      "Epoch 6/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0168 - acc: 0.9960\n",
      "Epoch 7/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0160 - acc: 0.9960\n",
      "Epoch 8/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0154 - acc: 0.9958\n",
      "Epoch 9/100\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.0145 - acc: 0.9959\n",
      "Epoch 10/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0149 - acc: 0.9961\n",
      "Epoch 11/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0135 - acc: 0.9961: 0s - loss: 0.0137 - acc: 0.996\n",
      "Epoch 12/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0130 - acc: 0.9960\n",
      "Epoch 13/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0129 - acc: 0.9961\n",
      "Epoch 14/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0124 - acc: 0.9959\n",
      "Epoch 15/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0121 - acc: 0.9961\n",
      "Epoch 16/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 17/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 18/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 19/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 20/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 21/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 22/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0095 - acc: 0.9968\n",
      "Epoch 23/100\n",
      "17044/17044 [==============================] - 1s 52us/step - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 24/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0089 - acc: 0.9971\n",
      "Epoch 25/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 26/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 27/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0083 - acc: 0.9973\n",
      "Epoch 28/100\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 29/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0089 - acc: 0.9971\n",
      "Epoch 30/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0073 - acc: 0.9975\n",
      "Epoch 31/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0062 - acc: 0.9977\n",
      "Epoch 32/100\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.0060 - acc: 0.9979\n",
      "Epoch 33/100\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.0074 - acc: 0.9973\n",
      "Epoch 34/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0067 - acc: 0.9975\n",
      "Epoch 35/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0056 - acc: 0.9980\n",
      "Epoch 36/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0056 - acc: 0.9981\n",
      "Epoch 37/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0053 - acc: 0.9980\n",
      "Epoch 38/100\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.0055 - acc: 0.9984\n",
      "Epoch 39/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0045 - acc: 0.9988\n",
      "Epoch 40/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0049 - acc: 0.9984\n",
      "Epoch 41/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9984\n",
      "Epoch 42/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0056 - acc: 0.9978\n",
      "Epoch 43/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 44/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0048 - acc: 0.9987: 0s - loss: 0.0059 - ac\n",
      "Epoch 45/100\n",
      "17044/17044 [==============================] - 1s 55us/step - loss: 0.0051 - acc: 0.9978\n",
      "Epoch 46/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0042 - acc: 0.9985\n",
      "Epoch 47/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0049 - acc: 0.9982\n",
      "Epoch 48/100\n",
      "17044/17044 [==============================] - 1s 52us/step - loss: 0.0050 - acc: 0.9981\n",
      "Epoch 49/100\n",
      "17044/17044 [==============================] - 1s 49us/step - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 50/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0051 - acc: 0.9980\n",
      "Epoch 51/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0037 - acc: 0.9987: 0s - loss: 0.0038\n",
      "Epoch 52/100\n",
      "17044/17044 [==============================] - 1s 51us/step - loss: 0.0039 - acc: 0.9986\n",
      "Epoch 53/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0040 - acc: 0.9984\n",
      "Epoch 54/100\n",
      "17044/17044 [==============================] - 1s 50us/step - loss: 0.0063 - acc: 0.9977\n",
      "Epoch 55/100\n",
      "17044/17044 [==============================] - 1s 48us/step - loss: 0.0041 - acc: 0.9983\n",
      "Epoch 56/100\n",
      "17044/17044 [==============================] - 1s 56us/step - loss: 0.0051 - acc: 0.9981: 0s - loss: 0.0054 - acc: 0.\n",
      "Epoch 57/100\n",
      "17044/17044 [==============================] - 1s 60us/step - loss: 0.0035 - acc: 0.9987\n",
      "Epoch 58/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0034 - acc: 0.9988\n",
      "Epoch 59/100\n",
      "17044/17044 [==============================] - 1s 45us/step - loss: 0.0049 - acc: 0.9981\n",
      "Epoch 60/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 61/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0038 - acc: 0.9987\n",
      "Epoch 62/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0030 - acc: 0.9988\n",
      "Epoch 63/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0043 - acc: 0.9983\n",
      "Epoch 64/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0037 - acc: 0.9988\n",
      "Epoch 65/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0033 - acc: 0.9988\n",
      "Epoch 66/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0027 - acc: 0.9988\n",
      "Epoch 67/100\n",
      "17044/17044 [==============================] - 1s 45us/step - loss: 0.0030 - acc: 0.9989\n",
      "Epoch 68/100\n",
      "17044/17044 [==============================] - 1s 45us/step - loss: 0.0031 - acc: 0.9989\n",
      "Epoch 69/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0029 - acc: 0.9987\n",
      "Epoch 70/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0034 - acc: 0.9985\n",
      "Epoch 71/100\n",
      "17044/17044 [==============================] - 1s 46us/step - loss: 0.0038 - acc: 0.9989\n",
      "Epoch 72/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0034 - acc: 0.9988\n",
      "Epoch 73/100\n",
      "17044/17044 [==============================] - 1s 44us/step - loss: 0.0035 - acc: 0.9986\n",
      "Epoch 74/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0026 - acc: 0.9990\n",
      "Epoch 75/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 76/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0025 - acc: 0.9989\n",
      "Epoch 77/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 78/100\n",
      "17044/17044 [==============================] - 1s 43us/step - loss: 0.0026 - acc: 0.9989\n",
      "Epoch 79/100\n",
      "14800/17044 [=========================>....] - ETA: 0s - loss: 0.0038 - acc: 0.9986"
     ]
    }
   ],
   "source": [
    "# From the above cell it was found to be the following layers to be the best\n",
    "# Conv2D 44,4\n",
    "# Conv2D 44, 7\n",
    "# Conv2D 44, 4\n",
    "# Conv2D 44 7\n",
    "# Flatten()\n",
    "# Dropout(0.2)\n",
    "# Dense(44)\n",
    "# Dense(2)\n",
    "\n",
    "# let's train a model to see if we get similar results with that\n",
    "model = Sequential()\n",
    "model.add(Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 7, activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(44))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "        optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "        metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "recall = recall_score(y_test.reshape(-1,), predict)\n",
    "print(\"RECALL:\",recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring dropout for deployment\n",
    "K.set_learning_phase(0)\n",
    " \n",
    "# Set a file path to save the model in.\n",
    "model_name = \"cnn_model\"\n",
    "model_version = \"1\"\n",
    "tf_path = \"./../../saved_models/{}/{}\".format(model_name, model_version)\n",
    " \n",
    "# Get the session from the Keras back-end to save the model in TF format.\n",
    "with K.get_session() as sess:\n",
    "    tf.saved_model.simple_save(sess, tf_path, inputs={'input': model.input}, outputs={t.name: t for t in model.outputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
