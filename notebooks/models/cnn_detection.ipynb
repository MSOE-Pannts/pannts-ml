{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccomackjp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Activation, MaxPooling2D\n",
    "from scripts.model_functions import create_model\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variables to be used in Keras and the CNN\n",
    "\n",
    "# number of items to use for training\n",
    "BATCH_SIZE = 400 \n",
    "\n",
    "# Number of identifying classes \n",
    "#   WE have two, Bloom and no bloom 1/0\n",
    "NUM_CLASSES = 2 \n",
    "\n",
    "# number of times to repeat process\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "df_train = pd.read_csv('../../data/cleaned/site1_vineyard.csv')\n",
    "df_test = pd.read_csv('../../data/cleaned/site2_bird.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.37</td>\n",
       "      <td>2184</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.70</td>\n",
       "      <td>92.2</td>\n",
       "      <td>9.16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.428449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>15.45</td>\n",
       "      <td>2139</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>9.92</td>\n",
       "      <td>93.3</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.428449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>15.49</td>\n",
       "      <td>2057</td>\n",
       "      <td>-102.3</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.90</td>\n",
       "      <td>94.8</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.856898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>15.67</td>\n",
       "      <td>1978</td>\n",
       "      <td>-102.6</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.62</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.856898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>15.34</td>\n",
       "      <td>2136</td>\n",
       "      <td>-100.2</td>\n",
       "      <td>8.41</td>\n",
       "      <td>9.88</td>\n",
       "      <td>92.7</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.428449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.37             2184   -100.0  8.41   \n",
       "1          5/5/2017      0:15   15.45             2139   -101.0  8.43   \n",
       "2          5/5/2017      0:30   15.49             2057   -102.3  8.45   \n",
       "3          5/5/2017      0:45   15.67             1978   -102.6  8.45   \n",
       "4          5/5/2017      1:00   15.34             2136   -100.2  8.41   \n",
       "\n",
       "   Turbidity (NTU)  ODOSat%  ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)  \n",
       "0            10.70     92.2        9.16                  0.1    0.428449  \n",
       "1             9.92     93.3        9.25                  0.1    0.428449  \n",
       "2             8.90     94.8        9.40                  0.2    0.856898  \n",
       "3             8.62     96.0        9.49                  0.2    0.856898  \n",
       "4             9.88     92.7        9.22                  0.1    0.428449  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df_train['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "df_train = df_train.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "df_train['BGA (ug/L)'] = target\n",
    "df_train.head(5)\n",
    "\n",
    "\n",
    "target = df_test['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "df_test = df_test.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "df_test['BGA (ug/L)'] = target\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestamp = df_train['Date (mm.dd.yyyy)'] + ' '+ df_train['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "df_train['Timestamp'] = timestamp\n",
    "\n",
    "timestamp = df_test['Date (mm.dd.yyyy)'] + ' '+ df_test['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "df_test['Timestamp'] = timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont need data and time now that we have Timestamp. Lets remove them\n",
    "\n",
    "df_train = df_train.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n",
    "df_test = df_test.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = df_train['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "df_train['Bloom'] = train_target\n",
    "\n",
    "test_target = df_test['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "df_test['Bloom'] = test_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccomackjp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\mccomackjp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# lets try to normalize this now....\n",
    "dataset_columns = ['Temp C','Sp Cond (uS/cm)', 'pH (mV)','pH', 'Turbidity (NTU)', 'ODOSat%','ODO (mg/L)', 'Bloom']\n",
    "scaler = MinMaxScaler()\n",
    "ds_scaled = scaler.fit_transform(df_train[dataset_columns])\n",
    "df_train = pd.DataFrame(ds_scaled,columns=dataset_columns)\n",
    "\n",
    "ds_scaled = scaler.fit_transform(df_test[dataset_columns])\n",
    "df_test = pd.DataFrame(ds_scaled,columns=dataset_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to take a moving window of the data of 10 time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "determines the window size for the daata set\n",
    "@param dataset - The dataset to get windows for\n",
    "@param window_size - the size of the window  \n",
    "@param shift - the amout to shift the window\n",
    "'''\n",
    "def windows(dataset, window_size, shift):\n",
    "    start = 0\n",
    "    while start+window_size < dataset.shape[0]: \n",
    "        yield (int(start), int(start+window_size))\n",
    "        # shift the window five blocks of time\n",
    "        start += shift\n",
    "        if start % 300 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format(((start+window_size) / dataset.shape[0]) * 100 ))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Segments the dataset based on the parameters that are passed in.\n",
    "@param dataset - the dataset to segment into window\n",
    "@param columns - the array of columns from the dataset to be looked at\n",
    "@param window_size - the size of the window you would like to be looked at. Defualt is 10\n",
    "\n",
    "'''\n",
    "def segment_dataset(dataset, columns, target, window_size=10):    \n",
    "    print('WINDOW SIZE',window_size)\n",
    "    print('NUMBER OF COULUMNS',len(columns))\n",
    "    segments = np.empty((0, window_size, len(columns)))\n",
    "    labels = np.empty((0))\n",
    "    count = 0\n",
    "    for (start, end) in windows(dataset, window_size, 1):\n",
    "        count+=1\n",
    "        values = dataset[columns][start:end]\n",
    "        if(values.shape[0] == window_size):\n",
    "            segments = np.vstack([segments, np.stack([values])])\n",
    "            # Takes the larger of the two variables if there are more than one. \n",
    "            # This makes it more likly to predict a bloom. Can be changed to iloc[0] to\n",
    "            # be less likly to predict a bloom (more 0s in the label array)\n",
    "            \n",
    "            labels = np.append(labels, dataset[target][start:end].mode().iloc[-1])\n",
    "        else:\n",
    "            print(\"No more Windows available... Exiting\")\n",
    "            break\n",
    "    return (segments, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.63% done\n",
      "Window Segmentation 3.21% done\n",
      "Window Segmentation 4.80% done\n",
      "Window Segmentation 6.38% done\n",
      "Window Segmentation 7.96% done\n",
      "Window Segmentation 9.55% done\n",
      "Window Segmentation 11.13% done\n",
      "Window Segmentation 12.71% done\n",
      "Window Segmentation 14.30% done\n",
      "Window Segmentation 15.88% done\n",
      "Window Segmentation 17.46% done\n",
      "Window Segmentation 19.05% done\n",
      "Window Segmentation 20.63% done\n",
      "Window Segmentation 22.21% done\n",
      "Window Segmentation 23.80% done\n",
      "Window Segmentation 25.38% done\n",
      "Window Segmentation 26.96% done\n",
      "Window Segmentation 28.55% done\n",
      "Window Segmentation 30.13% done\n",
      "Window Segmentation 31.71% done\n",
      "Window Segmentation 33.30% done\n",
      "Window Segmentation 34.88% done\n",
      "Window Segmentation 36.46% done\n",
      "Window Segmentation 38.05% done\n",
      "Window Segmentation 39.63% done\n",
      "Window Segmentation 41.21% done\n",
      "Window Segmentation 42.80% done\n",
      "Window Segmentation 44.38% done\n",
      "Window Segmentation 45.97% done\n",
      "Window Segmentation 47.55% done\n",
      "Window Segmentation 49.13% done\n",
      "Window Segmentation 50.72% done\n",
      "Window Segmentation 52.30% done\n",
      "Window Segmentation 53.88% done\n",
      "Window Segmentation 55.47% done\n",
      "Window Segmentation 57.05% done\n",
      "Window Segmentation 58.63% done\n",
      "Window Segmentation 60.22% done\n",
      "Window Segmentation 61.80% done\n",
      "Window Segmentation 63.38% done\n",
      "Window Segmentation 64.97% done\n",
      "Window Segmentation 66.55% done\n",
      "Window Segmentation 68.13% done\n",
      "Window Segmentation 69.72% done\n",
      "Window Segmentation 71.30% done\n",
      "Window Segmentation 72.88% done\n",
      "Window Segmentation 74.47% done\n",
      "Window Segmentation 76.05% done\n",
      "Window Segmentation 77.63% done\n",
      "Window Segmentation 79.22% done\n",
      "Window Segmentation 80.80% done\n",
      "Window Segmentation 82.38% done\n",
      "Window Segmentation 83.97% done\n",
      "Window Segmentation 85.55% done\n",
      "Window Segmentation 87.13% done\n",
      "Window Segmentation 88.72% done\n",
      "Window Segmentation 90.30% done\n",
      "Window Segmentation 91.88% done\n",
      "Window Segmentation 93.47% done\n",
      "Window Segmentation 95.05% done\n",
      "Window Segmentation 96.63% done\n",
      "Window Segmentation 98.22% done\n",
      "Window Segmentation 99.80% done\n",
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.81% done\n",
      "Window Segmentation 3.56% done\n",
      "Window Segmentation 5.32% done\n",
      "Window Segmentation 7.07% done\n",
      "Window Segmentation 8.83% done\n",
      "Window Segmentation 10.58% done\n",
      "Window Segmentation 12.34% done\n",
      "Window Segmentation 14.09% done\n",
      "Window Segmentation 15.85% done\n",
      "Window Segmentation 17.60% done\n",
      "Window Segmentation 19.36% done\n",
      "Window Segmentation 21.11% done\n",
      "Window Segmentation 22.87% done\n",
      "Window Segmentation 24.62% done\n",
      "Window Segmentation 26.38% done\n",
      "Window Segmentation 28.13% done\n",
      "Window Segmentation 29.89% done\n",
      "Window Segmentation 31.64% done\n",
      "Window Segmentation 33.40% done\n",
      "Window Segmentation 35.15% done\n",
      "Window Segmentation 36.91% done\n",
      "Window Segmentation 38.66% done\n",
      "Window Segmentation 40.42% done\n",
      "Window Segmentation 42.17% done\n",
      "Window Segmentation 43.93% done\n",
      "Window Segmentation 45.68% done\n",
      "Window Segmentation 47.43% done\n",
      "Window Segmentation 49.19% done\n",
      "Window Segmentation 50.94% done\n",
      "Window Segmentation 52.70% done\n",
      "Window Segmentation 54.45% done\n",
      "Window Segmentation 56.21% done\n",
      "Window Segmentation 57.96% done\n",
      "Window Segmentation 59.72% done\n",
      "Window Segmentation 61.47% done\n",
      "Window Segmentation 63.23% done\n",
      "Window Segmentation 64.98% done\n",
      "Window Segmentation 66.74% done\n",
      "Window Segmentation 68.49% done\n",
      "Window Segmentation 70.25% done\n",
      "Window Segmentation 72.00% done\n",
      "Window Segmentation 73.76% done\n",
      "Window Segmentation 75.51% done\n",
      "Window Segmentation 77.27% done\n",
      "Window Segmentation 79.02% done\n",
      "Window Segmentation 80.78% done\n",
      "Window Segmentation 82.53% done\n",
      "Window Segmentation 84.29% done\n",
      "Window Segmentation 86.04% done\n",
      "Window Segmentation 87.80% done\n",
      "Window Segmentation 89.55% done\n",
      "Window Segmentation 91.31% done\n",
      "Window Segmentation 93.06% done\n",
      "Window Segmentation 94.82% done\n",
      "Window Segmentation 96.57% done\n",
      "Window Segmentation 98.33% done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "feature_columns = dataset_columns[:-1]\n",
    "(x_train, y_train) = segment_dataset(df_train, feature_columns, 'Bloom', 9)\n",
    "(x_test, y_test) = segment_dataset(df_test, feature_columns, 'Bloom', 9)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18938, 9, 7)\n",
      "(17086, 9, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18938,)\n",
      "(17086,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaping the data to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),9,7,1)\n",
    "x_test = x_test.reshape(len(x_test),9,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking apart training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (18938, 9, 7, 1)\n",
      "x_test shape: (17086, 9, 7, 1)\n",
      "y_train shape: (18938, 1)\n",
      "y_test shape: (17086, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"x_test shape:\",x_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mod = ks.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_mod = ks.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "input_shape = (9,7,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gets the precision of the different metrics\n",
    "def create_class_predictions(pred):\n",
    "    retval = np.array([])\n",
    "    for row in pred:\n",
    "        max_value = (-1,-1)\n",
    "        for index, value in enumerate(row):\n",
    "            if value > max_value[1]:\n",
    "                max_value = (index, value)\n",
    "        retval = np.append(retval, max_value[0])\n",
    "    return retval\n",
    "\n",
    "\n",
    "def create_layers(num_layers):\n",
    "    layers = [Flatten(), Dropout(0.2), Dense(NUM_CLASSES, activation='softmax', input_dim=2)]\n",
    "    for i in range(0, num_layers):\n",
    "        layers.insert(0, Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Come on, let's create the model already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18938/18938 [==============================] - 57s 3ms/step - loss: 0.1484 - acc: 0.9867\n",
      "Epoch 2/100\n",
      "18938/18938 [==============================] - 56s 3ms/step - loss: 0.0283 - acc: 0.9961\n",
      "Epoch 3/100\n",
      "18938/18938 [==============================] - 59s 3ms/step - loss: 0.0259 - acc: 0.9961\n",
      "Epoch 4/100\n",
      "18938/18938 [==============================] - 55s 3ms/step - loss: 0.0213 - acc: 0.9961\n",
      "Epoch 5/100\n",
      "18938/18938 [==============================] - 55s 3ms/step - loss: 0.0168 - acc: 0.9961\n",
      "Epoch 6/100\n",
      "18938/18938 [==============================] - 58s 3ms/step - loss: 0.0159 - acc: 0.9961\n",
      "Epoch 7/100\n",
      "18938/18938 [==============================] - 60s 3ms/step - loss: 0.0150 - acc: 0.9959\n",
      "Epoch 8/100\n",
      "18938/18938 [==============================] - 63s 3ms/step - loss: 0.0145 - acc: 0.9961\n",
      "Epoch 9/100\n",
      "18938/18938 [==============================] - 58s 3ms/step - loss: 0.0139 - acc: 0.9959\n",
      "Epoch 10/100\n",
      "18938/18938 [==============================] - 58s 3ms/step - loss: 0.0136 - acc: 0.9960\n",
      "Epoch 11/100\n",
      "18938/18938 [==============================] - 56s 3ms/step - loss: 0.0138 - acc: 0.9962\n",
      "Epoch 12/100\n",
      "18938/18938 [==============================] - 57s 3ms/step - loss: 0.0143 - acc: 0.9962\n",
      "Epoch 13/100\n",
      "18938/18938 [==============================] - 55s 3ms/step - loss: 0.0128 - acc: 0.9965\n",
      "Epoch 14/100\n",
      "18938/18938 [==============================] - 55s 3ms/step - loss: 0.0121 - acc: 0.9962\n",
      "Epoch 15/100\n",
      "18938/18938 [==============================] - 57s 3ms/step - loss: 0.0117 - acc: 0.9964\n",
      "Epoch 16/100\n",
      "18938/18938 [==============================] - 57s 3ms/step - loss: 0.0113 - acc: 0.9962\n",
      "Epoch 17/100\n",
      "18938/18938 [==============================] - 59s 3ms/step - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 18/100\n",
      "18938/18938 [==============================] - 56s 3ms/step - loss: 0.0117 - acc: 0.9965\n",
      "Epoch 19/100\n",
      "18938/18938 [==============================] - 59s 3ms/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 20/100\n",
      "18938/18938 [==============================] - 61s 3ms/step - loss: 0.0101 - acc: 0.9966\n",
      "Epoch 21/100\n",
      "18938/18938 [==============================] - 58s 3ms/step - loss: 0.0100 - acc: 0.9966\n",
      "Epoch 22/100\n",
      "18938/18938 [==============================] - 57s 3ms/step - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 23/100\n",
      "18938/18938 [==============================] - 54s 3ms/step - loss: 0.0096 - acc: 0.9970\n",
      "Epoch 24/100\n",
      "18938/18938 [==============================] - 57s 3ms/step - loss: 0.0088 - acc: 0.9970\n",
      "Epoch 25/100\n",
      "18938/18938 [==============================] - 55s 3ms/step - loss: 0.0092 - acc: 0.9971\n",
      "Epoch 26/100\n",
      "18938/18938 [==============================] - 61s 3ms/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 27/100\n",
      "18938/18938 [==============================] - 63s 3ms/step - loss: 0.0088 - acc: 0.9969\n",
      "Epoch 28/100\n",
      "18938/18938 [==============================] - 57s 3ms/step - loss: 0.0078 - acc: 0.9975\n",
      "Epoch 29/100\n",
      "18938/18938 [==============================] - 61s 3ms/step - loss: 0.0088 - acc: 0.9973\n",
      "Epoch 30/100\n",
      "18938/18938 [==============================] - 60s 3ms/step - loss: 0.0070 - acc: 0.9978\n",
      "Epoch 31/100\n",
      "18938/18938 [==============================] - 62819s 3s/step - loss: 0.0070 - acc: 0.9975\n",
      "Epoch 32/100\n",
      " 3200/18938 [====>.........................] - ETA: 1:03 - loss: 0.0065 - acc: 0.9975"
     ]
    }
   ],
   "source": [
    "# From the layer/node investigation\n",
    "# it was found to be the following layers to be the best\n",
    "# Conv2D 44,4\n",
    "# Conv2D 44, 7\n",
    "# Conv2D 44, 4\n",
    "# Conv2D 44 7\n",
    "# Flatten()\n",
    "# Dropout(0.2)\n",
    "# Dense(44)\n",
    "# Dense(2)\n",
    "\n",
    "# let's train a model to see if we get similar results with that\n",
    "model = Sequential()\n",
    "model.add(Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Conv2D(44, 7, activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(44))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "        optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "        metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "y = y_test.reshape(-1,)\n",
    "recall = recall_score(y, predict)\n",
    "precision = precision_score(y, predict)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(confusion_matrix(y, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring dropout for deployment\n",
    "K.set_learning_phase(0)\n",
    " \n",
    "# Set a file path to save the model in.\n",
    "model_name = \"cnn_model\"\n",
    "model_version = \"1\"\n",
    "tf_path = \"./../../saved_models/{}/{}\".format(model_name, model_version)\n",
    " \n",
    "# Get the session from the Keras back-end to save the model in TF format.\n",
    "with K.get_session() as sess:\n",
    "    tf.saved_model.simple_save(sess, tf_path, inputs={'input': model.input}, outputs={t.name: t for t in model.outputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
