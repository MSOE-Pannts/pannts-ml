{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccomackjp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input, Flatten, ConvLSTM2D, Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variables to be used in Keras and the CNN\n",
    "\n",
    "# number of items to use for training\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# Number of identifying classes \n",
    "#   WE have two, Bloom and no bloom 1/0\n",
    "NUM_CLASSES = 2 \n",
    "\n",
    "# number of times to repeat process\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>Chlorophyll (ug/L)</th>\n",
       "      <th>Chlorophyll RFU</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.02             1848   -100.1  8.36   \n",
       "1          5/5/2017      0:15   14.99             1847   -100.1  8.36   \n",
       "2          5/5/2017      0:30   14.96             1847   -100.1  8.36   \n",
       "3          5/5/2017      0:45   14.95             1848   -100.1  8.36   \n",
       "4          5/5/2017      1:00   14.92             1848   -100.0  8.36   \n",
       "\n",
       "   Turbidity (NTU)  Chlorophyll (ug/L)  Chlorophyll RFU  ODOSat%  ODO (mg/L)  \\\n",
       "0            16.84                 4.4              1.3     90.2        9.04   \n",
       "1            16.76                 4.2              1.2     90.2        9.04   \n",
       "2            16.82                 4.3              1.3     90.1        9.04   \n",
       "3            17.19                 4.5              1.3     90.0        9.03   \n",
       "4            16.85                 4.5              1.3     89.8        9.02   \n",
       "\n",
       "   BGA-Phycocyanin RFU  \n",
       "0                  0.4  \n",
       "1                  0.4  \n",
       "2                  0.4  \n",
       "3                  0.4  \n",
       "4                  0.4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../../data/cleaned/site1_vineyard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.02             1848   -100.1  8.36   \n",
       "1          5/5/2017      0:15   14.99             1847   -100.1  8.36   \n",
       "2          5/5/2017      0:30   14.96             1847   -100.1  8.36   \n",
       "3          5/5/2017      0:45   14.95             1848   -100.1  8.36   \n",
       "4          5/5/2017      1:00   14.92             1848   -100.0  8.36   \n",
       "\n",
       "   Turbidity (NTU)  ODOSat%  ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)  \n",
       "0            16.84     90.2        9.04                  0.4    1.713796  \n",
       "1            16.76     90.2        9.04                  0.4    1.713796  \n",
       "2            16.82     90.1        9.04                  0.4    1.713796  \n",
       "3            17.19     90.0        9.03                  0.4    1.713796  \n",
       "4            16.85     89.8        9.02                  0.4    1.713796  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['BGA-Phycocyanin RFU'].apply(lambda x : x/0.2334)\n",
    "target\n",
    "dataset = df.drop(columns=['Chlorophyll (ug/L)', 'Chlorophyll RFU'])\n",
    "dataset['BGA (ug/L)'] = target\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (mm.dd.yyyy)</th>\n",
       "      <th>Time 24hr</th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:15</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:30</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>0:45</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/5/2017</td>\n",
       "      <td>1:00</td>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (mm.dd.yyyy) Time 24hr  Temp C  Sp Cond (uS/cm)  pH (mV)    pH  \\\n",
       "0          5/5/2017      0:00   15.02             1848   -100.1  8.36   \n",
       "1          5/5/2017      0:15   14.99             1847   -100.1  8.36   \n",
       "2          5/5/2017      0:30   14.96             1847   -100.1  8.36   \n",
       "3          5/5/2017      0:45   14.95             1848   -100.1  8.36   \n",
       "4          5/5/2017      1:00   14.92             1848   -100.0  8.36   \n",
       "\n",
       "   Turbidity (NTU)  ODOSat%  ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)  \\\n",
       "0            16.84     90.2        9.04                  0.4    1.713796   \n",
       "1            16.76     90.2        9.04                  0.4    1.713796   \n",
       "2            16.82     90.1        9.04                  0.4    1.713796   \n",
       "3            17.19     90.0        9.03                  0.4    1.713796   \n",
       "4            16.85     89.8        9.02                  0.4    1.713796   \n",
       "\n",
       "            Timestamp  \n",
       "0 2017-05-05 00:00:00  \n",
       "1 2017-05-05 00:15:00  \n",
       "2 2017-05-05 00:30:00  \n",
       "3 2017-05-05 00:45:00  \n",
       "4 2017-05-05 01:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = dataset['Date (mm.dd.yyyy)'] + ' '+ dataset['Time 24hr']\n",
    "timestamp = pd.to_datetime(timestamp)\n",
    "dataset['Timestamp'] = timestamp\n",
    "dataset.head()\n",
    "#converts the date object to a numerical representation of that object\n",
    "#dataset['date (mm.dd.yyyy)'] = (dataset['date (mm.dd.yyyy)'] - dataset['date (mm.dd.yyyy)'].min()) / np.timedelta64(1,'D')\n",
    "#dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>BGA-Phycocyanin RFU</th>\n",
       "      <th>BGA (ug/L)</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.02</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.84</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.99</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.76</td>\n",
       "      <td>90.2</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.96</td>\n",
       "      <td>1847</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.1</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.95</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>17.19</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.92</td>\n",
       "      <td>1848</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.85</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.92</td>\n",
       "      <td>1850</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.43</td>\n",
       "      <td>89.8</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.90</td>\n",
       "      <td>1851</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.35</td>\n",
       "      <td>89.7</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.88</td>\n",
       "      <td>1852</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.40</td>\n",
       "      <td>89.6</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 01:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.84</td>\n",
       "      <td>1850</td>\n",
       "      <td>-99.9</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.82</td>\n",
       "      <td>89.4</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1851</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>8.36</td>\n",
       "      <td>16.50</td>\n",
       "      <td>89.4</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.713796</td>\n",
       "      <td>2017-05-05 02:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temp C  Sp Cond (uS/cm)  pH (mV)    pH  Turbidity (NTU)  ODOSat%  \\\n",
       "0   15.02             1848   -100.1  8.36            16.84     90.2   \n",
       "1   14.99             1847   -100.1  8.36            16.76     90.2   \n",
       "2   14.96             1847   -100.1  8.36            16.82     90.1   \n",
       "3   14.95             1848   -100.1  8.36            17.19     90.0   \n",
       "4   14.92             1848   -100.0  8.36            16.85     89.8   \n",
       "5   14.92             1850   -100.1  8.36            16.43     89.8   \n",
       "6   14.90             1851   -100.1  8.36            16.35     89.7   \n",
       "7   14.88             1852   -100.0  8.36            16.40     89.6   \n",
       "8   14.84             1850    -99.9  8.36            16.82     89.4   \n",
       "9   14.83             1851   -100.0  8.36            16.50     89.4   \n",
       "\n",
       "   ODO (mg/L)  BGA-Phycocyanin RFU  BGA (ug/L)           Timestamp  \n",
       "0        9.04                  0.4    1.713796 2017-05-05 00:00:00  \n",
       "1        9.04                  0.4    1.713796 2017-05-05 00:15:00  \n",
       "2        9.04                  0.4    1.713796 2017-05-05 00:30:00  \n",
       "3        9.03                  0.4    1.713796 2017-05-05 00:45:00  \n",
       "4        9.02                  0.4    1.713796 2017-05-05 01:00:00  \n",
       "5        9.02                  0.4    1.713796 2017-05-05 01:15:00  \n",
       "6        9.01                  0.4    1.713796 2017-05-05 01:30:00  \n",
       "7        9.00                  0.4    1.713796 2017-05-05 01:45:00  \n",
       "8        8.99                  0.4    1.713796 2017-05-05 02:00:00  \n",
       "9        8.99                  0.4    1.713796 2017-05-05 02:15:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dont need data and time now that we have Timestamp. Lets remove them\n",
    "\n",
    "dataset = dataset.drop(columns=['Date (mm.dd.yyyy)', 'Time 24hr'])\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temp C                        float64\n",
       "Sp Cond (uS/cm)                 int64\n",
       "pH (mV)                       float64\n",
       "pH                            float64\n",
       "Turbidity (NTU)               float64\n",
       "ODOSat%                       float64\n",
       "ODO (mg/L)                    float64\n",
       "BGA-Phycocyanin RFU           float64\n",
       "BGA (ug/L)                    float64\n",
       "Timestamp              datetime64[ns]\n",
       "Bloom                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = dataset['BGA (ug/L)'].apply(lambda x: 1 if x > 20 else 0)\n",
    "dataset['Bloom'] = target\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccomackjp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp C</th>\n",
       "      <th>Sp Cond (uS/cm)</th>\n",
       "      <th>pH (mV)</th>\n",
       "      <th>pH</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>ODOSat%</th>\n",
       "      <th>ODO (mg/L)</th>\n",
       "      <th>Bloom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "      <td>18947.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.560516</td>\n",
       "      <td>0.893366</td>\n",
       "      <td>0.477889</td>\n",
       "      <td>0.541089</td>\n",
       "      <td>0.090355</td>\n",
       "      <td>0.165126</td>\n",
       "      <td>0.273546</td>\n",
       "      <td>0.005120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.267413</td>\n",
       "      <td>0.070246</td>\n",
       "      <td>0.116241</td>\n",
       "      <td>0.113254</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>0.093899</td>\n",
       "      <td>0.116220</td>\n",
       "      <td>0.071369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.308195</td>\n",
       "      <td>0.853771</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.117086</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.640366</td>\n",
       "      <td>0.895882</td>\n",
       "      <td>0.492228</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.065216</td>\n",
       "      <td>0.138870</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.784656</td>\n",
       "      <td>0.956502</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.102407</td>\n",
       "      <td>0.177672</td>\n",
       "      <td>0.370909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Temp C  Sp Cond (uS/cm)       pH (mV)            pH  \\\n",
       "count  18947.000000     18947.000000  18947.000000  18947.000000   \n",
       "mean       0.560516         0.893366      0.477889      0.541089   \n",
       "std        0.267413         0.070246      0.116241      0.113254   \n",
       "min        0.000000         0.000000      0.000000      0.000000   \n",
       "25%        0.308195         0.853771      0.426166      0.461538   \n",
       "50%        0.640366         0.895882      0.492228      0.553846   \n",
       "75%        0.784656         0.956502      0.538860      0.592308   \n",
       "max        1.000000         1.000000      1.000000      1.000000   \n",
       "\n",
       "       Turbidity (NTU)       ODOSat%    ODO (mg/L)         Bloom  \n",
       "count     18947.000000  18947.000000  18947.000000  18947.000000  \n",
       "mean          0.090355      0.165126      0.273546      0.005120  \n",
       "std           0.085879      0.093899      0.116220      0.071369  \n",
       "min           0.000000      0.000000      0.000000      0.000000  \n",
       "25%           0.045893      0.117086      0.190000      0.000000  \n",
       "50%           0.065216      0.138870      0.264545      0.000000  \n",
       "75%           0.102407      0.177672      0.370909      0.000000  \n",
       "max           1.000000      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try to normalize this now....\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "dataset_columns = ['Temp C','Sp Cond (uS/cm)', 'pH (mV)','pH', 'Turbidity (NTU)', 'ODOSat%','ODO (mg/L)', 'Bloom']\n",
    "scaler = MinMaxScaler()\n",
    "ds_scaled = scaler.fit_transform(dataset[dataset_columns])\n",
    "dataset = pd.DataFrame(ds_scaled,columns=dataset_columns)\n",
    "dataset.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to take a moving window of the data of 10 time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "determines the window size for the daata set\n",
    "@param dataset - The dataset to get windows for\n",
    "@param window_size - the size of the window  \n",
    "@param shift - the amout to shift the window\n",
    "'''\n",
    "def windows(dataset, window_size, shift):\n",
    "    start = 0\n",
    "    while start+window_size < dataset.shape[0]: \n",
    "        yield (int(start), int(start+window_size))\n",
    "        # shift the window five blocks of time\n",
    "        start += shift\n",
    "        if start % 300 == 0:\n",
    "            print('Window Segmentation {0:.2f}% done'.format(((start+window_size) / dataset.shape[0]) * 100 ))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Segments the dataset based on the parameters that are passed in.\n",
    "@param dataset - the dataset to segment into window\n",
    "@param columns - the array of columns from the dataset to be looked at\n",
    "@param window_size - the size of the window you would like to be looked at. Defualt is 10\n",
    "\n",
    "'''\n",
    "def segment_dataset(dataset, columns, target, window_size=10):    \n",
    "    print('WINDOW SIZE',window_size)\n",
    "    print('NUMBER OF COULUMNS',len(columns))\n",
    "    segments = np.empty((0, window_size, len(columns)))\n",
    "    labels = np.empty((0))\n",
    "    count = 0\n",
    "    for (start, end) in windows(dataset, window_size, 1):\n",
    "        count+=1\n",
    "        values = dataset[columns][start:end]\n",
    "        if(values.shape[0] == window_size):\n",
    "            segments = np.vstack([segments, np.stack([values])])\n",
    "            # Takes the larger of the two variables if there are more than one. \n",
    "            # This makes it more likly to predict a bloom. Can be changed to iloc[0] to\n",
    "            # be less likly to predict a bloom (more 0s in the label array)\n",
    "            \n",
    "            labels = np.append(labels, dataset[target][start:end].mode().iloc[-1])\n",
    "        else:\n",
    "            print(\"No more Windows available... Exiting\")\n",
    "            break\n",
    "    return (segments, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW SIZE 9\n",
      "NUMBER OF COULUMNS 7\n",
      "Window Segmentation 1.63% done\n",
      "Window Segmentation 3.21% done\n",
      "Window Segmentation 4.80% done\n",
      "Window Segmentation 6.38% done\n",
      "Window Segmentation 7.96% done\n",
      "Window Segmentation 9.55% done\n",
      "Window Segmentation 11.13% done\n",
      "Window Segmentation 12.71% done\n",
      "Window Segmentation 14.30% done\n",
      "Window Segmentation 15.88% done\n",
      "Window Segmentation 17.46% done\n",
      "Window Segmentation 19.05% done\n",
      "Window Segmentation 20.63% done\n",
      "Window Segmentation 22.21% done\n",
      "Window Segmentation 23.80% done\n",
      "Window Segmentation 25.38% done\n",
      "Window Segmentation 26.96% done\n",
      "Window Segmentation 28.55% done\n",
      "Window Segmentation 30.13% done\n",
      "Window Segmentation 31.71% done\n",
      "Window Segmentation 33.30% done\n",
      "Window Segmentation 34.88% done\n",
      "Window Segmentation 36.46% done\n",
      "Window Segmentation 38.05% done\n",
      "Window Segmentation 39.63% done\n",
      "Window Segmentation 41.21% done\n",
      "Window Segmentation 42.80% done\n",
      "Window Segmentation 44.38% done\n",
      "Window Segmentation 45.97% done\n",
      "Window Segmentation 47.55% done\n",
      "Window Segmentation 49.13% done\n",
      "Window Segmentation 50.72% done\n",
      "Window Segmentation 52.30% done\n",
      "Window Segmentation 53.88% done\n",
      "Window Segmentation 55.47% done\n",
      "Window Segmentation 57.05% done\n",
      "Window Segmentation 58.63% done\n",
      "Window Segmentation 60.22% done\n",
      "Window Segmentation 61.80% done\n",
      "Window Segmentation 63.38% done\n",
      "Window Segmentation 64.97% done\n",
      "Window Segmentation 66.55% done\n",
      "Window Segmentation 68.13% done\n",
      "Window Segmentation 69.72% done\n",
      "Window Segmentation 71.30% done\n",
      "Window Segmentation 72.88% done\n",
      "Window Segmentation 74.47% done\n",
      "Window Segmentation 76.05% done\n",
      "Window Segmentation 77.63% done\n",
      "Window Segmentation 79.22% done\n",
      "Window Segmentation 80.80% done\n",
      "Window Segmentation 82.38% done\n",
      "Window Segmentation 83.97% done\n",
      "Window Segmentation 85.55% done\n",
      "Window Segmentation 87.13% done\n",
      "Window Segmentation 88.72% done\n",
      "Window Segmentation 90.30% done\n",
      "Window Segmentation 91.88% done\n",
      "Window Segmentation 93.47% done\n",
      "Window Segmentation 95.05% done\n",
      "Window Segmentation 96.63% done\n",
      "Window Segmentation 98.22% done\n",
      "Window Segmentation 99.80% done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "feature_columns = dataset_columns[:-1]\n",
    "(segments, labels) = segment_dataset(dataset, feature_columns, 'Bloom', 9)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938, 9, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaping the data to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938, 9, 7, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = segments.reshape(len(segments),9,7,1)\n",
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS0AAAAkCAYAAADcm2ySAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABMNJREFUeJztnE1oXFUUx3/HNlEMNTQVaxUKCiLdKPiBiAYFEUtE2oULXYiLaikudCUGBDcqUhWXLlxIiAsV3NiFtLY1tZsWjPiRKMTaClKoxmhFotg29bi4N+k4TpPJm/cx983/B0Pu+8j73XOYHO57796YuyOEEKlwSdUdEEKI1aCiJYRIChUtIURSqGgJIZJCRUsIkRQqWkKIpOioaJnZVjObMbPvzWw0r051k7PuviqcdfdV4eyFGJe8Wedpmdka4G/gOHAGuAG4zd2/za971Trr7qvCWXdfFc5eiLGRFUdaZva2mc2a2XTDviHgCLAG+Am4F3gR2JZHp8p21t1XhbNbYgTuI3zP+4BZ4LUifb2Q06KdK9HO7eEYsLVp3yjwHfAncDhunwSuzalfZTvr7qvCWbbvYs6ngAXgDuAgcGvBvl7IadHOZVmxaLn7YeC3pt3bgE9jezvwDKHa/u9e08x2mtmkmU329fW1dS/aibNsXxancrq8L2fn7cA54GPgUeDugn2ZcmpmvxTpa+VcydepM4uvHbI+iN8ITAOfu/tNhHvbEaC/xbnDwBZgy8LCQicdb9dZti8vp3JajPMKYNLdbwHuj9vdltMFYF3BvmZnSt+b/9DJ28PPgM1mdh2hwhrwR/NJ7v6Yuw+4+wAtqn/ezrJ9OTuV0/yd5xt8v8d93ZbTr2I/C/O1cKb2vVkia9H6GdgMPAscAAYIbxAO5tSvbnDW3VeFs4oYZ4GXgX3AMUJxUE7Tcy6xNuPv7QF2AQ8AlxMq7FvuvjevjnWBs+6+KpxVxHgIeIlQvAaBI8ppks4LuPuyH+Bd4BThYeZJYAewgVBVj8WfQytdJ17raJvn5eIs29euUzlVjE3X2Qm8o5y298k8uVQIIapAaw+FEGmR15CtaSj4PHCWMKScIwwj9wPr4/EnCK9JzxAmqP0DfBk/exLynSU8iNzf6Gzhe47wADjFGEvx9UKMymk+vlyLVexUX+zwPcAbsf0QYdbs7njOODAd248A5xL1DcT2WDw2Cuxu4XsfmE80xsJ9vRCjcpqfL3NClun4k8BcbM8AE8BeYBMwE/dPAR/E9lriPI/UfHF7HpiI7U2xD82+OTorWrXOaS/EqJzm5yvimdaNhD9SCDNnZ4Br3P0UcFXcvx4YNrOvgffivi/M7KiZbU/IByHxGwAanM2+eeCyuKQhtRjL8FXhrLuvCmcpvqzztJYwswPA1Q27NgLrzKxxxXfzK8p5YMTdT5jZLuBBwmr8QeATM5ty9+Pd4GvhXPRNE+7f2/GNADe7+zdmdn23xdgFOa1djMppMTGGK2YcenY4RNwH3Bnb/YSHcYvTL8aAh1Pwxe1Wt4cX9aUWYxm+XohROc3PV8Tt4TgwaGbDwEeEVfVvAo8DH8ZzDsVtCA/sTru7m9mVwF3Aav6RWGU+MxsALgV+jMcWnY2+Vwhr3voBUouxJF8vxKic5uVbTeVeRcV9gQuvPX8lvPY8Dbwej4/H44uvPU8QFo1OATsS800QZgX/BfwADAGvEkZg5wlLHJ6OrlRjLNzXCzEqp/n4NCNeCJEUmhEvhEgKFS0hRFKoaAkhkkJFSwiRFCpaQoikUNESQiSFipYQIilUtIQQSfEvi9PXTjwosD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x2880 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what the heck does this look like now?\n",
    "X = 5\n",
    "y = 40\n",
    "plt.figure(figsize=(X,y))\n",
    "columns = 10\n",
    "for x in range(0, 10):\n",
    "    plt.subplot(len(segments) / columns + 1, columns, x + 1)\n",
    "    plt.imshow(segments[x][0]*255,cmap='gray')\n",
    "#plt.imshow(segments[0][0] * 255, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18938, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels.reshape(labels.shape[0],1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking apart training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(segments, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (17044, 9, 7, 1)\n",
      "x_test shape: (1894, 9, 7, 1)\n",
      "y_train shape: (17044, 1)\n",
      "y_test shape: (1894, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\",x_train.shape)\n",
    "print(\"x_test shape:\",x_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mod = ks.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_mod = ks.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "input_shape = (9,7,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Activation, MaxPooling2D\n",
    "\n",
    "# Gets the precision of the different metrics\n",
    "def create_class_predictions(pred):\n",
    "    retval = np.array([])\n",
    "    for row in pred:\n",
    "        max_value = (-1,-1)\n",
    "        for index, value in enumerate(row):\n",
    "            if value > max_value[1]:\n",
    "                max_value = (index, value)\n",
    "        retval = np.append(retval, max_value[0])\n",
    "    return retval\n",
    "\n",
    "\n",
    "def create_layers(num_layers):\n",
    "    layers = [Flatten(), Dropout(0.2), Dense(NUM_CLASSES, activation='softmax', input_dim=2)]\n",
    "    for i in range(0, num_layers):\n",
    "        layers.insert(0, Conv2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (17044, 9, 7, 1)\n",
      "x_train new shape: (17044, 9, 7, 1, 1)\n",
      "x_test shape: (1894, 9, 7, 1)\n",
      "x_test new shape: (1894, 9, 7, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "shape = x_train.shape\n",
    "print(\"x_train shape:\", shape)\n",
    "x_train = x_train.reshape(shape[0], shape[1], shape[2], shape[3], 1)\n",
    "print(\"x_train new shape:\", x_train.shape)\n",
    "\n",
    "shape = x_test.shape\n",
    "print(\"x_test shape:\", shape)\n",
    "x_test = x_test.reshape(shape[0], shape[1], shape[2], shape[3], 1)\n",
    "print(\"x_test new shape:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 7, 1, 44)          388256    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 7, 1, 44)       0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 7, 1, 44)          247984    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1, 7, 1, 44)       0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, 7, 1, 44)          247984    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 1, 7, 1, 44)       0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, 7, 1, 44)          759088    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 308)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 308)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 44)                13596     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 90        \n",
      "=================================================================\n",
      "Total params: 1,656,998\n",
      "Trainable params: 1,656,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "17044/17044 [==============================] - 473s 28ms/step - loss: 0.1251 - acc: 0.9958\n",
      "Epoch 2/100\n",
      "17044/17044 [==============================] - 459s 27ms/step - loss: 0.0643 - acc: 0.9960\n",
      "Epoch 3/100\n",
      "17044/17044 [==============================] - 444s 26ms/step - loss: 0.0643 - acc: 0.9960\n",
      "Epoch 4/100\n",
      " 6480/17044 [==========>...................] - ETA: 4:12 - loss: 0.0547 - acc: 0.9966"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-bdae3b3e0b51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         metrics=['accuracy'])\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = (9, 7, 1, 1)\n",
    "conv_output_shape = (1, 7, 1, 44)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(ConvLSTM2D(44, 7, input_shape=input_shape, activation='relu', padding='same'))\n",
    "model.add(Reshape(conv_output_shape))\n",
    "model.add(ConvLSTM2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Reshape(conv_output_shape))\n",
    "model.add(ConvLSTM2D(44, 4, activation='relu', padding='same'))\n",
    "model.add(Reshape(conv_output_shape))\n",
    "model.add(ConvLSTM2D(44, 7, activation='relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(44))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "        optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "        metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "recall = recall_score(y_test.reshape(-1,), predict)\n",
    "print(\"RECALL:\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (17044, 9, 7, 1, 1)\n",
      "x_train new shape: (17044, 9, 7)\n",
      "x_test shape: (1894, 9, 7, 1, 1)\n",
      "x_test new shape: (1894, 9, 7)\n"
     ]
    }
   ],
   "source": [
    "shape = x_train.shape\n",
    "print(\"x_train shape:\", shape)\n",
    "x_train = x_train.reshape(shape[0], shape[1], shape[2])\n",
    "print(\"x_train new shape:\", x_train.shape)\n",
    "\n",
    "shape = x_test.shape\n",
    "print(\"x_test shape:\", shape)\n",
    "x_test = x_test.reshape(shape[0], shape[1], shape[2])\n",
    "print(\"x_test new shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 2)                 80        \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 2)                 40        \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 1, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 2)                 40        \n",
      "=================================================================\n",
      "Total params: 160\n",
      "Trainable params: 160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "17044/17044 [==============================] - 17s 1ms/step - loss: nan - acc: 0.9952\n",
      "Epoch 2/100\n",
      "17044/17044 [==============================] - 11s 621us/step - loss: nan - acc: 0.9960\n",
      "Epoch 3/100\n",
      "17044/17044 [==============================] - 11s 629us/step - loss: nan - acc: 0.9960\n",
      "Epoch 4/100\n",
      "17044/17044 [==============================] - 11s 642us/step - loss: nan - acc: 0.9960\n",
      "Epoch 5/100\n",
      "17044/17044 [==============================] - 11s 640us/step - loss: nan - acc: 0.9960\n",
      "Epoch 6/100\n",
      "17044/17044 [==============================] - 11s 655us/step - loss: nan - acc: 0.9960\n",
      "Epoch 7/100\n",
      "17044/17044 [==============================] - 11s 654us/step - loss: nan - acc: 0.9960\n",
      "Epoch 8/100\n",
      "17044/17044 [==============================] - 10s 583us/step - loss: nan - acc: 0.9960\n",
      "Epoch 9/100\n",
      "17044/17044 [==============================] - 10s 566us/step - loss: nan - acc: 0.9960\n",
      "Epoch 10/100\n",
      "17044/17044 [==============================] - 10s 581us/step - loss: nan - acc: 0.9960\n",
      "Epoch 11/100\n",
      "17044/17044 [==============================] - 10s 560us/step - loss: nan - acc: 0.9960\n",
      "Epoch 12/100\n",
      "17044/17044 [==============================] - 10s 572us/step - loss: nan - acc: 0.9960\n",
      "Epoch 13/100\n",
      "17044/17044 [==============================] - 10s 577us/step - loss: nan - acc: 0.9960\n",
      "Epoch 14/100\n",
      "17044/17044 [==============================] - 10s 566us/step - loss: nan - acc: 0.9960\n",
      "Epoch 15/100\n",
      "17044/17044 [==============================] - 10s 592us/step - loss: nan - acc: 0.9960\n",
      "Epoch 16/100\n",
      "17044/17044 [==============================] - 12s 678us/step - loss: nan - acc: 0.9960\n",
      "Epoch 17/100\n",
      "17044/17044 [==============================] - 10s 597us/step - loss: nan - acc: 0.9960\n",
      "Epoch 18/100\n",
      "17044/17044 [==============================] - 10s 569us/step - loss: nan - acc: 0.9960\n",
      "Epoch 19/100\n",
      "17044/17044 [==============================] - 10s 568us/step - loss: nan - acc: 0.9960\n",
      "Epoch 20/100\n",
      "17044/17044 [==============================] - 10s 583us/step - loss: nan - acc: 0.9960\n",
      "Epoch 21/100\n",
      "17044/17044 [==============================] - 10s 595us/step - loss: nan - acc: 0.9960\n",
      "Epoch 22/100\n",
      "17044/17044 [==============================] - 10s 589us/step - loss: nan - acc: 0.9960\n",
      "Epoch 23/100\n",
      "17044/17044 [==============================] - 10s 564us/step - loss: nan - acc: 0.9960\n",
      "Epoch 24/100\n",
      "17044/17044 [==============================] - 11s 628us/step - loss: nan - acc: 0.9960\n",
      "Epoch 25/100\n",
      "17044/17044 [==============================] - 11s 672us/step - loss: nan - acc: 0.9960\n",
      "Epoch 26/100\n",
      "17044/17044 [==============================] - 11s 644us/step - loss: nan - acc: 0.9960\n",
      "Epoch 27/100\n",
      "17044/17044 [==============================] - 11s 630us/step - loss: nan - acc: 0.9960\n",
      "Epoch 28/100\n",
      "17044/17044 [==============================] - 11s 667us/step - loss: nan - acc: 0.9960\n",
      "Epoch 29/100\n",
      "17044/17044 [==============================] - 11s 664us/step - loss: nan - acc: 0.9960\n",
      "Epoch 30/100\n",
      "17044/17044 [==============================] - 11s 655us/step - loss: nan - acc: 0.9960\n",
      "Epoch 31/100\n",
      "17044/17044 [==============================] - 11s 659us/step - loss: nan - acc: 0.9960\n",
      "Epoch 32/100\n",
      "17044/17044 [==============================] - 11s 622us/step - loss: nan - acc: 0.9960s - loss: nan -\n",
      "Epoch 33/100\n",
      "17044/17044 [==============================] - 10s 560us/step - loss: nan - acc: 0.9960\n",
      "Epoch 34/100\n",
      "17044/17044 [==============================] - 10s 572us/step - loss: nan - acc: 0.9960\n",
      "Epoch 35/100\n",
      "17044/17044 [==============================] - 10s 571us/step - loss: nan - acc: 0.9960\n",
      "Epoch 36/100\n",
      "17044/17044 [==============================] - 10s 565us/step - loss: nan - acc: 0.9960\n",
      "Epoch 37/100\n",
      "17044/17044 [==============================] - 10s 590us/step - loss: nan - acc: 0.9960\n",
      "Epoch 38/100\n",
      "17044/17044 [==============================] - 10s 558us/step - loss: nan - acc: 0.9960\n",
      "Epoch 39/100\n",
      "17044/17044 [==============================] - 9s 553us/step - loss: nan - acc: 0.9960\n",
      "Epoch 40/100\n",
      "17044/17044 [==============================] - 10s 577us/step - loss: nan - acc: 0.9960\n",
      "Epoch 41/100\n",
      "17044/17044 [==============================] - 11s 637us/step - loss: nan - acc: 0.9960\n",
      "Epoch 42/100\n",
      "17044/17044 [==============================] - 12s 680us/step - loss: nan - acc: 0.9960\n",
      "Epoch 43/100\n",
      "17044/17044 [==============================] - 13s 745us/step - loss: nan - acc: 0.9960\n",
      "Epoch 44/100\n",
      "17044/17044 [==============================] - 12s 690us/step - loss: nan - acc: 0.9960\n",
      "Epoch 45/100\n",
      "17044/17044 [==============================] - 12s 717us/step - loss: nan - acc: 0.9960\n",
      "Epoch 46/100\n",
      "17044/17044 [==============================] - 11s 653us/step - loss: nan - acc: 0.9960\n",
      "Epoch 47/100\n",
      "17044/17044 [==============================] - 10s 590us/step - loss: nan - acc: 0.9960\n",
      "Epoch 48/100\n",
      "17044/17044 [==============================] - 10s 583us/step - loss: nan - acc: 0.9960\n",
      "Epoch 49/100\n",
      "17044/17044 [==============================] - 10s 577us/step - loss: nan - acc: 0.9960\n",
      "Epoch 50/100\n",
      "17044/17044 [==============================] - 10s 577us/step - loss: nan - acc: 0.9960\n",
      "Epoch 51/100\n",
      "17044/17044 [==============================] - 10s 592us/step - loss: nan - acc: 0.9960s\n",
      "Epoch 52/100\n",
      "17044/17044 [==============================] - 10s 592us/step - loss: nan - acc: 0.9960\n",
      "Epoch 53/100\n",
      "17044/17044 [==============================] - 10s 593us/step - loss: nan - acc: 0.9960\n",
      "Epoch 54/100\n",
      "17044/17044 [==============================] - 10s 566us/step - loss: nan - acc: 0.9960\n",
      "Epoch 55/100\n",
      "17044/17044 [==============================] - 10s 570us/step - loss: nan - acc: 0.9960\n",
      "Epoch 56/100\n",
      "17044/17044 [==============================] - 10s 581us/step - loss: nan - acc: 0.9960\n",
      "Epoch 57/100\n",
      "17044/17044 [==============================] - 10s 566us/step - loss: nan - acc: 0.9960\n",
      "Epoch 58/100\n",
      "17044/17044 [==============================] - 10s 595us/step - loss: nan - acc: 0.9960\n",
      "Epoch 84/100\n",
      "17044/17044 [==============================] - 10s 584us/step - loss: nan - acc: 0.9960\n",
      "Epoch 85/100\n",
      "17044/17044 [==============================] - 10s 568us/step - loss: nan - acc: 0.9960\n",
      "Epoch 86/100\n",
      "17044/17044 [==============================] - 11s 622us/step - loss: nan - acc: 0.9960\n",
      "Epoch 87/100\n",
      "17044/17044 [==============================] - 11s 635us/step - loss: nan - acc: 0.9960\n",
      "Epoch 88/100\n",
      "17044/17044 [==============================] - 10s 571us/step - loss: nan - acc: 0.9960\n",
      "Epoch 89/100\n",
      "17044/17044 [==============================] - 10s 593us/step - loss: nan - acc: 0.9960\n",
      "Epoch 90/100\n",
      "17044/17044 [==============================] - 10s 577us/step - loss: nan - acc: 0.9960\n",
      "Epoch 91/100\n",
      "17044/17044 [==============================] - 10s 572us/step - loss: nan - acc: 0.9960\n",
      "Epoch 92/100\n",
      "17044/17044 [==============================] - 10s 578us/step - loss: nan - acc: 0.9960\n",
      "Epoch 100/100\n",
      "17044/17044 [==============================] - 10s 598us/step - loss: nan - acc: 0.9960\n",
      "17044/17044 [==============================] - 3s 169us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mccomackjp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in greater\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7566633b19cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_class_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RECALL:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1365\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1368\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m-> 1047\u001b[1;33m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[0;32m   1048\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "input_shape = (9, 7)\n",
    "conv_output_shape = (1, 7, 1, 44)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(NUM_CLASSES, dropout=0.2, input_shape=input_shape))\n",
    "model.add(Reshape((1, 2)))\n",
    "model.add(LSTM(NUM_CLASSES, dropout=0.2))\n",
    "model.add(Reshape((1, 2)))\n",
    "model.add(LSTM(NUM_CLASSES, dropout=0.2))\n",
    "Dense(NUM_CLASSES, activation='softmax', input_dim=2)\n",
    "model.compile(loss=ks.losses.categorical_crossentropy,\n",
    "        optimizer=ks.optimizers.Adam(lr=0.0001),\n",
    "        metrics=['accuracy'])\n",
    "model.build()\n",
    "print(model.summary())\n",
    "model.fit(x=x_train, y=y_train_mod, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "score = model.evaluate(x_train, y_train_mod, verbose=1)\n",
    "predictions = model.predict(x_test)\n",
    "predict = create_class_predictions(predictions)\n",
    "recall = recall_score(y_test.reshape(-1,), predict)\n",
    "print(\"RECALL:\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the precision of the different metrics\n",
    "def create_class_predictions(pred):\n",
    "    retval = np.array([])\n",
    "    for row in pred:\n",
    "        max_value = (-1,-1)\n",
    "        for index, value in enumerate(row):\n",
    "            if value > max_value[1]:\n",
    "                max_value = (index, value)\n",
    "        retval = np.append(retval, max_value[0])\n",
    "    return retval\n",
    "\n",
    "predict = create_class_predictions(predictions)\n",
    "recall = recall_score(y_test.reshape(-1,), predict)\n",
    "print(recall)\n",
    "print(predict)\n",
    "print(y_test.reshape(-1,))\n",
    "y = y_test.reshape(-1,)\n",
    "for i in range(0, len(predict)):\n",
    "    if predict[i] == y[i]:\n",
    "        print(y[i])\n",
    "#     else:\n",
    "#         print(\"y={}, p={}\".format(y[i], predict[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring dropout for deployment\n",
    "K.set_learning_phase(0)\n",
    " \n",
    "# Set a file path to save the model in.\n",
    "model_name = \"rnn_detection_model\"\n",
    "model_version = \"1\"\n",
    "tf_path = \"./../../saved_models/{}/{}\".format(model_name, model_version)\n",
    " \n",
    "# Get the session from the Keras back-end to save the model in TF format.\n",
    "with K.get_session() as sess:\n",
    "    tf.saved_model.simple_save(sess, tf_path, inputs={'input': model.input}, outputs={t.name: t for t in model.outputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
